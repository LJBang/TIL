{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22.03.25\n",
    "\n",
    "### 단어 임베딩\n",
    "\n",
    "#### 동의어\n",
    "서로 대치해도 의미가 비슷한 단어들 (상황에 따라 잘 맞이 않을 수 있다.)  \n",
    "\n",
    "#### 유사성\n",
    "유사한 의미를 가진 단어들  \n",
    "차 - 자전거  \n",
    "소 - 말  \n",
    "\n",
    "#### 연관성  \n",
    "단어들은 유사성 외에도 연관될 수 있다.  \n",
    "\n",
    "**Semantic Field**  \n",
    "특정한 주제나 영역을 공유하는 단어들  \n",
    "병원 - 수술, 의사, 간호사, ...  \n",
    "식당 - 웨이터, 메뉴, 음식, ...  \n",
    "\n",
    "**Semantic Frame**  \n",
    "특정 행위에 참여하는 주체들의 역할에 관한 단어들  \n",
    "상거래 - buy, sell, pay, ...  \n",
    "\n",
    "#### 벡터로 의미 표현하기  \n",
    "단어들은 주변 단어에 의해 의미가 결정된다.  \n",
    "따라서 A, B의 주변단어가 거의 동일하다면 두 단어는 유사하다고 할 수 있다.  \n",
    "벡터 공간 내에서 비슷한 단어들은 가까이 있다.  \n",
    "벡터로 표현된 단어를 임베딩이라고 한다.  \n",
    "\n",
    "**희소벡터**  \n",
    "- tf-idf  \n",
    "- Vector propagation  \n",
    "\n",
    "**밀집벡터**  \n",
    "- Word2vec  \n",
    "- Glove  \n",
    "- 더 적은 개수의 파라미터  \n",
    "- 더 나은 일반화 능력\n",
    "- 동의어, 유사어를 더 잘 표현  \n",
    "\n",
    "희소모델과 밀집모델을 함께 사용할 수 있다.  \n",
    "\n",
    "### Word2Vec\n",
    "주어진 단어 w에 대해서 주변 단어 c를 예측하는 분류기를 만든다고 생각할 때,  \n",
    "이를 위한 가중치가 w의 임베딩 벡터이다.  \n",
    "skip-gram: 한 단어가 주어질 때 주변 단어를 예측할 확률을 구하는 것.  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
