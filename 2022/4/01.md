# 22.04.01
## 네트워크
### 로드밸런싱
웹에 접속하는 인원이 늘어남에 따라 한대의 하드웨어로는 감당이 안됨.  
여러대의 서버가 나눠서 일 하도록 스케일업 하는 것이 효과적이다.  
이 때 트래픽을 균등하게 분산시켜주는 것이 로드밸런싱이다.  

로드밸런서를 서버와 클라이언트 사이에 두어 클라이언트의 요청을 서버에 부하가 일어나지 않도록 분산시켜준다.  
#### 서버 선택 방식
- 라운드 로빈: CPU스케쥴링의 라운드로빈 방식
- least connections: 연결 개수가 가장 적은 서버 선택(트래픽으로 인해 세션이 길어지는 경우 권장)
- Source: 사용자 IP를 해싱하여 분배(특정 사용자가 항상 같은 서버로 연결 되는 것 보장)  
#### 로드밸런서 장애 대비
서버를 분배하는 로드밸런서에 문제가 생길 수 있기 때문에 로드 밸런서를 이중화 한다.  
두 대의 밸런서가 서로 상태 체크를 계속 하며 메인 밸런서가 동작하지 않을 경우  
메인 밸런서에 연결된 가상 IP는 서브 밸런스로 변경되고, 서브 밸런서가 역할을 수행한다.  

### Blocking-NonBlocking / Synchronous-Asynchronous
#### Blocking / NonBlocking
블럭/논블럭은 호출된 함수가 호출한 함수에게 제어권을 건네주는 유무의 차이.  
함수 A, B가 있고, A안에서 B를 호출했을 때, 호출한 함수는 A이고, 호출된 함수는 B이다. 호출된 B에게 제어권이 있다.  
- Blocking: 함수 B는 내 할일을 다 마칠때까지 제어권을 가지고 있는다. A는 B가 다 마칠때 까지 기다려야한다.  
- Non-Blocking: 함수 B는 내 할일을 마치지 않았어도, A에게 제어권을 바로 넘겨준다. A는 B를 기다리면서도 다른일을 진행한다.  
#### Sync/Async
동기/비동기는 일을 수행중인 동시성에 주목  
위와 같은 상황에서 B의 수행결과나 종료 상태를 A가 신경쓰고 있는지의 차이  
- Sync: 함수 A는 함수 B가 일을 하는 중에 기다리면서, 현재 상태가 어떤지 계속 체크한다.  
- Async: 함수 B의 수행 상태를 B 혼자 직접 신경쓰면서 처리한다(Callback)  
비동기는 호출시 Callback을 전달하여 작업의 완료여부를 호출한 함수에게 답하게 된다.  
Callback이 오기 전까지 호출한 함수는 신경쓰지 않고 다른 일을 할 수 있음.  

### Blocking IO / NonBlocking IO
#### Blocking IO
I/O Bloking 형태의 작업은  
1. process가 Kernel에게 IO를 요청하는 함수 호출  
2. kernel이 작업을 완료하면 결과를 반환받음  
- IO작업이 진행되는 동안 user Process는 자신의 작업을 중단한 채 대기  
- resource낭비가 심함 (IO는 CPU를 거의 쓰지 않으므로)  
따라서 여서 클라이언트가 접속하는 서버를 Blocking방식으로 구현하는 경우 한 클라이언가 IO작업을 진행하는 동안 다른 클라이언트의 작업을 중지할 수 없으므로 클라이언트별로 스레드를 만들어야하고 스레드가 많아지면 컨텍스트 스위칭 횟수가 증가한다. -> 비효율적  
#### Nonblocking IO
IO작업이 진행되는 동안 유저 프로세스 작업을 중지하지 않음  
1. 유저 프로세스가 recvfrom함수 호출(커널에게 해당 소켓으로부터 data를 받고 싶다고 요청)
2. 커널은 이 요청에 대해서, 곧바로 recvbuffer를 채워서 보내지 못하므로, `EWOULDBLOCK`을 반환.
3. 유저 프로세스는 다른작업 진행 가능
4. recvbuffer에 유저가 받을 수 있는 데이터가 있는 경우 buffer로부터 데이터를 복사하여 받아옴. 이때 recvbuffer는 커널이 가진 메모리에 적재되어 있으므로, 메모리간 복사로 인해 IO보다 훨씬 빠른 속도로 data를 받아올 수 있음  
5. recvfrom함수는 빠르게 data를 복사한 후, 복사한 data의 길이와 함께 반환.  

## 운영체제
### 프로세스 / 스레드
프로세스: 프로그램을 메모리 상에서 실행중인 작업  
스레드: 프로세스 안에서 실행되는 여러 흐름 단위  
기본적으로 프로세스마다 최소 한 개의 스레드 소유(메인 스레드 포함)  

프로세스는 각각 별도의 주소공간 할당(독립적)  
- Code: 코드 자체를 구성하는 메모리 영역(프로그램 명령)  
- Data: 전역변수, 정적변수, 배열 등
    - 초기화된 데이터는 data영역에 저장
    - 초기화 되지 않은 데이터는 bss영역에 저장  
- Heap: 동적 할당시 사용(new(), malloc() 등)
- Stack: 지역변수, 매개변수, 리턴 값(임시 메모리 영역)

스레드는 Stack만 따로 할당 받고, 나머지 영역은 서로 공유한다.  
스택만 독립적으로 할당 받는 이유는 스택은 함수 호출 시 전달되는 인자, 돌아갈 주소값 및 함수 내에서 선언하는 지역변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고, 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.  
하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드가 같이 생성된다.  
프로세스는 자신만의 고유 공간이 있는 반면 스레드는 프로세스 내부의 다른 스레드와 공간, 자원을 공유한다.  

#### 멀티 프로세스
하나의 컴퓨터에 여러 CPU 장착 -> 하나 이상의 프로세스들을 동시에 처리(병렬)  
장점: 안정성(메모리 침범 문제는 OS차원에서 해결)  
단점: 각각 독립된 메모리 영역을 갖고 있어, 작업량 많을 수록 오버헤드 발생, Context Switching으로 인한 성능 저하  
#### 프로세스의 Context Switching
프로세스의 상태 정보를 저장하고 복원하는 일련의 과정  
즉, 동작중인 프로세스가 인터럽트 요청에 의해 대기하면서 해당 프로세스의 상태를 보관하고, 대기하고 있던 다음 순번의 프로세스가 동작하면서 새로운 프로세스의 상태나 레지스터 값으로 교체하는 작업.  
-> 프로세스는 각 독립된 메모리 영역을 할당받아 사용하므로, 새로 캐시정보를 쌓아야 하고, 그 동안 CPU는 아무것도 못하기 때문에 오버헤드가 생긴다.  
#### 멀티 스레드
하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것  
스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌  
장점: 독립적인 프로세스에 비해 공유 메모리만큼의 시간, 자원 손실이 감소한다. 전역변수와 정적 변수에 대한 자료 공유 가능, 스레드의 context switching은 캐시 메모리를 비울 필요가 없기 때문에 프로세스의 것보다 훨씬 빠르다.    
단점: 안정성. 하나의 스레드가 데이터 공간을 망가뜨리면 모든 스레드가 작동불능  
이러한 단점은 Critical Section기법을 통해 대비 -> 이것도 과도할 경우 병목현상이 일어날 가능성이 높다.  

### PCB, ContextSwitching
CPU는 각 프로세스들이 누구인지 알아야 관리가 가능한데, 이 특징이 Process Metadata  
#### Process Metadata
- Process ID (PID)
- Process State
- Process Priority
- CPU Registers
- Owner
- CPU Usage
- Memory Usage  
이 메타데이터들은 프로세스가 생성되면 PCB(Process Control Block)에 저장됨  
#### PCB
CPU에서는 프로세스의 상태에 따라 교체작업이 이루어지기 때문에, 앞으로 다시 수행할 대기 중인 프로세스에 관한 저장 값을 PCB에 저장해둔다.  
#### PCB의 관리
Linked List방식으로 관리되며,  
PCB List Head에 PCB들이 생성될 때마다 붙는다. 주소값으로 연결이 이루어진 연결리스트이기 때문에 삽입, 삭제가 용이하다.  
즉, 프로세스가 생성되면 해당 PCB가 생성되고, 프로세스 완료시 제거된다.  
#### Context Switching
수행중인 프로세스를 변경할 때, CPU의 레지스터 정보가 변경되는 것.  
즉 CPU가 이전의 프로세스 상태를 PCB에 보관하고, 또 다른 프로세스의 정보를 PCB에 읽어 레지스터에 적재하는 과정.  
보통 인터럽트가 발생하거나 실행중인 CPU사용 허가 시간을 모두 소모하거나, 입출력을 위해 대기해야 하는 경우에 Context Switching이 발생한다.  

### 인터럽트
프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우 현재 실행중인 작업을 즉 시 중단하고, 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것.  
하드웨어 지원을 받는 인터럽트의 경우 반응이 빠르기 때문에 실시간 대응이 필요할 때 사용할 수 있다.
외부/내부 인터럽트는 CPU의 하드웨어 신호에 의해 발생  
소프트웨어 인터럽트는 명령어의 수행에 의해 발생  
- 외부 인터럽트  
    입출력 장치, 타이밍장치, 전원 등 외부적인 요인으로 발생  
    전원이상, 기계착오, 외부신호, 입출력 등  
- 내부 인터럽트  
    Trap이라고 부르며, 잘못된 명령이나 데이터를 사용할 때 발생  
    0으로 나누기, 오버플로우, 예외  
- 소프트웨어 인터럽트  
    프로그램 처리 중 명령의 요청에 의해 발생한 것, (SVC인터럽트)
    사용자가 프로그램을 실행시킬 때 발생  
    소프트웨어 이용 중 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다.  
#### 처리 과정
1. 주프로그램 실행 중 인터럽트 발생
2. 현재 수행 중인 프로그램을 멈추고, 상태 레지스터와 PC등을 스택에 저장 후 인터럽트 서비스 루틴으로 이동  
3. 인터럽트 처리 후 저장된 복귀 주소 호출  
4. 주 프로그램의 마지막에 실행되전 주소로 이동 후 주 프로그램 실행  
인터럽트가 없다면 폴링 방식을 이용행 컨트롤러가 시기를 계속 체크해주어야 한다.  
이는 주 프로그램에 집중할 수 없게되어 비효율적임  

### 시스템 콜
fork(), exec(), wait()와 같은 것들은 process 생성과 제어를 위한 System Call  
fork()는 새로운 프로세스를 위한 메모리를 할당한다. fork()를 호출한 프로세스를 새로운 공간으로 전부 복사하게 되고, 원래 프로세스(부모)는 원래 프로세스대로 작업을 실행하고 fork()를 이용해서 생성된 프로세스(자식)도 나름대로 fork()시스템 콜이 수행된 라인의 다음 라인부터 실행된다. 즉 복제가 되는것과 비슷 그러나 fork()의 리턴값은 다르다.   
exec()은 새로운 프로세스를 위한 메모리를 할당하지 않고, exec()을 호출한 프로세스가 아닌 exec()에 의해 호출된 프로세스만 메모리에 남게 된다. 즉 새 프로세스가 기존 프로세스에 덮어씌워짐. 자식 프로세스에서 부모와 다른 동작을 하고 싶을 때, exec을 사용한다. 인자로 받은 파일이나 함수를 실행하며, heap, stack과 같은 메모리 영역이 초기화된다.    

### IPC, Inter Process Communication
프로세스는 서로 독립적이므로, 프로세스간 통신이 필요하다.  
운영체제의 커널이 제공하는 IPC설비를 이용해 프로세스간 통신을 할 수 있게 된다.  
#### IPC의 종류  
1. 익명 PIPE  
    파이프는 두개의 프로세스를 연결하는데 하나의 프로세스는 데이터를 쓰기만 하고, 다른 하나는 데이터를 읽기만 할 수 있다. 
    한쪽 방향으로만 통신이 가능한 반이중 통신이라고도 한다.  
    따라서 양 쪽으로 모두 송/수신을 하고 싶으면 2개의 파이프를 만들어야 한다.  
    매우 간단하게 사용할 수 있기 때문에 단순한 데이터 흐름을 가질 땐 파이프를 사용하는 것이 효율적이다.  
    그러나 전이중 통신을 위해 2개를 만들어야 할 때는 구현이 복잡해진다.  
2. Named PIPE(FIFO)
    익명 파이프는 통신할 프로세스를 명확히 알 수 있는 경우에 사용한다. (부모-자식 간 통신)  
    Named PIPE는 이의 확장된 형태로 전혀 모르는 상태의 프로세스들 사이 통신에 사용한다. 통신을 위해서는 이름있는 파일을 사용한다.  
    그러나 역시 읽/쓰 동시에 불가능하고, 전이중을 위해서는 2개의 파이프를 만들어야 한다.  
3. Message Queue
    입출력 방식은 Named 파이프와 동일.  
    다른 점은 메시지 큐는 파이프처럼 데이터의 흐름이 아니라 메모리 공간이다.  
    사용할 데이터에 번호를 붙이면서 여러 프로세스가 동시에 데이터를 쉽게 다룰 수 있다.  
4. 공유메모리
    파이프, 메시지큐가 통신을 이용한 설비라면, 공유 메모리는 데이터 자체를 공유하도록 지원하는 설비.  
    프로세스의 메모리 영역은 독립적으로 가지며 다른 프로세스가 접근하지 못하도록 반드시 보호되어야 한다. 하지만 다른 프로세스가 데이터를 사용하도록 해야하는 상황도 필요할 것 이다. 파이프를 이용해 통신을 통해 데이터 전달도 가능하지만, 스레드처럼 메모리를 공유하도록 해준다면 더욱 편할 것이라는 생각.  
    -> 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 허용  
    프로세스가 공유메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 메모리 공간을 할당해주고 이후 모든 프로세스는 해당 메모리 영역에 접근할 수 있게 된다.  
    -> 중개자가 없어서 곧바로 메모리에 접근할 수 있어서 IPC중에 가장 빠르게 작동한다.  
5. 메모리 맵
    공유 메모리처럼 메모리를 공유해준다. 메모리맵은 열린 파일을 메모리에 맵핑시켜서 공유하는 방식이다.(즉 공유 매개체가 파일+메모리)  
    주로 파일로 대용량 데이터를 공유해야 할 때 사용한다.  
6. 소켓
    네트워크 소켓 통신을 통해 데이터를 공유한다.  
    클라이언트와 서버가 소켓을 통해서 통신하는 구조로, 원격에서 프로세스간 데이터를 공유할 때 사용한다.  
    서버는 bind-listen-accept, 클라이언트는 connect  
이렇게 IPC 통신에서 프로세스간 데이터를 동기화하고 보호하기 위해 세마포어와 뮤텍스를 사용한다.  

### CPU Scheduling
CPU를 잘 사용하기 위해서 프로세스를 잘 배정하자.  
오버헤드와 기아현상을 줄이고, 사용률을 높이자.  
Batch System: 사능하면 많은 일을 수행. 시간(time)보다 처리량(Throughout)이 중요하다.  
Interactive System: 빠른 응답시간, 적은 대기 시간  
Real-time System: 기한 맞추기  

#### 선점/ 비선점 스케쥴링  
선점(preemptive): OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우(처리시간 예측이 어려움)  
비선점(nonpreemptive): 프로세스종료 or IO등의 이벤트가 있을 때까지 실행 보장(처리시간 예측 용이함)  

#### 비선점 스케쥴링
1. FCFS(First Come First Served)
    - 큐에 도착한 순서대로 CPU 할당  
    - 실행 시간이 짧은 게 뒤로 가면 평균 대기 시간이 길어짐
2. SJF(Shortest Job First)
    - 수행 시간이 가장 짧다고 판단되는 작업을 먼저 수행  
    - FCFS보다 평균 대기시간 감소, 짧은 작업에 유리
3. HRN(Hightest Response-ratio Next)
    - 우선순위를 계산하여 점유 불평등을 보완한 방법(SJF의 단점 보완)  
    - 우선순위 = (대기시간 + 실행시간) / (실행시간)  
#### 선점 스케쥴링
1. Priority Scheduling
    - 정적/동적으로 우선순위를 부여하여 우선순위가 높은 순서대로 처리  
    - 우선순위가 낮은 프로세스가 무한정 기다리는 Starvation이 생길 수 있음
    - Aging 방법으로 Starvation 문제 해결 가능  
2. Round Robin
    - FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 `Time Quantum`만큼 CPU를 할당 받음. (time quantum: 실행의 최소 단위 시간)  
    - 할당 시간이 크면 FCFS와 같게 되고, 작으면 문맥 교환이 잦아져서 오버헤드 증가  
3. Multilevel-Queue
    - 작업들을 여러 종류의 그룹으로 나누어 여러개의 큐를 이용하는 기법  
    - 우선순위가 낮은 큐들이 실행 못하는 걸 방지하고자 각 큐마다 다른 `time quantum`을 설정해주는 방식을 사용  
    - 우선순위가 높은 큐는 작은 time quantum할당. 우선순위가 낮은 큐는 큰 time quantum 할당  
4. Multilevel Feedback Queue
    - 다단계 큐에서 자신의 time quantum을 다 채운 프로세스는 밑으로 내려가고 자신의 time quantum을 다 채우지 못한 프로세스는 원래 큐 그대로  
    - 짧은 작업에 유리, 입출력 위주 작업(인터럽트가 잦은)에 우선권을 준다.  
    - 처리 시간이 짧은 프로세스를 먼저 처리하기 때문에 Turnaround 평균 시간을 줄여줌
#### CPU 스케쥴링 척도
1. response time  
    - 작업이 처음 실행되기까지 걸린 시간  
2. Turnaround Time  
    - 실행 시간과 대기 시간을 모두 합한 시간으로 작업이 완료될 때 까지 걸린 시간  
#### 프로세스의 상태 전이
- 승인: 프로세스 생성이 가능하여 승인됨  
- 스케줄러 디스패치: 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것.  
- 인터럽트: 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것.  
- 입출력 또는 이벤트 대기: 실행중인 프로세스가 입출력이나 이벤트를 처리해야하는 경우 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것.  
- 입출력 또는 이벤트 완료: 입출력/이벤트가 끝난 프로세스를 준비상태로 전환하여 스케줄러에 의해 선택될 수 있도록 만드는 것.  

### 데드락
프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하는 상태  
한정된 자원(크리티컬 섹션)을 여러 곳에서 사용하려고 할 때 발생  
두 프로세스가 원하는 자원이 서로에게 있어서 다음 작업을 수행하지 못하는 상태  
#### 발생 조건
아래의 4가지 모두가 성립해야 데드락이 발생하며, 하나라도 성립하지 않으면 문제 해결 가능  
1. 상호배제
    자원은 한번에 한 프로세스만 사용할 수 있음.  
2. 점유 대기
    최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야 함.  
3. 비선점
    다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음  
4. 순환 대기
    프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함.  
#### 데드락 처리
**교착 상태를 예방 & 회피**  
1. 예방
    교착 상태 발생 조건 중 하나를 제거하면서 해결한다.(자원 낭비 심함)  
    - 상호배제 부정: 여러 프로세스가 공유 자원 사용
    - 점유대기 부정: 프로세스 실행 전 모든 자원을 할당
    - 비선점 부정: 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납  
    - 순환대기 부정: 자원에 고유번호 할당 후 순서대로 자원 요구  
2. 회피
    교착상태 발생시 피해나가는 방법
    - 은행원 알고리즘
        - 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는 데서 유래함
        - 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지 사전에 검사하여 교착 상태 회피
        - 안정 상태면 자원할당, 아니면 다른 프로세스들이 자원 해지까지 대기  

**교착 상태를 탐지, 회복**  
1. 탐지
    자원 할당 그래프를 통해 교착상태를 탐지함  
    자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함  
2. 회복
    교착 상태 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법  
    **프로세스 종료 방법**  
    - 교착 상태의 프로세스를 모두 중지
    - 교착 상태가 제거될 때 까지 하나씩 프로세스 중지  
    **자원 선점 방법**
    - 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당(해당 프로세스 일시정지 시킴)  
    - 우선순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점  

### 경쟁 상태
공유 자원에 대해서 여러 프로세스가 동시에 접근할 때, 경과값에 영향을 줄 수 있는 상태.  
동시 접근시 자료의 일관성을 해친다.  

#### Race Condition이 발생하는 경우
1. 커널 작업을 수행하는 중에 인터럽트 발생
    - 문제점: 커널모드에서 데이터를 로드하여 작업을 수행하다가 인터럽트가 발생하여 같은 데이터를 조작하는 경우  
    - 해결법: 커널모드에서 작업을 수행하는 동안, 인터럽트를 disable시켜 CPU제어권을 가져가지 못하도록 한다.  
2. 프로세스가 시스템 콜을 하여 커널 모드로 진입하여 작업을수행하는 도중 문맥 교환이 발생할 때  
    - 문제점: 프로세스1이 커널모드에서 데이터를 조작하는 도중, 시간이 초과되어 CPU제어권이 프로세스2로 넘어가 같은 데이터를 조작하는 경우  
    - 해결법: 프로세스가 커널 모드에서 작업을 하는 경우 시간이 초과되어도 CPU제어권이 다른 프로세스에게 넘어가지 않도록 함  
3. 멀티 프로세서 환경에서 공유 메모리 내의 커널 데이터에 접근할 때
    - 문제점: 멀티 프로세서 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우
    - 해결법: 커널 내부에 있는 각 공유 데이터에 접근할 때마다, 그 데이터에 대한 lock/unlock을 하는 방법  

### 세마포, 뮤텍스
공유된 자원에 여러 프로세스가 동시에 접근하면서 문제가 발생할 수 있다.  
이때 공유된 자원의 데이터는 한 번에 하나의 프로세스만 접근할 수 있도록 제한을 둬야 한다.  
#### 임계구역
여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분  
공유 데이터를 여러 프로세스가 동시에 접근할 때 잘못된 결과를 만들 수 있기 때문에, 한 프로세스가 임계 구역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야한다.  
#### 세마포어 P, V연산 
P: 임계구역 들어가기전에 수행, 프로세스 진입 여부를 자원의 개수를 통해 결정  
V: 임계 구역에서 나올 때 수행, 자원반납 알림, 대기중인 프로세스를 깨우는 신호  

한 프로세스가 P혹은 V를 수행하고 있는 동안 프로세스가 인터럽트당하지 않게 된다.  
P와 V를 사용하여 임계 구역에 대한 상호배제 구현이 가능하게 되었다.  
#### 뮤텍스
각 스레드들의 실행시간이 서로 겹치지 않고 각각 단독으로 실행되게 하는 기술  
lock, unlock으로 되어있기 때문에 이진 세마포어라고 부르기도 한다.  
#### 뮤텍스 알고리즘
1. 데커 알고리즘: flag와 turn을 통해 임계 구역에 들어갈 프로세스/스레드를 결정하는 방식  
    flag: 프로세스 중 누가 임계영역에 진입할 것인지 나타내는 변수  
    turn: 누가 임계구역에 들어갈 차례인지 나타내는 변수  
2. 피터슨 알고리즘: 데커와 유사하지만, 상대방 프로세스/스레드에 진입 기회를 양보  
    프로세스 1이 임계구역 진입 시도 -> 2에게 먼저 양보 -> 대기 후 1 진입  
3. 제과점 알고리즘: 여러 프로세스/스레드에 대한 처리가 가능한 알고리즘, 가장 작은 수의 번호표를 가지고 있는 프로세스가 입계 구역에 진입한다.  

### 페이징과 세그먼테이션
기법을 쓰는 이유  
다중 프로그래밍 시스템에 여러 프로세스를 수용하기 위해 주기억장치를 동적 분할하는 메모리 관리 작업이 필요하기 때문  

#### 메모리 관리 기법
1. 연속 메모리 관리
    - 프로그램 전체가 하나의 커다란 공간에 연속적으로 할당되어야 함
    - 고정 분할 기법: 주기억장치가 고정된 파티션으로 분할(내부 단편화 발생)
    - 동적 분할 기법: 파티션들이 동적 생성되며 자신의 크기와 같은 파티션에 적재(외부 단편화 발생)  
2. 불연속 메모리 관리
    - 프로그램 일부가 서로 다른 주소 공간에 할당될 수 있는 기법
    - 페이지: 고정 사이즈의 작은 프로세스 조각
    - 프레임: 페이지 크기와 같은 주기억장치 메모리 조각
    - 단편화: 기억 장치으 ㅣ빈 공간 or 자료가 여러 조각으로 나뉘는 현상
    - tprmajsxm: 서로 다른 크기를 가진 논리적 블록이 연속적 공간에 배치되는 것  

- 고정 크기: 페이징  
- 가변 크기: 세그먼테이션  
- 단순 페이징  
    각 프로세스는 프레임들과 같은 길이를 가진 균등 페이지로 나뉨  
    외부 단편화 X  
    소량의 내부 단편화 존재  
- 단순 세그먼테이션  
    각 프로세스는 여러 세그먼트들로 나뉨  
    내부 단편화 x, 메모리 사용 효율 개선, 동적 분할을 통한 오버헤드 감소  
    외부 단편화 존재  
- 가상 메모리 페이징
    단순 페이징과 비교해 프로세스 페이지 전부를 로드시킬 필요 X  
    필요한 페이지가 있으면 나중에 자동으로 불러들여짐  
    외부단편화 X  
    복잡한 메모리 관리로 오버헤드 발생  
- 가상 메모리 세그먼테이션
    필요하지 않은 세그먼트들은 로드X  
    필요한 세그먼트 있을때 자동으로 불러들여짐  
    내부단편화 X  
    복잡한 메모리 관리로 오버헤드 발생  

### 페이지 교체 알고리즘
페이지 부재 -> 새로운 페이지 할당해야함 -> 현재 할당된 페이지 중 무엇을?  

### 메모리
메인 메모리: CPU가 직접 접근할 수 있는 기억 장치, 프로세스가 실행되려면 프로그램이 메모리에 올라와야 함  
메인 메모리는 주소가 할당된 일련의 바이트들로 구성되어 있다.  
CPU는 레지스터가 지시하는대로 메모리에 접근하여 다음에 수행할 명령어를 가져온다.  
명령어 수행 시 메모리에 필요한 데이터가 없으면 해당 데이터를 우선 가져온다.  
이 역할을 하는 것이 바로 MMU  
메모리 관리장치 MMU는 논리주소를 물리 주소로 변환해준다.  
뿐만 아니라 메모리 보호나 캐시 관리 등 CPU가 메모리에 접근하는 것을 총 관리해주는 하드웨어다.  
메모리의 공간이 한정적이기 때문에 사용자에게 더 많은 메모리를 제공하기 위해 가상주소라는 개념이 등장했다.(프로그램 상에서 사용자가 보는 주소 공간)  
이 가상 주소에서 실제 데이터가 담겨 있는 곳에 접근하기 위해선 빠른 주소 변환이 필요한데, 이를 MMU가 도와주는 것이다.  
또한 메인 메모리의 직접 접근은 비효율적이므로, CPU와 메인 메모리 속도를 맞추기 위해 캐시가 존재한다.  
#### MMU의 메모리 보호  
프로세스는 독립적인 메모리 공간을 가져야 하고, 자신만의 공간만 접근해야 한다.  
따라서 한 프로세스에게 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 Trap을 발생시키며 보호한다.  
base와 limit을 사용한 보호기법이 있다.  
base 레지스터는 메모리상의 프로세스 시작 주소를 물리 주소로 저장  
limit 레지스터는 프로세스의 사이즈를 저장  
이렇게 프로세스에 접근 가능한 합법적인 메모리 영역을 제한하므로써 이 영역 밖에서 접근하면 trap을 발생시킨다.  
#### 메모리 과할당
실제 메모리의 사이즈보다 더 큰 사이즈의 메모리를 프로세스에 할당한 상황  
페이지 기법과 같은 메모리 관리 기법들은 사용자가 눈치채지 못하도록 눈속임(가상메모리)을 통해 메모리를 할당해준다.  
과할당 상황에 대해서 사용자를 속인 것을 들킬만한 상황이 존재한다.  
1. 프로세스 실행 도중 페이지폴트  
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음  
3. 메모리의 빈 프레임에 페이지를 올려야 하는데, 모든 메모리가 사용중이라 빈 프레임이 없음  

과할당을 해결하기 위해서는 빈 프레임을 확보할 수 있어야 한다.  
1. 메모리에 올라와 있는 한 프로세스를 종료시켜 빈 프레임을 얻음 ->사용자에게 페이징을 들킬수 있어서 하면 안됨  
2. 프로세스 하나는 swap out하고 이 공간을 빈 프레임으로 활용  

#### 페이지 교체
메모리 과할당이 발생했을 때, 프로세스 하나를 swap out해서 빈 프레임을 확보하는 것.  
1. 프로세스 실행 도중 페이지 부재 발생  
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음
3. 메모리에 빈 프레임 확인
    - 있으면 해당 프레임 사용
    - 없으면 victim프레임 선정 후 디스크에 기록하고 페이지 테이블 업데이트  
4. 빈 프레임에 페이지 폴트가 발생한 페이지를 올리고 페이지 테이블 업데이트  

#### 오버헤드를 감소시키는 해결법
빈 프레임이 없는 상황에서 victim프레임을 비울 때와 원하는 페이지를 프레임으로 올릴 때 두 번의 디스크 접근이 이뤄진다 -> 오버헤드  

방법1  
변경 비트를 모든 페이지마다 둬서 victim페이지가 정해지면 해당 페이지의 비트를 확인  
- 해당 비트가 set -> 페이지 내용이 디스크상의 내용과 달라졌다는 뜻, 페이지가 메모리에 올라온 이후 한번이라도 수정이 일어난 상태, 디스크에 기록해야 한다.  
- bit가 clear -> 디스크 상의 페이지 내용과 메모리상의 페이지가 정확히 일치 -> 기록할 필요 없음  
비트를 활용해 디스크에 기록하는 횟수를 줄이면서 오버헤드에 대한 수를 최대 절반으로 감소시킬 수 있다.  

방법2  
페이지 교체 알고리즘을 상황에 따라 잘 선택해야 한다.  
현재 상황에서 페이지 폴트를 발생할 확률을 최대한 줄여줄 수 있는 교체 알고리즘을 사용  
- FIFO: 페이지가 적재된 시간을 기준으로 교체될 페이지 선정  
- OPT: 앞으로 가장 오랫동안 사용하지 않을 페이지를 교체 -> 구현 불가  
- LRU: 가장 오랫동안 참조되지 않은 페이지 교체  

#### 캐시메모리
주기억 장치에 저장된 내용의 일부를 임시로 저장해두는 기억장치  
CPU와 주기억장치의 속도차이로 성능 저하를 방지하기 위한 방법  
CPU가 이미 봤던걸 다시 재접근할 때, 메모리 참조 및 인출 과정에 대한 비용을 줄이기 위해 캐시에 저장해둔 데이터를 활용한다.  
캐시는 플립플롭 소자로 구성된 SRAM이기 때문에 DRAM보다 빠르다.  

**CPU와 기억장치의 상호작용**  
CPU에서 주소 전달 -> 캐시에 명령어 존재하는지 확인  
- 존재 -> Hit -> 해당 명령어를 CPU로 전송  
- 비존재 -> Miss -> 명령어를 갖고 주기억장치로 접근 -> 해당 명령어를 가진 데이터 인출 -> 해당 명령어 데이터를 캐시에 저장 -> 해당 명령어를 CPU로 전송 -> 완료  

이처럼 캐시를 잘 활용 한다면 비용을 많이 줄일 수 있다.  
따라서 CPU가 어떤 데이터를 원할지 어느정도 예측할 수 있어야 한다.  

#### 지역성의 원리
캐시에 쓸모있는 정보를 넣기위해 사용하는 이론  
- 시간 지역성: 최근에 참조된 주소의 내용은 곧 다음에도 참조되는 특성
- 공간 지역성: 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성  

#### 캐싱 라인
빈번하게 사용되는 데이터들만 캐시에 저장했더라도, 내가 필요한 데이터를 캐시에서 찾을 때, 모든 데이터를 보는것은 낭비.  
따라서 set이나 map등과 같은 자료구조를 활용하여 캐시에 데이터를 저장한다.  

