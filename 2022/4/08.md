# 22.04.08
## 추천 시스템
### 개인정보문제
어떤 아이템을 검색했는가, 어떤 상품을 클릭했는가에 따라서 개인화하여 추천하는데 이는 개인정보 유출에 문제가 생길 수 있다.  

### 실시간 추천 엔진
사용자가 로그인 하거나 방문하는 순간 추천 시작  
유데미의 경우 Kafka나 Cassandra와 같은 메세지큐와 Nosql을 사용  
일부 피쳐는 하둡 Spark를 이용해 배치로 매일 계산 후 카산드라(NoSQL)에 저장  

### 추천 엔진 평가 방법
#### LOOCV  
데이터의 수대로 cv 폴드를 만들어 사용(100개의 데이터에서 99개로 학습하고 1개로 테스트를 100번 반복)  
추천엔진 모델 검증에서 의미가 있고, 성능이 좋지만 시간이 오래걸린다.  

#### Top-N추천 정확도 기반
사용자별로 일부 높은 평점 레코드를 따로 빼놓고(LOOCV) 나중에 추천되는 아이템들과의 일치율 계산  

## 지식 세미나
### 데브코스 후회없이 수료하는 법
#### 프로젝트를 잘하자
JD를 보며 프로젝트 기술을 탐색했었음  
-> 해당 기술 경험과 이해도 향상  
데이터 라벨링 툴에 대해서 확인해보자  
doccano는 자연어처리분야에서 드래그를 이용해서 문장을 라벨링 하는 툴  
팀원들끼리 서로 피드백을 주면서 강점을 찾아보자  
꼭 기술적인 강점이 아니더라도, 시장과 사용자에 대한 이해는 차별성이 될 수 있다.  

#### 인연을 만들자
썬님이 최고 마당발이다!  

프로그래머스 수료후에 했던 프로젝트들 정리하고, 인공지능 분야 최신 트렌드들을 많이 찾아봤다.  

### 토이프로젝트 
국뽕 유튜버!  
2019년 일본 불매운동 시기부터 급증했다  
koGPT2 사용 temperature 파라미터를 사용해서 희소한 단어들도 생성될 수 있도록 만들었다.  
temperature가 높을수록 조금 더 창의적인 제목들이 나오더라~~  
진짜 국뽕같은 문장들이 만들어져서 신기하다  

### 캐글에서 발악해보자
#### 데이터
- 원핫인코딩 - 피쳐가 너무 많아진다!  
- 지섭님은 PCA를 주로 사용하심  
- mean인코딩 - 0~1사이로 인코딩  
- 숫자형 데이터는 구간별로 자르거나, 스케일링, k-means  
#### 평가
- Baseline ROC_AUC가 0.72는 넘겨야한다.  
- 베이지안 최적화로 파라미터 최적화  
- stacking 여러 모델들의 예측값을 데이터로 사용  
- 모델간 상관관계를 보고, 상관관계가 낮은 것들끼리 앙상블  
- 베이스라인 코드는 쉬운건 직접 짜지만 어려운 거는 카피앤 페이스트

### 가중치 초기화
파라미터 초기화가 중요해서 0으로 초기화를 안하고 랜덤으로 초기화 하는 줄은 알고있었는데, 하비에르 초기화나 he 초기화와 같은 수학적인 방법들이 있는줄은 몰랐다..  
he 유니폼과 relu의 조합이 최고다!  
towardsdatascience.com을 참고해보자 양질의 자료가 많다  


## 알고리즘 복습
- 추석 트래픽(문자열 처리 후 브루트): 문자열 형태로 입력된 값을 각각 따로 떼고, 각 접속기록의 시작시간, 끝 시간을 돌면서 겹치는 부분이 가장 많은 곳을 선택한다.  
- N으로 표현(DP, 브루트): i개의 숫자를 사용해서 만들 수 있는 식은 i-j개의 경우와 j개의 경우를 프로덕트 후에 모두 알아본다.  
- 입국심사(이분탐색): 모든 사람이 다 보는 데 차악 시간은 최소시간 걸리는 사람이 다 보는 경우, 이를 right로 두고 최소시간은 left로 두고 이분탐색 목표는 n명을 모두 심사할 수 있는 시간 중 최소값을 찾아 내는것.  
- 가장 먼 노드(그래프, bfs): 1번노드로부터 가장 멀리 떨어진 노드의 수를 찾아야하므로 dfs로 푸는게 나을텐데 왜 bfs로 했지? 아무튼 인접리스트방식으로 풂
- 정수 삼각형(DP): 각 줄의 각 값에서 양쪽 위에서 오는 것 중 더 큰것을 더하면서 내려간다.  