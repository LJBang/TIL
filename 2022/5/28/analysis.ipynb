{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로그래머스 머신러닝 과제 테스트\n",
    "\n",
    "### 과제\n",
    "6개의 column과 696timestamp를 가진 데이터들을 이용해  \n",
    "10을 제외한 0~15까지의 클래스를 분류하는 문제.  \n",
    "\n",
    "### 모델\n",
    "시계열 분류에서 가장 기본이 되는 LSTM과 GRU를 학습한 뒤 더 나은 모델을 사용.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "lr = 0.0001\n",
    "\n",
    "epochs = 300\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['class0', 'class1', 'class11', 'class12', 'class13', 'class14',\n",
      "       'class15', 'class2', 'class3', 'class4', 'class5', 'class6',\n",
      "       'class7', 'class8', 'class9'], dtype='<U7')]\n",
      "[array(['class0', 'class1', 'class10', 'class2', 'class3', 'class4',\n",
      "       'class5', 'class6', 'class7', 'class8', 'class9'], dtype='<U7')]\n"
     ]
    }
   ],
   "source": [
    "dataset0_classes = os.listdir('dataset0/train/')\n",
    "dataset0_label_encoder = LabelEncoder()\n",
    "dataset0_onehot_encoder = OneHotEncoder()\n",
    "\n",
    "dataset0_onehot_encoder.fit(np.array(dataset0_classes).reshape(-1,1))\n",
    "print(dataset0_onehot_encoder.categories_)\n",
    "\n",
    "dataset1_classes = os.listdir('dataset1/train/')\n",
    "dataset1_label_encoder = LabelEncoder()\n",
    "dataset1_onehot_encoder = OneHotEncoder()\n",
    "\n",
    "dataset1_onehot_encoder.fit(np.array(dataset1_classes).reshape(-1,1))\n",
    "print(dataset1_onehot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset0_onehot_encoder.transform([['class0'], ['class11']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_dir = 'dataset0/'\n",
    "dataset1_dir = 'dataset1/'\n",
    "\n",
    "dataset0_train_dir = dataset0_dir + 'train/'\n",
    "dataset0_test_dir = dataset0_dir + 'test/'\n",
    "\n",
    "dataset1_train_dir = dataset1_dir + 'train/'\n",
    "dataset1_test_dir = dataset1_dir + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir):\n",
    "  X, y = [], []\n",
    "  labels = os.listdir(dataset_dir)\n",
    "  for label in labels:\n",
    "    file_list = os.listdir(dataset_dir + label + '/')\n",
    "    for f in file_list:\n",
    "      temp = pd.read_csv(dataset_dir + label + '/' + f)\n",
    "      X.append(torch.from_numpy(temp.values))\n",
    "      y.append([label])\n",
    "  X = pad_sequence(X, batch_first=True)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# dataset0's training/test datasets & dataloader\n",
    "dataset0_X_train, dataset0_y_train = create_dataset(dataset0_train_dir)\n",
    "dataset0_y_train = dataset0_onehot_encoder.transform(dataset0_y_train).toarray()\n",
    "\n",
    "dataset0_X_test, dataset0_y_test = create_dataset(dataset0_test_dir)\n",
    "dataset0_y_test = dataset0_onehot_encoder.transform(dataset0_y_test).toarray()\n",
    "\n",
    "dataset0_train_dataset = TensorDataset(torch.tensor(dataset0_X_train).float(), torch.from_numpy(dataset0_y_train))\n",
    "dataset0_test_dataset = TensorDataset(torch.tensor(dataset0_X_test).float(), torch.from_numpy(dataset0_y_test))\n",
    "\n",
    "dataset0_train_dataloader = DataLoader(dataset0_train_dataset,\n",
    "                                       batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "dataset0_test_dataloader= DataLoader(dataset0_test_dataset,\n",
    "                                     batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 13961\n",
      "Test dataset size: 6975\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset size:', len(dataset0_train_dataset))\n",
    "print('Test dataset size:', len(dataset0_test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloader):\n",
    "    model.train()\n",
    "    for indexs, (values, labels) in enumerate(train_dataloader):\n",
    "        values = values.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(values)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader):\n",
    "    model.eval()\n",
    "    corrects, total_loss, f1score = 0, 0, 0\n",
    "    for indexs, (values, labels) in enumerate(test_dataloader):\n",
    "        values = values.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(values)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        _, targets = torch.max(labels, 1)\n",
    "        corrects += preds.eq(targets).sum().item()\n",
    "        f1score += f1_score(targets.cpu(), preds.cpu(), average='macro')\n",
    "        \n",
    "    size = len(test_dataloader.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    avg_f1score = 100.0 * f1score / size\n",
    "    return avg_loss, avg_accuracy, avg_f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "lstm 모델을 사용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 작성\n",
    "class model(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, n_layers, num_classes):\n",
    "    super(model, self).__init__()\n",
    "    \"\"\"\n",
    "    코드 작성하세요\n",
    "    \"\"\"\n",
    "    self.n_layers = n_layers\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_classes = num_classes\n",
    "    \n",
    "    self.LSTM = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "    self.fc = nn.Linear(self.hidden_size, self.num_classes)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    코드 작성하세요\n",
    "    \"\"\"\n",
    "    x, _ = self.LSTM(x)\n",
    "    h_t = x[:, -1, :]\n",
    "    output = self.fc(h_t)\n",
    "    \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (LSTM): LSTM(6, 16, batch_first=True)\n",
      "  (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=15, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "net = model(6, 16, 2, 15).to(device)\n",
    "print(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] val loss :  0.01 | val accuracy : 10.85 | val_f1 :  0.02\n",
      "[Epoch: 2] val loss :  0.01 | val accuracy : 17.98 | val_f1 :  0.02\n",
      "[Epoch: 3] val loss :  0.01 | val accuracy : 24.33 | val_f1 :  0.03\n",
      "[Epoch: 4] val loss :  0.01 | val accuracy : 26.41 | val_f1 :  0.03\n",
      "[Epoch: 5] val loss :  0.01 | val accuracy : 26.70 | val_f1 :  0.03\n",
      "[Epoch: 6] val loss :  0.01 | val accuracy : 27.15 | val_f1 :  0.03\n",
      "[Epoch: 7] val loss :  0.01 | val accuracy : 27.53 | val_f1 :  0.03\n",
      "[Epoch: 8] val loss :  0.01 | val accuracy : 28.24 | val_f1 :  0.03\n",
      "[Epoch: 9] val loss :  0.01 | val accuracy : 29.92 | val_f1 :  0.03\n",
      "[Epoch: 10] val loss :  0.01 | val accuracy : 29.18 | val_f1 :  0.03\n",
      "[Epoch: 11] val loss :  0.01 | val accuracy : 30.02 | val_f1 :  0.03\n",
      "[Epoch: 12] val loss :  0.01 | val accuracy : 31.34 | val_f1 :  0.03\n",
      "[Epoch: 13] val loss :  0.01 | val accuracy : 32.57 | val_f1 :  0.04\n",
      "[Epoch: 14] val loss :  0.01 | val accuracy : 33.13 | val_f1 :  0.04\n",
      "[Epoch: 15] val loss :  0.01 | val accuracy : 32.87 | val_f1 :  0.04\n",
      "[Epoch: 16] val loss :  0.01 | val accuracy : 33.45 | val_f1 :  0.04\n",
      "[Epoch: 17] val loss :  0.01 | val accuracy : 34.42 | val_f1 :  0.04\n",
      "[Epoch: 18] val loss :  0.01 | val accuracy : 36.44 | val_f1 :  0.05\n",
      "[Epoch: 19] val loss :  0.01 | val accuracy : 37.30 | val_f1 :  0.05\n",
      "[Epoch: 20] val loss :  0.01 | val accuracy : 38.29 | val_f1 :  0.05\n",
      "[Epoch: 21] val loss :  0.01 | val accuracy : 39.14 | val_f1 :  0.05\n",
      "[Epoch: 22] val loss :  0.01 | val accuracy : 39.66 | val_f1 :  0.05\n",
      "[Epoch: 23] val loss :  0.01 | val accuracy : 40.19 | val_f1 :  0.05\n",
      "[Epoch: 24] val loss :  0.01 | val accuracy : 40.86 | val_f1 :  0.05\n",
      "[Epoch: 25] val loss :  0.01 | val accuracy : 41.22 | val_f1 :  0.05\n",
      "[Epoch: 26] val loss :  0.01 | val accuracy : 41.35 | val_f1 :  0.05\n",
      "[Epoch: 27] val loss :  0.01 | val accuracy : 41.36 | val_f1 :  0.05\n",
      "[Epoch: 28] val loss :  0.01 | val accuracy : 41.69 | val_f1 :  0.05\n",
      "[Epoch: 29] val loss :  0.01 | val accuracy : 42.21 | val_f1 :  0.05\n",
      "[Epoch: 30] val loss :  0.01 | val accuracy : 42.88 | val_f1 :  0.05\n",
      "[Epoch: 31] val loss :  0.01 | val accuracy : 42.47 | val_f1 :  0.05\n",
      "[Epoch: 32] val loss :  0.01 | val accuracy : 42.95 | val_f1 :  0.06\n",
      "[Epoch: 33] val loss :  0.01 | val accuracy : 43.76 | val_f1 :  0.06\n",
      "[Epoch: 34] val loss :  0.01 | val accuracy : 44.86 | val_f1 :  0.06\n",
      "[Epoch: 35] val loss :  0.01 | val accuracy : 43.11 | val_f1 :  0.06\n",
      "[Epoch: 36] val loss :  0.01 | val accuracy : 43.57 | val_f1 :  0.06\n",
      "[Epoch: 37] val loss :  0.01 | val accuracy : 44.93 | val_f1 :  0.06\n",
      "[Epoch: 38] val loss :  0.01 | val accuracy : 44.37 | val_f1 :  0.06\n",
      "[Epoch: 39] val loss :  0.01 | val accuracy : 44.89 | val_f1 :  0.06\n",
      "[Epoch: 40] val loss :  0.01 | val accuracy : 45.02 | val_f1 :  0.06\n",
      "[Epoch: 41] val loss :  0.01 | val accuracy : 44.72 | val_f1 :  0.06\n",
      "[Epoch: 42] val loss :  0.01 | val accuracy : 46.09 | val_f1 :  0.06\n",
      "[Epoch: 43] val loss :  0.01 | val accuracy : 45.28 | val_f1 :  0.06\n",
      "[Epoch: 44] val loss :  0.01 | val accuracy : 46.15 | val_f1 :  0.06\n",
      "[Epoch: 45] val loss :  0.01 | val accuracy : 46.11 | val_f1 :  0.06\n",
      "[Epoch: 46] val loss :  0.01 | val accuracy : 46.28 | val_f1 :  0.06\n",
      "[Epoch: 47] val loss :  0.01 | val accuracy : 46.77 | val_f1 :  0.06\n",
      "[Epoch: 48] val loss :  0.01 | val accuracy : 47.07 | val_f1 :  0.06\n",
      "[Epoch: 49] val loss :  0.01 | val accuracy : 47.07 | val_f1 :  0.07\n",
      "[Epoch: 50] val loss :  0.01 | val accuracy : 46.92 | val_f1 :  0.06\n",
      "[Epoch: 51] val loss :  0.01 | val accuracy : 47.21 | val_f1 :  0.07\n",
      "[Epoch: 52] val loss :  0.01 | val accuracy : 47.10 | val_f1 :  0.07\n",
      "[Epoch: 53] val loss :  0.01 | val accuracy : 47.71 | val_f1 :  0.07\n",
      "[Epoch: 54] val loss :  0.01 | val accuracy : 47.54 | val_f1 :  0.07\n",
      "[Epoch: 55] val loss :  0.01 | val accuracy : 47.35 | val_f1 :  0.07\n",
      "[Epoch: 56] val loss :  0.01 | val accuracy : 47.35 | val_f1 :  0.07\n",
      "[Epoch: 57] val loss :  0.01 | val accuracy : 47.07 | val_f1 :  0.07\n",
      "[Epoch: 58] val loss :  0.01 | val accuracy : 46.71 | val_f1 :  0.07\n",
      "[Epoch: 59] val loss :  0.01 | val accuracy : 48.30 | val_f1 :  0.07\n",
      "[Epoch: 60] val loss :  0.01 | val accuracy : 48.46 | val_f1 :  0.07\n",
      "[Epoch: 61] val loss :  0.01 | val accuracy : 48.39 | val_f1 :  0.07\n",
      "[Epoch: 62] val loss :  0.01 | val accuracy : 47.63 | val_f1 :  0.07\n",
      "[Epoch: 63] val loss :  0.01 | val accuracy : 47.80 | val_f1 :  0.07\n",
      "[Epoch: 64] val loss :  0.01 | val accuracy : 47.87 | val_f1 :  0.07\n",
      "[Epoch: 65] val loss :  0.01 | val accuracy : 47.13 | val_f1 :  0.07\n",
      "[Epoch: 66] val loss :  0.01 | val accuracy : 47.27 | val_f1 :  0.07\n",
      "[Epoch: 67] val loss :  0.01 | val accuracy : 47.66 | val_f1 :  0.07\n",
      "[Epoch: 68] val loss :  0.01 | val accuracy : 48.29 | val_f1 :  0.07\n",
      "[Epoch: 69] val loss :  0.01 | val accuracy : 48.50 | val_f1 :  0.07\n",
      "[Epoch: 70] val loss :  0.01 | val accuracy : 48.10 | val_f1 :  0.07\n",
      "[Epoch: 71] val loss :  0.01 | val accuracy : 47.78 | val_f1 :  0.07\n",
      "[Epoch: 72] val loss :  0.01 | val accuracy : 48.16 | val_f1 :  0.07\n",
      "[Epoch: 73] val loss :  0.01 | val accuracy : 48.39 | val_f1 :  0.07\n",
      "[Epoch: 74] val loss :  0.01 | val accuracy : 49.85 | val_f1 :  0.08\n",
      "[Epoch: 75] val loss :  0.01 | val accuracy : 48.60 | val_f1 :  0.07\n",
      "[Epoch: 76] val loss :  0.01 | val accuracy : 49.61 | val_f1 :  0.08\n",
      "[Epoch: 77] val loss :  0.01 | val accuracy : 50.12 | val_f1 :  0.08\n",
      "[Epoch: 78] val loss :  0.01 | val accuracy : 50.06 | val_f1 :  0.08\n",
      "[Epoch: 79] val loss :  0.01 | val accuracy : 50.74 | val_f1 :  0.08\n",
      "[Epoch: 80] val loss :  0.01 | val accuracy : 51.48 | val_f1 :  0.08\n",
      "[Epoch: 81] val loss :  0.01 | val accuracy : 51.37 | val_f1 :  0.08\n",
      "[Epoch: 82] val loss :  0.01 | val accuracy : 50.92 | val_f1 :  0.08\n",
      "[Epoch: 83] val loss :  0.01 | val accuracy : 50.72 | val_f1 :  0.08\n",
      "[Epoch: 84] val loss :  0.01 | val accuracy : 51.10 | val_f1 :  0.08\n",
      "[Epoch: 85] val loss :  0.01 | val accuracy : 51.20 | val_f1 :  0.08\n",
      "[Epoch: 86] val loss :  0.01 | val accuracy : 52.00 | val_f1 :  0.08\n",
      "[Epoch: 87] val loss :  0.01 | val accuracy : 51.80 | val_f1 :  0.08\n",
      "[Epoch: 88] val loss :  0.01 | val accuracy : 51.56 | val_f1 :  0.08\n",
      "[Epoch: 89] val loss :  0.01 | val accuracy : 51.34 | val_f1 :  0.08\n",
      "[Epoch: 90] val loss :  0.01 | val accuracy : 51.64 | val_f1 :  0.08\n",
      "[Epoch: 91] val loss :  0.01 | val accuracy : 52.16 | val_f1 :  0.08\n",
      "[Epoch: 92] val loss :  0.01 | val accuracy : 52.16 | val_f1 :  0.08\n",
      "[Epoch: 93] val loss :  0.01 | val accuracy : 52.14 | val_f1 :  0.08\n",
      "[Epoch: 94] val loss :  0.01 | val accuracy : 52.16 | val_f1 :  0.08\n",
      "[Epoch: 95] val loss :  0.01 | val accuracy : 52.32 | val_f1 :  0.08\n",
      "[Epoch: 96] val loss :  0.01 | val accuracy : 52.26 | val_f1 :  0.08\n",
      "[Epoch: 97] val loss :  0.01 | val accuracy : 51.86 | val_f1 :  0.08\n",
      "[Epoch: 98] val loss :  0.01 | val accuracy : 51.93 | val_f1 :  0.08\n",
      "[Epoch: 99] val loss :  0.01 | val accuracy : 52.67 | val_f1 :  0.09\n",
      "[Epoch: 100] val loss :  0.01 | val accuracy : 52.87 | val_f1 :  0.09\n",
      "[Epoch: 101] val loss :  0.01 | val accuracy : 52.97 | val_f1 :  0.09\n",
      "[Epoch: 102] val loss :  0.01 | val accuracy : 53.00 | val_f1 :  0.09\n",
      "[Epoch: 103] val loss :  0.01 | val accuracy : 53.88 | val_f1 :  0.09\n",
      "[Epoch: 104] val loss :  0.01 | val accuracy : 53.68 | val_f1 :  0.09\n",
      "[Epoch: 105] val loss :  0.01 | val accuracy : 53.85 | val_f1 :  0.09\n",
      "[Epoch: 106] val loss :  0.01 | val accuracy : 53.66 | val_f1 :  0.09\n",
      "[Epoch: 107] val loss :  0.01 | val accuracy : 54.57 | val_f1 :  0.10\n",
      "[Epoch: 108] val loss :  0.01 | val accuracy : 54.47 | val_f1 :  0.09\n",
      "[Epoch: 109] val loss :  0.01 | val accuracy : 54.41 | val_f1 :  0.09\n",
      "[Epoch: 110] val loss :  0.01 | val accuracy : 54.34 | val_f1 :  0.09\n",
      "[Epoch: 111] val loss :  0.01 | val accuracy : 53.43 | val_f1 :  0.09\n",
      "[Epoch: 112] val loss :  0.01 | val accuracy : 54.42 | val_f1 :  0.09\n",
      "[Epoch: 113] val loss :  0.01 | val accuracy : 54.42 | val_f1 :  0.10\n",
      "[Epoch: 114] val loss :  0.01 | val accuracy : 54.62 | val_f1 :  0.10\n",
      "[Epoch: 115] val loss :  0.01 | val accuracy : 54.55 | val_f1 :  0.10\n",
      "[Epoch: 116] val loss :  0.01 | val accuracy : 54.58 | val_f1 :  0.10\n",
      "[Epoch: 117] val loss :  0.01 | val accuracy : 54.45 | val_f1 :  0.10\n",
      "[Epoch: 118] val loss :  0.01 | val accuracy : 54.54 | val_f1 :  0.10\n",
      "[Epoch: 119] val loss :  0.01 | val accuracy : 54.61 | val_f1 :  0.10\n",
      "[Epoch: 120] val loss :  0.01 | val accuracy : 54.67 | val_f1 :  0.10\n",
      "[Epoch: 121] val loss :  0.01 | val accuracy : 54.65 | val_f1 :  0.10\n",
      "[Epoch: 122] val loss :  0.01 | val accuracy : 54.74 | val_f1 :  0.10\n",
      "[Epoch: 123] val loss :  0.01 | val accuracy : 54.67 | val_f1 :  0.10\n",
      "[Epoch: 124] val loss :  0.01 | val accuracy : 54.92 | val_f1 :  0.10\n",
      "[Epoch: 125] val loss :  0.01 | val accuracy : 54.88 | val_f1 :  0.10\n",
      "[Epoch: 126] val loss :  0.01 | val accuracy : 54.94 | val_f1 :  0.10\n",
      "[Epoch: 127] val loss :  0.01 | val accuracy : 54.98 | val_f1 :  0.10\n",
      "[Epoch: 128] val loss :  0.01 | val accuracy : 52.69 | val_f1 :  0.10\n",
      "[Epoch: 129] val loss :  0.01 | val accuracy : 54.49 | val_f1 :  0.10\n",
      "[Epoch: 130] val loss :  0.01 | val accuracy : 54.31 | val_f1 :  0.10\n",
      "[Epoch: 131] val loss :  0.01 | val accuracy : 54.87 | val_f1 :  0.10\n",
      "[Epoch: 132] val loss :  0.01 | val accuracy : 54.70 | val_f1 :  0.10\n",
      "[Epoch: 133] val loss :  0.01 | val accuracy : 55.05 | val_f1 :  0.10\n",
      "[Epoch: 134] val loss :  0.01 | val accuracy : 54.90 | val_f1 :  0.10\n",
      "[Epoch: 135] val loss :  0.01 | val accuracy : 55.07 | val_f1 :  0.10\n",
      "[Epoch: 136] val loss :  0.01 | val accuracy : 55.24 | val_f1 :  0.10\n",
      "[Epoch: 137] val loss :  0.01 | val accuracy : 55.21 | val_f1 :  0.10\n",
      "[Epoch: 138] val loss :  0.01 | val accuracy : 55.13 | val_f1 :  0.10\n",
      "[Epoch: 139] val loss :  0.01 | val accuracy : 55.25 | val_f1 :  0.10\n",
      "[Epoch: 140] val loss :  0.01 | val accuracy : 55.25 | val_f1 :  0.10\n",
      "[Epoch: 141] val loss :  0.01 | val accuracy : 55.40 | val_f1 :  0.10\n",
      "[Epoch: 142] val loss :  0.01 | val accuracy : 55.50 | val_f1 :  0.10\n",
      "[Epoch: 143] val loss :  0.01 | val accuracy : 55.47 | val_f1 :  0.10\n",
      "[Epoch: 144] val loss :  0.01 | val accuracy : 55.44 | val_f1 :  0.10\n",
      "[Epoch: 145] val loss :  0.01 | val accuracy : 55.50 | val_f1 :  0.10\n",
      "[Epoch: 146] val loss :  0.01 | val accuracy : 55.50 | val_f1 :  0.10\n",
      "[Epoch: 147] val loss :  0.01 | val accuracy : 55.78 | val_f1 :  0.10\n",
      "[Epoch: 148] val loss :  0.01 | val accuracy : 55.68 | val_f1 :  0.10\n",
      "[Epoch: 149] val loss :  0.01 | val accuracy : 55.64 | val_f1 :  0.10\n",
      "[Epoch: 150] val loss :  0.01 | val accuracy : 55.89 | val_f1 :  0.10\n",
      "[Epoch: 151] val loss :  0.01 | val accuracy : 55.84 | val_f1 :  0.10\n",
      "[Epoch: 152] val loss :  0.01 | val accuracy : 55.91 | val_f1 :  0.10\n",
      "[Epoch: 153] val loss :  0.01 | val accuracy : 56.00 | val_f1 :  0.10\n",
      "[Epoch: 154] val loss :  0.01 | val accuracy : 55.96 | val_f1 :  0.10\n",
      "[Epoch: 155] val loss :  0.01 | val accuracy : 55.93 | val_f1 :  0.10\n",
      "[Epoch: 156] val loss :  0.01 | val accuracy : 55.89 | val_f1 :  0.10\n",
      "[Epoch: 157] val loss :  0.01 | val accuracy : 55.96 | val_f1 :  0.10\n",
      "[Epoch: 158] val loss :  0.01 | val accuracy : 56.03 | val_f1 :  0.10\n",
      "[Epoch: 159] val loss :  0.01 | val accuracy : 55.97 | val_f1 :  0.10\n",
      "[Epoch: 160] val loss :  0.01 | val accuracy : 56.01 | val_f1 :  0.10\n",
      "[Epoch: 161] val loss :  0.01 | val accuracy : 56.04 | val_f1 :  0.10\n",
      "[Epoch: 162] val loss :  0.01 | val accuracy : 56.03 | val_f1 :  0.10\n",
      "[Epoch: 163] val loss :  0.01 | val accuracy : 56.11 | val_f1 :  0.10\n",
      "[Epoch: 164] val loss :  0.01 | val accuracy : 56.32 | val_f1 :  0.11\n",
      "[Epoch: 165] val loss :  0.01 | val accuracy : 56.14 | val_f1 :  0.10\n",
      "[Epoch: 166] val loss :  0.01 | val accuracy : 57.29 | val_f1 :  0.12\n",
      "[Epoch: 167] val loss :  0.01 | val accuracy : 57.85 | val_f1 :  0.12\n",
      "[Epoch: 168] val loss :  0.01 | val accuracy : 57.82 | val_f1 :  0.12\n",
      "[Epoch: 169] val loss :  0.01 | val accuracy : 57.69 | val_f1 :  0.12\n",
      "[Epoch: 170] val loss :  0.01 | val accuracy : 57.61 | val_f1 :  0.12\n",
      "[Epoch: 171] val loss :  0.01 | val accuracy : 57.52 | val_f1 :  0.12\n",
      "[Epoch: 172] val loss :  0.01 | val accuracy : 57.48 | val_f1 :  0.12\n",
      "[Epoch: 173] val loss :  0.01 | val accuracy : 56.20 | val_f1 :  0.11\n",
      "[Epoch: 174] val loss :  0.01 | val accuracy : 57.39 | val_f1 :  0.12\n",
      "[Epoch: 175] val loss :  0.01 | val accuracy : 57.56 | val_f1 :  0.12\n",
      "[Epoch: 176] val loss :  0.01 | val accuracy : 57.39 | val_f1 :  0.12\n",
      "[Epoch: 177] val loss :  0.01 | val accuracy : 57.43 | val_f1 :  0.12\n",
      "[Epoch: 178] val loss :  0.01 | val accuracy : 57.55 | val_f1 :  0.12\n",
      "[Epoch: 179] val loss :  0.01 | val accuracy : 57.52 | val_f1 :  0.12\n",
      "[Epoch: 180] val loss :  0.01 | val accuracy : 57.65 | val_f1 :  0.12\n",
      "[Epoch: 181] val loss :  0.01 | val accuracy : 57.61 | val_f1 :  0.12\n",
      "[Epoch: 182] val loss :  0.01 | val accuracy : 57.58 | val_f1 :  0.12\n",
      "[Epoch: 183] val loss :  0.01 | val accuracy : 57.71 | val_f1 :  0.12\n",
      "[Epoch: 184] val loss :  0.01 | val accuracy : 57.66 | val_f1 :  0.12\n",
      "[Epoch: 185] val loss :  0.01 | val accuracy : 57.75 | val_f1 :  0.12\n",
      "[Epoch: 186] val loss :  0.01 | val accuracy : 57.72 | val_f1 :  0.12\n",
      "[Epoch: 187] val loss :  0.01 | val accuracy : 57.68 | val_f1 :  0.12\n",
      "[Epoch: 188] val loss :  0.01 | val accuracy : 57.85 | val_f1 :  0.12\n",
      "[Epoch: 189] val loss :  0.01 | val accuracy : 57.88 | val_f1 :  0.12\n",
      "[Epoch: 190] val loss :  0.01 | val accuracy : 57.75 | val_f1 :  0.12\n",
      "[Epoch: 191] val loss :  0.01 | val accuracy : 57.76 | val_f1 :  0.12\n",
      "[Epoch: 192] val loss :  0.01 | val accuracy : 57.92 | val_f1 :  0.12\n",
      "[Epoch: 193] val loss :  0.01 | val accuracy : 57.89 | val_f1 :  0.12\n",
      "[Epoch: 194] val loss :  0.01 | val accuracy : 57.94 | val_f1 :  0.12\n",
      "[Epoch: 195] val loss :  0.01 | val accuracy : 57.95 | val_f1 :  0.12\n",
      "[Epoch: 196] val loss :  0.01 | val accuracy : 58.01 | val_f1 :  0.12\n",
      "[Epoch: 197] val loss :  0.01 | val accuracy : 58.09 | val_f1 :  0.12\n",
      "[Epoch: 198] val loss :  0.01 | val accuracy : 58.08 | val_f1 :  0.12\n",
      "[Epoch: 199] val loss :  0.01 | val accuracy : 58.04 | val_f1 :  0.12\n",
      "[Epoch: 200] val loss :  0.01 | val accuracy : 58.08 | val_f1 :  0.12\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, epochs+1):\n",
    "    train(net, optimizer, dataset0_train_dataloader)\n",
    "    val_loss, val_corrects, val_f1 = evaluate(net, dataset0_test_dataloader)\n",
    "\n",
    "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f | val_f1 : %5.2f\" % (e, val_loss, val_corrects, val_f1))\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(net.state_dict(), './snapshot/lstmclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU\n",
    "GRU 모델을 사용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, n_layers, num_classes):\n",
    "    super(GRU, self).__init__()\n",
    "    \"\"\"\n",
    "    코드 작성하세요\n",
    "    \"\"\"\n",
    "    self.n_layers = n_layers\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_classes = num_classes\n",
    "    \n",
    "    self.GRU = nn.GRU(input_size=self.input_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "    self.fc = nn.Linear(self.hidden_size, self.num_classes)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    코드 작성하세요\n",
    "    \"\"\"\n",
    "    x, _ = self.GRU(x)\n",
    "    h_t = x[:, -1, :]\n",
    "    output = self.fc(h_t)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (GRU): GRU(6, 16, batch_first=True)\n",
      "  (fc): Linear(in_features=16, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gru_net = GRU(6, 16, 2, 15).to(device)\n",
    "print(gru_net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] val loss :  0.01 | val accuracy :  5.79 | val_f1 :  0.01\n",
      "[Epoch: 2] val loss :  0.01 | val accuracy :  6.04 | val_f1 :  0.01\n",
      "[Epoch: 3] val loss :  0.01 | val accuracy :  7.56 | val_f1 :  0.01\n",
      "[Epoch: 4] val loss :  0.01 | val accuracy :  8.46 | val_f1 :  0.02\n",
      "[Epoch: 5] val loss :  0.01 | val accuracy : 26.29 | val_f1 :  0.03\n",
      "[Epoch: 6] val loss :  0.01 | val accuracy : 28.65 | val_f1 :  0.03\n",
      "[Epoch: 7] val loss :  0.01 | val accuracy : 28.60 | val_f1 :  0.03\n",
      "[Epoch: 8] val loss :  0.01 | val accuracy : 28.82 | val_f1 :  0.03\n",
      "[Epoch: 9] val loss :  0.01 | val accuracy : 29.43 | val_f1 :  0.03\n",
      "[Epoch: 10] val loss :  0.01 | val accuracy : 29.95 | val_f1 :  0.03\n",
      "[Epoch: 11] val loss :  0.01 | val accuracy : 30.67 | val_f1 :  0.03\n",
      "[Epoch: 12] val loss :  0.01 | val accuracy : 31.17 | val_f1 :  0.03\n",
      "[Epoch: 13] val loss :  0.01 | val accuracy : 31.60 | val_f1 :  0.03\n",
      "[Epoch: 14] val loss :  0.01 | val accuracy : 32.04 | val_f1 :  0.03\n",
      "[Epoch: 15] val loss :  0.01 | val accuracy : 32.40 | val_f1 :  0.03\n",
      "[Epoch: 16] val loss :  0.01 | val accuracy : 32.86 | val_f1 :  0.04\n",
      "[Epoch: 17] val loss :  0.01 | val accuracy : 33.16 | val_f1 :  0.04\n",
      "[Epoch: 18] val loss :  0.01 | val accuracy : 32.20 | val_f1 :  0.03\n",
      "[Epoch: 19] val loss :  0.01 | val accuracy : 32.80 | val_f1 :  0.03\n",
      "[Epoch: 20] val loss :  0.01 | val accuracy : 33.65 | val_f1 :  0.03\n",
      "[Epoch: 21] val loss :  0.01 | val accuracy : 34.41 | val_f1 :  0.03\n",
      "[Epoch: 22] val loss :  0.01 | val accuracy : 35.43 | val_f1 :  0.03\n",
      "[Epoch: 23] val loss :  0.01 | val accuracy : 36.57 | val_f1 :  0.04\n",
      "[Epoch: 24] val loss :  0.01 | val accuracy : 37.81 | val_f1 :  0.04\n",
      "[Epoch: 25] val loss :  0.01 | val accuracy : 39.13 | val_f1 :  0.04\n",
      "[Epoch: 26] val loss :  0.01 | val accuracy : 40.80 | val_f1 :  0.04\n",
      "[Epoch: 27] val loss :  0.01 | val accuracy : 42.01 | val_f1 :  0.04\n",
      "[Epoch: 28] val loss :  0.01 | val accuracy : 43.17 | val_f1 :  0.04\n",
      "[Epoch: 29] val loss :  0.01 | val accuracy : 44.26 | val_f1 :  0.05\n",
      "[Epoch: 30] val loss :  0.01 | val accuracy : 44.95 | val_f1 :  0.05\n",
      "[Epoch: 31] val loss :  0.01 | val accuracy : 45.69 | val_f1 :  0.05\n",
      "[Epoch: 32] val loss :  0.01 | val accuracy : 46.02 | val_f1 :  0.05\n",
      "[Epoch: 33] val loss :  0.01 | val accuracy : 46.22 | val_f1 :  0.05\n",
      "[Epoch: 34] val loss :  0.01 | val accuracy : 46.80 | val_f1 :  0.05\n",
      "[Epoch: 35] val loss :  0.01 | val accuracy : 47.14 | val_f1 :  0.05\n",
      "[Epoch: 36] val loss :  0.01 | val accuracy : 47.51 | val_f1 :  0.05\n",
      "[Epoch: 37] val loss :  0.01 | val accuracy : 47.11 | val_f1 :  0.05\n",
      "[Epoch: 38] val loss :  0.01 | val accuracy : 47.80 | val_f1 :  0.06\n",
      "[Epoch: 39] val loss :  0.01 | val accuracy : 47.77 | val_f1 :  0.05\n",
      "[Epoch: 40] val loss :  0.01 | val accuracy : 48.22 | val_f1 :  0.06\n",
      "[Epoch: 41] val loss :  0.01 | val accuracy : 48.59 | val_f1 :  0.06\n",
      "[Epoch: 42] val loss :  0.01 | val accuracy : 49.12 | val_f1 :  0.06\n",
      "[Epoch: 43] val loss :  0.01 | val accuracy : 49.20 | val_f1 :  0.06\n",
      "[Epoch: 44] val loss :  0.01 | val accuracy : 49.46 | val_f1 :  0.06\n",
      "[Epoch: 45] val loss :  0.01 | val accuracy : 50.14 | val_f1 :  0.06\n",
      "[Epoch: 46] val loss :  0.01 | val accuracy : 50.81 | val_f1 :  0.06\n",
      "[Epoch: 47] val loss :  0.01 | val accuracy : 50.78 | val_f1 :  0.06\n",
      "[Epoch: 48] val loss :  0.01 | val accuracy : 51.48 | val_f1 :  0.06\n",
      "[Epoch: 49] val loss :  0.01 | val accuracy : 50.90 | val_f1 :  0.06\n",
      "[Epoch: 50] val loss :  0.01 | val accuracy : 52.50 | val_f1 :  0.06\n",
      "[Epoch: 51] val loss :  0.01 | val accuracy : 53.56 | val_f1 :  0.07\n",
      "[Epoch: 52] val loss :  0.01 | val accuracy : 52.67 | val_f1 :  0.07\n",
      "[Epoch: 53] val loss :  0.01 | val accuracy : 53.02 | val_f1 :  0.07\n",
      "[Epoch: 54] val loss :  0.01 | val accuracy : 53.32 | val_f1 :  0.07\n",
      "[Epoch: 55] val loss :  0.01 | val accuracy : 53.52 | val_f1 :  0.07\n",
      "[Epoch: 56] val loss :  0.01 | val accuracy : 54.70 | val_f1 :  0.07\n",
      "[Epoch: 57] val loss :  0.01 | val accuracy : 54.31 | val_f1 :  0.07\n",
      "[Epoch: 58] val loss :  0.01 | val accuracy : 54.28 | val_f1 :  0.07\n",
      "[Epoch: 59] val loss :  0.01 | val accuracy : 54.45 | val_f1 :  0.07\n",
      "[Epoch: 60] val loss :  0.01 | val accuracy : 54.25 | val_f1 :  0.07\n",
      "[Epoch: 61] val loss :  0.01 | val accuracy : 53.61 | val_f1 :  0.07\n",
      "[Epoch: 62] val loss :  0.01 | val accuracy : 53.81 | val_f1 :  0.07\n",
      "[Epoch: 63] val loss :  0.01 | val accuracy : 53.66 | val_f1 :  0.07\n",
      "[Epoch: 64] val loss :  0.01 | val accuracy : 53.25 | val_f1 :  0.07\n",
      "[Epoch: 65] val loss :  0.01 | val accuracy : 53.20 | val_f1 :  0.07\n",
      "[Epoch: 66] val loss :  0.01 | val accuracy : 53.02 | val_f1 :  0.07\n",
      "[Epoch: 67] val loss :  0.01 | val accuracy : 53.06 | val_f1 :  0.07\n",
      "[Epoch: 68] val loss :  0.01 | val accuracy : 53.32 | val_f1 :  0.07\n",
      "[Epoch: 69] val loss :  0.01 | val accuracy : 53.29 | val_f1 :  0.07\n",
      "[Epoch: 70] val loss :  0.01 | val accuracy : 53.52 | val_f1 :  0.07\n",
      "[Epoch: 71] val loss :  0.01 | val accuracy : 53.39 | val_f1 :  0.07\n",
      "[Epoch: 72] val loss :  0.01 | val accuracy : 53.62 | val_f1 :  0.08\n",
      "[Epoch: 73] val loss :  0.01 | val accuracy : 53.46 | val_f1 :  0.08\n",
      "[Epoch: 74] val loss :  0.01 | val accuracy : 52.87 | val_f1 :  0.08\n",
      "[Epoch: 75] val loss :  0.01 | val accuracy : 53.99 | val_f1 :  0.08\n",
      "[Epoch: 76] val loss :  0.01 | val accuracy : 54.01 | val_f1 :  0.08\n",
      "[Epoch: 77] val loss :  0.01 | val accuracy : 53.56 | val_f1 :  0.08\n",
      "[Epoch: 78] val loss :  0.01 | val accuracy : 53.91 | val_f1 :  0.08\n",
      "[Epoch: 79] val loss :  0.01 | val accuracy : 53.59 | val_f1 :  0.08\n",
      "[Epoch: 80] val loss :  0.01 | val accuracy : 53.41 | val_f1 :  0.08\n",
      "[Epoch: 81] val loss :  0.01 | val accuracy : 53.92 | val_f1 :  0.08\n",
      "[Epoch: 82] val loss :  0.01 | val accuracy : 54.44 | val_f1 :  0.08\n",
      "[Epoch: 83] val loss :  0.01 | val accuracy : 54.65 | val_f1 :  0.08\n",
      "[Epoch: 84] val loss :  0.01 | val accuracy : 54.47 | val_f1 :  0.08\n",
      "[Epoch: 85] val loss :  0.01 | val accuracy : 54.27 | val_f1 :  0.08\n",
      "[Epoch: 86] val loss :  0.01 | val accuracy : 55.27 | val_f1 :  0.08\n",
      "[Epoch: 87] val loss :  0.01 | val accuracy : 53.94 | val_f1 :  0.08\n",
      "[Epoch: 88] val loss :  0.01 | val accuracy : 55.37 | val_f1 :  0.08\n",
      "[Epoch: 89] val loss :  0.01 | val accuracy : 55.27 | val_f1 :  0.08\n",
      "[Epoch: 90] val loss :  0.01 | val accuracy : 54.54 | val_f1 :  0.08\n",
      "[Epoch: 91] val loss :  0.01 | val accuracy : 56.93 | val_f1 :  0.09\n",
      "[Epoch: 92] val loss :  0.01 | val accuracy : 56.92 | val_f1 :  0.09\n",
      "[Epoch: 93] val loss :  0.01 | val accuracy : 55.93 | val_f1 :  0.09\n",
      "[Epoch: 94] val loss :  0.01 | val accuracy : 55.43 | val_f1 :  0.09\n",
      "[Epoch: 95] val loss :  0.01 | val accuracy : 55.14 | val_f1 :  0.09\n",
      "[Epoch: 96] val loss :  0.01 | val accuracy : 55.89 | val_f1 :  0.09\n",
      "[Epoch: 97] val loss :  0.01 | val accuracy : 54.49 | val_f1 :  0.09\n",
      "[Epoch: 98] val loss :  0.01 | val accuracy : 53.66 | val_f1 :  0.08\n",
      "[Epoch: 99] val loss :  0.01 | val accuracy : 55.43 | val_f1 :  0.09\n",
      "[Epoch: 100] val loss :  0.01 | val accuracy : 54.64 | val_f1 :  0.09\n",
      "[Epoch: 101] val loss :  0.01 | val accuracy : 55.66 | val_f1 :  0.09\n",
      "[Epoch: 102] val loss :  0.01 | val accuracy : 55.78 | val_f1 :  0.09\n",
      "[Epoch: 103] val loss :  0.01 | val accuracy : 55.74 | val_f1 :  0.09\n",
      "[Epoch: 104] val loss :  0.01 | val accuracy : 55.51 | val_f1 :  0.09\n",
      "[Epoch: 105] val loss :  0.01 | val accuracy : 56.77 | val_f1 :  0.09\n",
      "[Epoch: 106] val loss :  0.01 | val accuracy : 56.69 | val_f1 :  0.09\n",
      "[Epoch: 107] val loss :  0.01 | val accuracy : 56.54 | val_f1 :  0.09\n",
      "[Epoch: 108] val loss :  0.01 | val accuracy : 56.17 | val_f1 :  0.09\n",
      "[Epoch: 109] val loss :  0.01 | val accuracy : 56.50 | val_f1 :  0.09\n",
      "[Epoch: 110] val loss :  0.01 | val accuracy : 56.83 | val_f1 :  0.09\n",
      "[Epoch: 111] val loss :  0.01 | val accuracy : 56.65 | val_f1 :  0.09\n",
      "[Epoch: 112] val loss :  0.01 | val accuracy : 56.42 | val_f1 :  0.09\n",
      "[Epoch: 113] val loss :  0.01 | val accuracy : 56.63 | val_f1 :  0.09\n",
      "[Epoch: 114] val loss :  0.00 | val accuracy : 58.27 | val_f1 :  0.10\n",
      "[Epoch: 115] val loss :  0.01 | val accuracy : 57.38 | val_f1 :  0.10\n",
      "[Epoch: 116] val loss :  0.00 | val accuracy : 58.44 | val_f1 :  0.10\n",
      "[Epoch: 117] val loss :  0.00 | val accuracy : 58.78 | val_f1 :  0.11\n",
      "[Epoch: 118] val loss :  0.00 | val accuracy : 59.58 | val_f1 :  0.11\n",
      "[Epoch: 119] val loss :  0.00 | val accuracy : 59.31 | val_f1 :  0.11\n",
      "[Epoch: 120] val loss :  0.00 | val accuracy : 59.76 | val_f1 :  0.11\n",
      "[Epoch: 121] val loss :  0.00 | val accuracy : 59.46 | val_f1 :  0.11\n",
      "[Epoch: 122] val loss :  0.00 | val accuracy : 59.68 | val_f1 :  0.11\n",
      "[Epoch: 123] val loss :  0.00 | val accuracy : 60.27 | val_f1 :  0.11\n",
      "[Epoch: 124] val loss :  0.00 | val accuracy : 60.32 | val_f1 :  0.11\n",
      "[Epoch: 125] val loss :  0.00 | val accuracy : 60.24 | val_f1 :  0.11\n",
      "[Epoch: 126] val loss :  0.00 | val accuracy : 60.52 | val_f1 :  0.11\n",
      "[Epoch: 127] val loss :  0.00 | val accuracy : 60.70 | val_f1 :  0.11\n",
      "[Epoch: 128] val loss :  0.00 | val accuracy : 60.93 | val_f1 :  0.11\n",
      "[Epoch: 129] val loss :  0.00 | val accuracy : 60.82 | val_f1 :  0.11\n",
      "[Epoch: 130] val loss :  0.00 | val accuracy : 61.15 | val_f1 :  0.11\n",
      "[Epoch: 131] val loss :  0.00 | val accuracy : 61.12 | val_f1 :  0.12\n",
      "[Epoch: 132] val loss :  0.00 | val accuracy : 61.02 | val_f1 :  0.12\n",
      "[Epoch: 133] val loss :  0.00 | val accuracy : 61.15 | val_f1 :  0.12\n",
      "[Epoch: 134] val loss :  0.00 | val accuracy : 61.33 | val_f1 :  0.12\n",
      "[Epoch: 135] val loss :  0.00 | val accuracy : 61.45 | val_f1 :  0.12\n",
      "[Epoch: 136] val loss :  0.00 | val accuracy : 61.46 | val_f1 :  0.12\n",
      "[Epoch: 137] val loss :  0.00 | val accuracy : 61.69 | val_f1 :  0.12\n",
      "[Epoch: 138] val loss :  0.00 | val accuracy : 61.42 | val_f1 :  0.12\n",
      "[Epoch: 139] val loss :  0.00 | val accuracy : 61.82 | val_f1 :  0.12\n",
      "[Epoch: 140] val loss :  0.00 | val accuracy : 61.95 | val_f1 :  0.12\n",
      "[Epoch: 141] val loss :  0.00 | val accuracy : 61.63 | val_f1 :  0.12\n",
      "[Epoch: 142] val loss :  0.00 | val accuracy : 61.79 | val_f1 :  0.12\n",
      "[Epoch: 143] val loss :  0.00 | val accuracy : 61.78 | val_f1 :  0.12\n",
      "[Epoch: 144] val loss :  0.00 | val accuracy : 62.09 | val_f1 :  0.12\n",
      "[Epoch: 145] val loss :  0.00 | val accuracy : 61.62 | val_f1 :  0.12\n",
      "[Epoch: 146] val loss :  0.00 | val accuracy : 61.35 | val_f1 :  0.12\n",
      "[Epoch: 147] val loss :  0.00 | val accuracy : 61.69 | val_f1 :  0.12\n",
      "[Epoch: 148] val loss :  0.00 | val accuracy : 61.43 | val_f1 :  0.12\n",
      "[Epoch: 149] val loss :  0.00 | val accuracy : 61.79 | val_f1 :  0.12\n",
      "[Epoch: 150] val loss :  0.00 | val accuracy : 61.82 | val_f1 :  0.12\n",
      "[Epoch: 151] val loss :  0.00 | val accuracy : 62.14 | val_f1 :  0.12\n",
      "[Epoch: 152] val loss :  0.00 | val accuracy : 61.69 | val_f1 :  0.12\n",
      "[Epoch: 153] val loss :  0.00 | val accuracy : 61.94 | val_f1 :  0.12\n",
      "[Epoch: 154] val loss :  0.00 | val accuracy : 61.79 | val_f1 :  0.13\n",
      "[Epoch: 155] val loss :  0.00 | val accuracy : 62.34 | val_f1 :  0.13\n",
      "[Epoch: 156] val loss :  0.00 | val accuracy : 62.88 | val_f1 :  0.13\n",
      "[Epoch: 157] val loss :  0.00 | val accuracy : 62.24 | val_f1 :  0.13\n",
      "[Epoch: 158] val loss :  0.00 | val accuracy : 63.15 | val_f1 :  0.13\n",
      "[Epoch: 159] val loss :  0.00 | val accuracy : 63.43 | val_f1 :  0.13\n",
      "[Epoch: 160] val loss :  0.00 | val accuracy : 63.58 | val_f1 :  0.13\n",
      "[Epoch: 161] val loss :  0.00 | val accuracy : 63.34 | val_f1 :  0.13\n",
      "[Epoch: 162] val loss :  0.00 | val accuracy : 63.96 | val_f1 :  0.13\n",
      "[Epoch: 163] val loss :  0.00 | val accuracy : 63.96 | val_f1 :  0.13\n",
      "[Epoch: 164] val loss :  0.00 | val accuracy : 63.46 | val_f1 :  0.13\n",
      "[Epoch: 165] val loss :  0.00 | val accuracy : 63.61 | val_f1 :  0.13\n",
      "[Epoch: 166] val loss :  0.00 | val accuracy : 63.63 | val_f1 :  0.13\n",
      "[Epoch: 167] val loss :  0.00 | val accuracy : 63.90 | val_f1 :  0.13\n",
      "[Epoch: 168] val loss :  0.00 | val accuracy : 63.31 | val_f1 :  0.13\n",
      "[Epoch: 169] val loss :  0.00 | val accuracy : 63.74 | val_f1 :  0.13\n",
      "[Epoch: 170] val loss :  0.00 | val accuracy : 63.96 | val_f1 :  0.13\n",
      "[Epoch: 171] val loss :  0.00 | val accuracy : 63.58 | val_f1 :  0.13\n",
      "[Epoch: 172] val loss :  0.00 | val accuracy : 63.61 | val_f1 :  0.13\n",
      "[Epoch: 173] val loss :  0.00 | val accuracy : 63.60 | val_f1 :  0.13\n",
      "[Epoch: 174] val loss :  0.00 | val accuracy : 63.71 | val_f1 :  0.13\n",
      "[Epoch: 175] val loss :  0.00 | val accuracy : 63.68 | val_f1 :  0.13\n",
      "[Epoch: 176] val loss :  0.00 | val accuracy : 64.19 | val_f1 :  0.13\n",
      "[Epoch: 177] val loss :  0.00 | val accuracy : 63.97 | val_f1 :  0.13\n",
      "[Epoch: 178] val loss :  0.00 | val accuracy : 63.83 | val_f1 :  0.13\n",
      "[Epoch: 179] val loss :  0.00 | val accuracy : 63.84 | val_f1 :  0.13\n",
      "[Epoch: 180] val loss :  0.00 | val accuracy : 63.63 | val_f1 :  0.13\n",
      "[Epoch: 181] val loss :  0.00 | val accuracy : 64.01 | val_f1 :  0.13\n",
      "[Epoch: 182] val loss :  0.00 | val accuracy : 64.10 | val_f1 :  0.13\n",
      "[Epoch: 183] val loss :  0.00 | val accuracy : 64.85 | val_f1 :  0.13\n",
      "[Epoch: 184] val loss :  0.00 | val accuracy : 64.42 | val_f1 :  0.13\n",
      "[Epoch: 185] val loss :  0.00 | val accuracy : 63.99 | val_f1 :  0.13\n",
      "[Epoch: 186] val loss :  0.00 | val accuracy : 63.80 | val_f1 :  0.13\n",
      "[Epoch: 187] val loss :  0.00 | val accuracy : 63.94 | val_f1 :  0.13\n",
      "[Epoch: 188] val loss :  0.00 | val accuracy : 64.09 | val_f1 :  0.14\n",
      "[Epoch: 189] val loss :  0.00 | val accuracy : 64.09 | val_f1 :  0.13\n",
      "[Epoch: 190] val loss :  0.00 | val accuracy : 64.16 | val_f1 :  0.14\n",
      "[Epoch: 191] val loss :  0.00 | val accuracy : 64.10 | val_f1 :  0.13\n",
      "[Epoch: 192] val loss :  0.00 | val accuracy : 63.91 | val_f1 :  0.14\n",
      "[Epoch: 193] val loss :  0.00 | val accuracy : 64.47 | val_f1 :  0.14\n",
      "[Epoch: 194] val loss :  0.00 | val accuracy : 64.13 | val_f1 :  0.14\n",
      "[Epoch: 195] val loss :  0.00 | val accuracy : 63.94 | val_f1 :  0.13\n",
      "[Epoch: 196] val loss :  0.00 | val accuracy : 63.80 | val_f1 :  0.13\n",
      "[Epoch: 197] val loss :  0.00 | val accuracy : 63.99 | val_f1 :  0.13\n",
      "[Epoch: 198] val loss :  0.00 | val accuracy : 64.17 | val_f1 :  0.14\n",
      "[Epoch: 199] val loss :  0.00 | val accuracy : 64.04 | val_f1 :  0.13\n",
      "[Epoch: 200] val loss :  0.00 | val accuracy : 64.13 | val_f1 :  0.13\n",
      "[Epoch: 201] val loss :  0.00 | val accuracy : 63.61 | val_f1 :  0.13\n",
      "[Epoch: 202] val loss :  0.00 | val accuracy : 64.44 | val_f1 :  0.14\n",
      "[Epoch: 203] val loss :  0.00 | val accuracy : 64.29 | val_f1 :  0.13\n",
      "[Epoch: 204] val loss :  0.00 | val accuracy : 64.17 | val_f1 :  0.14\n",
      "[Epoch: 205] val loss :  0.00 | val accuracy : 64.47 | val_f1 :  0.14\n",
      "[Epoch: 206] val loss :  0.00 | val accuracy : 64.27 | val_f1 :  0.14\n",
      "[Epoch: 207] val loss :  0.00 | val accuracy : 64.44 | val_f1 :  0.14\n",
      "[Epoch: 208] val loss :  0.00 | val accuracy : 64.42 | val_f1 :  0.14\n",
      "[Epoch: 209] val loss :  0.00 | val accuracy : 64.76 | val_f1 :  0.14\n",
      "[Epoch: 210] val loss :  0.00 | val accuracy : 64.99 | val_f1 :  0.14\n",
      "[Epoch: 211] val loss :  0.00 | val accuracy : 64.22 | val_f1 :  0.13\n",
      "[Epoch: 212] val loss :  0.00 | val accuracy : 64.47 | val_f1 :  0.14\n",
      "[Epoch: 213] val loss :  0.00 | val accuracy : 64.34 | val_f1 :  0.14\n",
      "[Epoch: 214] val loss :  0.00 | val accuracy : 64.32 | val_f1 :  0.13\n",
      "[Epoch: 215] val loss :  0.00 | val accuracy : 65.25 | val_f1 :  0.14\n",
      "[Epoch: 216] val loss :  0.00 | val accuracy : 64.49 | val_f1 :  0.14\n",
      "[Epoch: 217] val loss :  0.00 | val accuracy : 64.27 | val_f1 :  0.14\n",
      "[Epoch: 218] val loss :  0.00 | val accuracy : 64.34 | val_f1 :  0.14\n",
      "[Epoch: 219] val loss :  0.00 | val accuracy : 63.80 | val_f1 :  0.13\n",
      "[Epoch: 220] val loss :  0.00 | val accuracy : 64.30 | val_f1 :  0.14\n",
      "[Epoch: 221] val loss :  0.00 | val accuracy : 64.36 | val_f1 :  0.14\n",
      "[Epoch: 222] val loss :  0.00 | val accuracy : 64.34 | val_f1 :  0.14\n",
      "[Epoch: 223] val loss :  0.00 | val accuracy : 64.09 | val_f1 :  0.14\n",
      "[Epoch: 224] val loss :  0.00 | val accuracy : 64.13 | val_f1 :  0.14\n",
      "[Epoch: 225] val loss :  0.00 | val accuracy : 64.23 | val_f1 :  0.14\n",
      "[Epoch: 226] val loss :  0.00 | val accuracy : 64.04 | val_f1 :  0.14\n",
      "[Epoch: 227] val loss :  0.00 | val accuracy : 64.22 | val_f1 :  0.14\n",
      "[Epoch: 228] val loss :  0.00 | val accuracy : 64.56 | val_f1 :  0.14\n",
      "[Epoch: 229] val loss :  0.00 | val accuracy : 64.44 | val_f1 :  0.14\n",
      "[Epoch: 230] val loss :  0.00 | val accuracy : 64.33 | val_f1 :  0.14\n",
      "[Epoch: 231] val loss :  0.00 | val accuracy : 64.09 | val_f1 :  0.14\n",
      "[Epoch: 232] val loss :  0.00 | val accuracy : 64.22 | val_f1 :  0.14\n",
      "[Epoch: 233] val loss :  0.00 | val accuracy : 63.84 | val_f1 :  0.14\n",
      "[Epoch: 234] val loss :  0.00 | val accuracy : 64.37 | val_f1 :  0.14\n",
      "[Epoch: 235] val loss :  0.00 | val accuracy : 64.44 | val_f1 :  0.14\n",
      "[Epoch: 236] val loss :  0.00 | val accuracy : 64.16 | val_f1 :  0.14\n",
      "[Epoch: 237] val loss :  0.00 | val accuracy : 64.10 | val_f1 :  0.14\n",
      "[Epoch: 238] val loss :  0.00 | val accuracy : 62.98 | val_f1 :  0.14\n",
      "[Epoch: 239] val loss :  0.00 | val accuracy : 64.26 | val_f1 :  0.14\n",
      "[Epoch: 240] val loss :  0.00 | val accuracy : 64.01 | val_f1 :  0.14\n",
      "[Epoch: 241] val loss :  0.00 | val accuracy : 63.57 | val_f1 :  0.14\n",
      "[Epoch: 242] val loss :  0.00 | val accuracy : 63.87 | val_f1 :  0.14\n",
      "[Epoch: 243] val loss :  0.00 | val accuracy : 63.84 | val_f1 :  0.14\n",
      "[Epoch: 244] val loss :  0.00 | val accuracy : 64.83 | val_f1 :  0.14\n",
      "[Epoch: 245] val loss :  0.00 | val accuracy : 64.60 | val_f1 :  0.14\n",
      "[Epoch: 246] val loss :  0.00 | val accuracy : 64.00 | val_f1 :  0.14\n",
      "[Epoch: 247] val loss :  0.00 | val accuracy : 63.96 | val_f1 :  0.14\n",
      "[Epoch: 248] val loss :  0.00 | val accuracy : 64.10 | val_f1 :  0.14\n",
      "[Epoch: 249] val loss :  0.00 | val accuracy : 64.00 | val_f1 :  0.14\n",
      "[Epoch: 250] val loss :  0.00 | val accuracy : 64.26 | val_f1 :  0.14\n",
      "[Epoch: 251] val loss :  0.00 | val accuracy : 63.96 | val_f1 :  0.14\n",
      "[Epoch: 252] val loss :  0.00 | val accuracy : 63.81 | val_f1 :  0.14\n",
      "[Epoch: 253] val loss :  0.00 | val accuracy : 64.39 | val_f1 :  0.14\n",
      "[Epoch: 254] val loss :  0.00 | val accuracy : 64.24 | val_f1 :  0.14\n",
      "[Epoch: 255] val loss :  0.00 | val accuracy : 64.23 | val_f1 :  0.14\n",
      "[Epoch: 256] val loss :  0.00 | val accuracy : 64.65 | val_f1 :  0.14\n",
      "[Epoch: 257] val loss :  0.00 | val accuracy : 64.13 | val_f1 :  0.14\n",
      "[Epoch: 258] val loss :  0.00 | val accuracy : 64.42 | val_f1 :  0.14\n",
      "[Epoch: 259] val loss :  0.00 | val accuracy : 64.39 | val_f1 :  0.14\n",
      "[Epoch: 260] val loss :  0.00 | val accuracy : 64.54 | val_f1 :  0.14\n",
      "[Epoch: 261] val loss :  0.00 | val accuracy : 64.30 | val_f1 :  0.14\n",
      "[Epoch: 262] val loss :  0.00 | val accuracy : 64.89 | val_f1 :  0.14\n",
      "[Epoch: 263] val loss :  0.00 | val accuracy : 64.33 | val_f1 :  0.14\n",
      "[Epoch: 264] val loss :  0.00 | val accuracy : 63.61 | val_f1 :  0.14\n",
      "[Epoch: 265] val loss :  0.00 | val accuracy : 64.23 | val_f1 :  0.14\n",
      "[Epoch: 266] val loss :  0.00 | val accuracy : 64.26 | val_f1 :  0.14\n",
      "[Epoch: 267] val loss :  0.00 | val accuracy : 64.44 | val_f1 :  0.14\n",
      "[Epoch: 268] val loss :  0.00 | val accuracy : 64.34 | val_f1 :  0.14\n",
      "[Epoch: 269] val loss :  0.00 | val accuracy : 64.20 | val_f1 :  0.14\n",
      "[Epoch: 270] val loss :  0.00 | val accuracy : 64.54 | val_f1 :  0.14\n",
      "[Epoch: 271] val loss :  0.00 | val accuracy : 64.42 | val_f1 :  0.14\n",
      "[Epoch: 272] val loss :  0.00 | val accuracy : 64.03 | val_f1 :  0.14\n",
      "[Epoch: 273] val loss :  0.00 | val accuracy : 64.62 | val_f1 :  0.14\n",
      "[Epoch: 274] val loss :  0.00 | val accuracy : 64.95 | val_f1 :  0.14\n",
      "[Epoch: 275] val loss :  0.00 | val accuracy : 64.62 | val_f1 :  0.14\n",
      "[Epoch: 276] val loss :  0.00 | val accuracy : 64.72 | val_f1 :  0.15\n",
      "[Epoch: 277] val loss :  0.00 | val accuracy : 64.79 | val_f1 :  0.15\n",
      "[Epoch: 278] val loss :  0.00 | val accuracy : 63.70 | val_f1 :  0.14\n",
      "[Epoch: 279] val loss :  0.00 | val accuracy : 64.14 | val_f1 :  0.14\n",
      "[Epoch: 280] val loss :  0.00 | val accuracy : 64.10 | val_f1 :  0.14\n",
      "[Epoch: 281] val loss :  0.00 | val accuracy : 64.07 | val_f1 :  0.14\n",
      "[Epoch: 282] val loss :  0.00 | val accuracy : 64.14 | val_f1 :  0.14\n",
      "[Epoch: 283] val loss :  0.00 | val accuracy : 63.38 | val_f1 :  0.14\n",
      "[Epoch: 284] val loss :  0.00 | val accuracy : 64.60 | val_f1 :  0.15\n",
      "[Epoch: 285] val loss :  0.00 | val accuracy : 64.79 | val_f1 :  0.15\n",
      "[Epoch: 286] val loss :  0.00 | val accuracy : 64.24 | val_f1 :  0.14\n",
      "[Epoch: 287] val loss :  0.00 | val accuracy : 64.52 | val_f1 :  0.15\n",
      "[Epoch: 288] val loss :  0.00 | val accuracy : 64.23 | val_f1 :  0.14\n",
      "[Epoch: 289] val loss :  0.00 | val accuracy : 64.57 | val_f1 :  0.15\n",
      "[Epoch: 290] val loss :  0.00 | val accuracy : 63.63 | val_f1 :  0.14\n",
      "[Epoch: 291] val loss :  0.00 | val accuracy : 64.30 | val_f1 :  0.14\n",
      "[Epoch: 292] val loss :  0.00 | val accuracy : 64.17 | val_f1 :  0.15\n",
      "[Epoch: 293] val loss :  0.00 | val accuracy : 64.32 | val_f1 :  0.15\n",
      "[Epoch: 294] val loss :  0.00 | val accuracy : 64.04 | val_f1 :  0.15\n",
      "[Epoch: 295] val loss :  0.00 | val accuracy : 63.86 | val_f1 :  0.14\n",
      "[Epoch: 296] val loss :  0.00 | val accuracy : 64.06 | val_f1 :  0.14\n",
      "[Epoch: 297] val loss :  0.00 | val accuracy : 64.63 | val_f1 :  0.15\n",
      "[Epoch: 298] val loss :  0.00 | val accuracy : 64.14 | val_f1 :  0.15\n",
      "[Epoch: 299] val loss :  0.00 | val accuracy : 64.26 | val_f1 :  0.15\n",
      "[Epoch: 300] val loss :  0.00 | val accuracy : 64.53 | val_f1 :  0.15\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, epochs+1):\n",
    "    train(gru_net, optimizer, dataset0_train_dataloader)\n",
    "    val_loss, val_corrects, val_f1 = evaluate(gru_net, dataset0_test_dataloader)\n",
    "\n",
    "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f | val_f1 : %5.2f\" % (e, val_loss, val_corrects, val_f1))\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(gru_net.state_dict(), './snapshot/gruclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# dataset1's training datasets & dataloader\n",
    "dataset1_X_train, dataset1_y_train = create_dataset(dataset1_train_dir)\n",
    "dataset1_y_train = dataset1_onehot_encoder.transform(dataset1_y_train).toarray()\n",
    "\n",
    "dataset1_train_dataset = TensorDataset(torch.tensor(dataset1_X_train).float(), torch.from_numpy(dataset1_y_train))\n",
    "dataset1_train_dataloader = DataLoader(dataset1_train_dataset,\n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 적용\n",
    "200 epoch시 성능이 더 좋았던 GRU 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GRU(6, 16, 2, 15).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "checkpoint = torch.load('./snapshot/gruclassification.pt')\n",
    "net.load_state_dict(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (GRU): GRU(6, 16, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc = nn.Linear(16, 11)\n",
    "net = net.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloader):\n",
    "    model.train()\n",
    "    for indexs, (values, labels) in enumerate(train_dataloader):\n",
    "        values = values.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(values)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = None\n",
    "for epoch in range(1, epochs//2 + 1):\n",
    "    train(net, optimizer, dataset1_train_dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "dataset1_test_X = []\n",
    "test_list = os.listdir(dataset1_test_dir)\n",
    "for f in test_list:\n",
    "  temp = pd.read_csv(dataset1_test_dir + f)\n",
    "  dataset1_test_X.append(torch.from_numpy(temp.values))\n",
    "\n",
    "dataset1_test_X = pad_sequence(dataset1_test_X, batch_first=True)\n",
    "print(dataset1_test_X.dtype)\n",
    "dataset1_test_dataset = TensorDataset(dataset1_test_X)\n",
    "dataset1_test_dataloader = DataLoader(dataset1_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['103.csv',\n",
       " '119.csv',\n",
       " '162.csv',\n",
       " '172.csv',\n",
       " '178.csv',\n",
       " '179.csv',\n",
       " '188.csv',\n",
       " '191.csv',\n",
       " '201.csv',\n",
       " '230.csv',\n",
       " '245.csv',\n",
       " '265.csv',\n",
       " '276.csv',\n",
       " '281.csv',\n",
       " '298.csv',\n",
       " '300.csv',\n",
       " '308.csv',\n",
       " '328.csv',\n",
       " '342.csv',\n",
       " '344.csv',\n",
       " '345.csv',\n",
       " '346.csv',\n",
       " '347.csv',\n",
       " '348.csv',\n",
       " '349.csv',\n",
       " '350.csv',\n",
       " '351.csv',\n",
       " '352.csv',\n",
       " '363.csv',\n",
       " '376.csv',\n",
       " '38.csv',\n",
       " '400.csv',\n",
       " '405.csv',\n",
       " '406.csv',\n",
       " '414.csv',\n",
       " '422.csv',\n",
       " '423.csv',\n",
       " '425.csv',\n",
       " '427.csv',\n",
       " '430.csv',\n",
       " '433.csv',\n",
       " '441.csv',\n",
       " '445.csv',\n",
       " '449.csv',\n",
       " '46.csv',\n",
       " '463.csv',\n",
       " '470.csv',\n",
       " '474.csv',\n",
       " '475.csv',\n",
       " '478.csv',\n",
       " '487.csv',\n",
       " '489.csv',\n",
       " '491.csv',\n",
       " '496.csv',\n",
       " '507.csv',\n",
       " '508.csv',\n",
       " '509.csv',\n",
       " '510.csv',\n",
       " '511.csv',\n",
       " '512.csv',\n",
       " '513.csv',\n",
       " '514.csv',\n",
       " '515.csv',\n",
       " '516.csv',\n",
       " '517.csv',\n",
       " '518.csv',\n",
       " '519.csv',\n",
       " '520.csv',\n",
       " '521.csv',\n",
       " '522.csv',\n",
       " '523.csv',\n",
       " '524.csv',\n",
       " '525.csv',\n",
       " '526.csv',\n",
       " '527.csv',\n",
       " '528.csv',\n",
       " '529.csv',\n",
       " '530.csv',\n",
       " '534.csv',\n",
       " '536.csv',\n",
       " '539.csv',\n",
       " '545.csv',\n",
       " '550.csv',\n",
       " '559.csv',\n",
       " '574.csv',\n",
       " '577.csv',\n",
       " '588.csv',\n",
       " '591.csv',\n",
       " '596.csv',\n",
       " '610.csv',\n",
       " '622.csv',\n",
       " '624.csv',\n",
       " '626.csv',\n",
       " '65.csv',\n",
       " '661.csv',\n",
       " '665.csv',\n",
       " '667.csv',\n",
       " '675.csv',\n",
       " '679.csv',\n",
       " '682.csv',\n",
       " '686.csv',\n",
       " '691.csv',\n",
       " '692.csv',\n",
       " '697.csv',\n",
       " '698.csv',\n",
       " '699.csv',\n",
       " '700.csv',\n",
       " '701.csv',\n",
       " '702.csv',\n",
       " '703.csv',\n",
       " '704.csv',\n",
       " '705.csv',\n",
       " '706.csv',\n",
       " '707.csv',\n",
       " '708.csv',\n",
       " '709.csv',\n",
       " '710.csv',\n",
       " '711.csv',\n",
       " '712.csv',\n",
       " '713.csv',\n",
       " '714.csv',\n",
       " '715.csv',\n",
       " '716.csv',\n",
       " '717.csv',\n",
       " '718.csv',\n",
       " '719.csv',\n",
       " '720.csv',\n",
       " '721.csv',\n",
       " '722.csv',\n",
       " '723.csv',\n",
       " '724.csv',\n",
       " '725.csv',\n",
       " '726.csv',\n",
       " '727.csv',\n",
       " '728.csv',\n",
       " '729.csv',\n",
       " '730.csv',\n",
       " '731.csv',\n",
       " '732.csv',\n",
       " '733.csv',\n",
       " '735.csv',\n",
       " '737.csv',\n",
       " '738.csv',\n",
       " '742.csv',\n",
       " '744.csv',\n",
       " '745.csv',\n",
       " '746.csv',\n",
       " '748.csv',\n",
       " '750.csv',\n",
       " '752.csv',\n",
       " '753.csv',\n",
       " '754.csv',\n",
       " '755.csv',\n",
       " '756.csv',\n",
       " '757.csv',\n",
       " '760.csv',\n",
       " '762.csv',\n",
       " '763.csv',\n",
       " '764.csv',\n",
       " '765.csv',\n",
       " '767.csv',\n",
       " '771.csv',\n",
       " '774.csv',\n",
       " '775.csv',\n",
       " '776.csv',\n",
       " '777.csv',\n",
       " '779.csv',\n",
       " '780.csv',\n",
       " '782.csv',\n",
       " '783.csv',\n",
       " '784.csv',\n",
       " '785.csv',\n",
       " '787.csv',\n",
       " '788.csv',\n",
       " '789.csv',\n",
       " '79.csv',\n",
       " '790.csv',\n",
       " '791.csv',\n",
       " '794.csv',\n",
       " '796.csv',\n",
       " '799.csv',\n",
       " '803.csv',\n",
       " '804.csv',\n",
       " '807.csv',\n",
       " '808.csv',\n",
       " '817.csv',\n",
       " '823.csv',\n",
       " '824.csv',\n",
       " '831.csv',\n",
       " '834.csv',\n",
       " '836.csv',\n",
       " '840.csv',\n",
       " '844.csv',\n",
       " '845.csv',\n",
       " '846.csv',\n",
       " '848.csv',\n",
       " '849.csv',\n",
       " '851.csv',\n",
       " '854.csv',\n",
       " '860.csv',\n",
       " '865.csv',\n",
       " '866.csv',\n",
       " '867.csv',\n",
       " '868.csv',\n",
       " '869.csv',\n",
       " '9.csv',\n",
       " '99.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset1의 test 데이터를 사용한 일반화 성능 확인\n",
    "\n",
    "net.eval()\n",
    "predicted = []\n",
    "with torch.no_grad():\n",
    "  for idx, x in enumerate(dataset1_test_dataloader):\n",
    "    x = x[0]\n",
    "    x = x.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = net(x.float())\n",
    "\n",
    "    _, preds = torch.max(output, 1)\n",
    "    predicted.extend(preds.cpu().numpy())\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class7', 'class1', 'class8', 'class5', 'class7', 'class8', 'class5', 'class5', 'class5', 'class5', 'class4', 'class8', 'class1', 'class7', 'class1', 'class7', 'class8', 'class7', 'class7', 'class7', 'class5', 'class5', 'class7', 'class1', 'class1', 'class8', 'class8', 'class5', 'class8', 'class5', 'class8', 'class8', 'class8', 'class5', 'class4', 'class7', 'class5', 'class7', 'class7', 'class5', 'class5', 'class4', 'class5', 'class8', 'class7', 'class8', 'class8', 'class7', 'class4', 'class10', 'class8', 'class4', 'class4', 'class8', 'class8', 'class8', 'class8', 'class1', 'class7', 'class5', 'class7', 'class4', 'class7', 'class8', 'class8', 'class7', 'class1', 'class8', 'class8', 'class8', 'class7', 'class4', 'class1', 'class7', 'class7', 'class7', 'class4', 'class8', 'class8', 'class7', 'class7', 'class8', 'class7', 'class8', 'class1', 'class8', 'class8', 'class8', 'class5', 'class1', 'class7', 'class8', 'class5', 'class5', 'class7', 'class8', 'class8', 'class8', 'class8', 'class7', 'class5', 'class4', 'class8', 'class8', 'class5', 'class7', 'class7', 'class5', 'class8', 'class8', 'class8', 'class5', 'class7', 'class4', 'class4', 'class4', 'class5', 'class10', 'class5', 'class8', 'class7', 'class8', 'class8', 'class5', 'class8', 'class7', 'class7', 'class7', 'class7', 'class7', 'class8', 'class5', 'class7', 'class7', 'class7', 'class8', 'class7', 'class8', 'class4', 'class8', 'class5', 'class8', 'class7', 'class1', 'class7', 'class7', 'class5', 'class7', 'class8', 'class8', 'class8', 'class7', 'class8', 'class8', 'class8', 'class8', 'class7', 'class7', 'class7', 'class5', 'class4', 'class5', 'class8', 'class8', 'class5', 'class7', 'class7', 'class8', 'class5', 'class1', 'class8', 'class7', 'class7', 'class8', 'class8', 'class5', 'class8', 'class10', 'class4', 'class8', 'class8', 'class7', 'class7', 'class7', 'class7', 'class5', 'class7', 'class8', 'class1', 'class7', 'class8', 'class7', 'class8', 'class7', 'class7', 'class5', 'class5', 'class7', 'class8', 'class7', 'class4', 'class5', 'class7', 'class5', 'class5', 'class8', 'class4']\n"
     ]
    }
   ],
   "source": [
    "l = len(predicted)\n",
    "answer = []\n",
    "for p in predicted:\n",
    "    temp = [0 for _ in range(11)]\n",
    "    temp[p] = 1\n",
    "    temp2 = dataset1_onehot_encoder.inverse_transform(np.array(temp).reshape(1,-1))\n",
    "    temp2 = temp2.tolist()\n",
    "    temp2 = temp2[0][0]\n",
    "    answer.append(temp2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>class8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>class7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "9   class8\n",
       "38  class8\n",
       "46  class7\n",
       "65  class5\n",
       "79  class5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {}\n",
    "for i, tl in enumerate(test_list):\n",
    "    df[int(tl[:-4])] = answer[i]\n",
    "\n",
    "pd_preds = pd.DataFrame.from_dict(df, orient='index').rename(columns={0:'label'})\n",
    "pd_preds = pd_preds.sort_index()\n",
    "pd_preds.to_csv('submission.csv')\n",
    "pd_preds.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e17ea03fbb32132e5671c308166b4379813c9bd4e6a684633c3a9083728c29e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('stdata')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
