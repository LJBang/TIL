{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leejoon-byeong\\vsprojects\\TIL\\2022\\5\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n"
     ]
    }
   ],
   "source": [
    "from kobart import get_kobart_tokenizer\n",
    "\n",
    "kobart_tokenizer = get_kobart_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁하지만',\n",
       " '▁아름다',\n",
       " '움',\n",
       " '이란',\n",
       " '▁일종의',\n",
       " '▁마',\n",
       " '법의',\n",
       " '▁주문',\n",
       " '이라는',\n",
       " '▁얘기',\n",
       " '▁기억',\n",
       " '나',\n",
       " '세요',\n",
       " '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobart_tokenizer.tokenize(\"하지만 아름다움이란 일종의 마법의 주문이라는 얘기 기억나세요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁그게',\n",
       " '▁있으면',\n",
       " '▁당사',\n",
       " '자는',\n",
       " '▁유리',\n",
       " '해지',\n",
       " '니까',\n",
       " ',',\n",
       " '▁그걸',\n",
       " '▁악용',\n",
       " '하는',\n",
       " '▁일도',\n",
       " '▁아주',\n",
       " '▁쉬',\n",
       " '워',\n",
       " '진',\n",
       " '다고',\n",
       " '▁생각해',\n",
       " '요.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobart_tokenizer.tokenize(\"그게 있으면 당사자는 유리해지니까, 그걸 악용하는 일도 아주 쉬워진다고 생각해요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[14393, 21076, 11921, 15548, 20427, 14087, 20401, 17737, 14394, 15734, 15806, 9495, 17275, 262], [17447, 17520, 19033, 14259, 17936, 23172, 14495, 243, 19165, 29596, 14049, 20668, 15861, 16164, 11933, 12335, 14117, 17232, 14543]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobart_tokenizer([\"하지만 아름다움이란 일종의 마법의 주문이라는 얘기 기억나세요?\",\"그게 있으면 당사자는 유리해지니까, 그걸 악용하는 일도 아주 쉬워진다고 생각해요.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\leejoon-byeong\\vsprojects\\TIL\\2022\\5\\.cache\\kobart_base_cased_ff4bda5738.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqModelOutput(last_hidden_state=tensor([[[-0.4418, -4.3673,  3.2404,  ...,  5.8832,  4.0629,  3.5540],\n",
       "         [-0.1316, -4.6446,  2.5955,  ...,  6.0093,  2.7467,  3.0007]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), past_key_values=((tensor([[[[-9.7980e-02, -6.6584e-01, -1.8089e+00,  ...,  9.6023e-01,\n",
       "           -1.8818e-01, -1.3252e+00],\n",
       "          [-6.2507e-01,  5.1009e-01, -7.4878e-01,  ...,  8.6230e-01,\n",
       "            1.5722e-01, -6.0267e-01]],\n",
       "\n",
       "         [[ 5.4597e-01, -2.3990e-01,  1.5901e+00,  ...,  4.3655e-01,\n",
       "            7.9514e-01,  8.9880e-02],\n",
       "          [-1.7327e-01, -6.3167e-01,  4.5152e-02,  ..., -1.4111e-01,\n",
       "            1.8678e-01, -1.2081e-01]],\n",
       "\n",
       "         [[ 1.4621e+00,  1.8980e+00, -7.6696e-01,  ...,  1.5695e+00,\n",
       "            6.7921e-02, -3.9372e-01],\n",
       "          [-4.1204e-02,  1.7132e+00, -1.1863e+00,  ..., -2.2272e-01,\n",
       "            9.8309e-02,  8.1729e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.8868e-01,  1.2633e+00, -1.1658e-01,  ..., -3.1989e-01,\n",
       "            1.2202e+00, -7.9021e-02],\n",
       "          [-8.4946e-01,  8.9379e-02, -1.0224e+00,  ...,  3.3125e-01,\n",
       "           -2.5262e-01,  5.0875e-01]],\n",
       "\n",
       "         [[ 1.5854e+00,  3.2461e-01,  3.0826e+00,  ..., -1.6728e+00,\n",
       "            1.2071e+00, -3.5671e-01],\n",
       "          [ 5.5400e-02, -9.2782e-01, -2.3053e-03,  ..., -6.1646e-01,\n",
       "            1.0880e+00,  2.8645e-01]],\n",
       "\n",
       "         [[ 8.7081e-01, -4.6088e-01, -2.8388e+00,  ...,  1.6038e+00,\n",
       "           -1.0963e+00, -1.8732e-01],\n",
       "          [ 4.5471e-01, -3.1087e-02, -2.4484e+00,  ...,  1.9392e+00,\n",
       "           -4.0694e-01, -1.9906e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 0.2187,  1.3322, -0.0016,  ..., -0.1200, -0.0395,  0.0971],\n",
       "          [-0.2722, -0.0590,  0.4620,  ...,  0.1822, -0.0171, -0.2176]],\n",
       "\n",
       "         [[ 0.1439,  0.0074,  0.0249,  ...,  0.2148, -0.5016,  0.1263],\n",
       "          [ 0.3625, -0.3192, -0.2254,  ...,  0.6312,  0.1061,  0.3506]],\n",
       "\n",
       "         [[-0.0862, -0.0073, -0.0479,  ...,  0.0110,  0.0198,  0.1909],\n",
       "          [-0.4622, -0.4537, -0.6060,  ...,  0.5620,  1.3319,  0.0989]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0868, -0.1329,  0.1862,  ..., -0.0489, -0.0084,  0.0151],\n",
       "          [-0.4065,  0.4082,  0.7682,  ..., -0.0909,  0.1701,  0.0145]],\n",
       "\n",
       "         [[ 0.1256,  0.1170,  0.0912,  ...,  0.0623, -0.0574,  0.0611],\n",
       "          [-0.2664, -0.4485,  0.1439,  ...,  0.2324,  0.3832, -1.0943]],\n",
       "\n",
       "         [[ 0.0702,  0.0227,  0.0311,  ..., -0.0203,  0.0602,  0.0033],\n",
       "          [-0.3197,  0.4879,  0.1972,  ..., -0.3241,  0.1762,  0.5655]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[-1.0648, -2.5643, -1.2208,  ...,  1.4609,  1.0088,  0.8616],\n",
       "          [-1.3031, -2.4746, -1.2874,  ...,  1.4641,  0.6007,  0.5663]],\n",
       "\n",
       "         [[-0.9957, -1.4633, -0.6104,  ..., -0.0807,  0.6639,  1.1657],\n",
       "          [-0.8524, -2.1023, -0.3089,  ...,  0.1747,  0.9409,  0.8996]],\n",
       "\n",
       "         [[ 1.7265, -0.0293, -0.3755,  ..., -0.6951,  0.4730,  0.3141],\n",
       "          [ 1.5839, -0.6262, -0.5320,  ...,  0.2295,  0.5922,  0.6125]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1965, -0.4015,  1.1312,  ..., -0.5016, -0.1073,  0.0549],\n",
       "          [-0.5866, -0.6739,  1.0961,  ..., -0.3082, -0.1296,  0.0126]],\n",
       "\n",
       "         [[-0.0225,  0.6815, -1.6006,  ...,  1.7747, -0.4324, -1.2341],\n",
       "          [ 0.2012,  0.2133, -2.0224,  ...,  1.0445, -0.3429, -1.1153]],\n",
       "\n",
       "         [[-0.4898, -0.2916,  0.1036,  ..., -1.1657, -2.0047, -0.5035],\n",
       "          [ 0.2014,  0.0172, -0.2052,  ..., -1.1187, -2.9760, -0.2174]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 0.2822, -0.1429, -0.0214,  ...,  0.0815,  0.1900, -0.2706],\n",
       "          [ 0.0435, -0.3802, -0.3064,  ...,  0.5159,  0.1527, -0.2039]],\n",
       "\n",
       "         [[-0.8001,  0.0466,  1.0855,  ..., -0.2635, -0.2926,  0.3927],\n",
       "          [-0.3446, -0.6481,  0.5623,  ...,  0.3295,  0.6792,  0.4060]],\n",
       "\n",
       "         [[-0.8864, -0.0462, -0.4937,  ..., -1.2180,  0.5027,  0.1991],\n",
       "          [-0.8240, -0.4198,  0.1187,  ..., -0.3042,  0.6595, -0.1653]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3499,  0.7639,  0.0130,  ...,  0.3620,  0.4275, -0.6412],\n",
       "          [-0.1910,  0.5114, -0.0352,  ...,  0.3060,  0.2019, -0.4844]],\n",
       "\n",
       "         [[ 0.2417,  0.1567,  0.2082,  ...,  0.1640, -0.1767, -0.1738],\n",
       "          [ 0.1304, -0.0716, -0.1840,  ...,  0.3307,  0.1039,  0.1808]],\n",
       "\n",
       "         [[-0.4749, -0.9211,  1.0276,  ..., -0.3349, -0.2668, -0.2143],\n",
       "          [ 0.0051, -0.7191,  0.6315,  ..., -0.2618,  0.0611, -0.1337]]]],\n",
       "       grad_fn=<CopyBackwards>)), (tensor([[[[ 0.0568,  0.1593,  0.3356,  ..., -0.0771, -0.1446, -0.1562],\n",
       "          [ 1.6254, -1.5403,  1.2852,  ...,  0.3465, -1.0204, -1.6762]],\n",
       "\n",
       "         [[ 0.2014, -0.2892, -0.4829,  ...,  0.2817, -0.1413,  1.5805],\n",
       "          [ 0.6554,  1.6124,  0.4492,  ...,  0.3675,  1.0584, -3.6320]],\n",
       "\n",
       "         [[-0.1167,  0.6492, -0.5715,  ...,  0.0990, -1.3751, -0.3157],\n",
       "          [ 0.5295, -2.8552,  1.0669,  ...,  0.8806,  2.6310, -0.9037]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0606,  0.1003,  0.1334,  ...,  0.0648,  0.0886,  1.1766],\n",
       "          [ 0.9016, -1.1139,  1.2164,  ...,  0.0885,  0.5449, -1.5874]],\n",
       "\n",
       "         [[ 0.1461,  0.1861,  0.0330,  ..., -0.0966, -0.3876,  0.2000],\n",
       "          [-0.4877,  0.6808,  0.8141,  ...,  1.1511, -1.0541, -0.7516]],\n",
       "\n",
       "         [[ 0.4198,  0.1532,  0.4183,  ..., -0.1995, -0.0194,  0.3649],\n",
       "          [ 1.9049,  0.4632, -1.9892,  ...,  0.2458,  0.5797, -0.5118]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 1.5379e-02,  4.6779e-02,  2.3209e-02,  ..., -3.6808e-03,\n",
       "           -6.6380e-02,  8.8302e-04],\n",
       "          [ 3.3722e-01,  5.9773e-01, -9.7631e-01,  ..., -6.7000e-01,\n",
       "           -8.6936e-01, -1.0744e+00]],\n",
       "\n",
       "         [[-8.2675e-03, -2.8381e-02, -3.8986e-02,  ...,  1.9672e-02,\n",
       "            2.6158e-03,  2.0188e-03],\n",
       "          [ 4.2856e-01,  1.3611e+00,  4.8732e-01,  ..., -5.9339e-02,\n",
       "           -1.1926e-01, -4.2579e-02]],\n",
       "\n",
       "         [[ 6.0655e-02, -1.8254e-02, -1.5229e-02,  ..., -1.6663e-02,\n",
       "            8.4880e-03, -4.8301e-02],\n",
       "          [-1.0497e-01, -8.1324e-02,  3.3243e-01,  ...,  3.5059e-01,\n",
       "           -7.1201e-02,  1.6472e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.6912e-02, -6.7970e-02, -8.0440e-02,  ..., -9.4137e-02,\n",
       "            3.8142e-03,  7.8198e-02],\n",
       "          [-2.4057e-01,  2.6778e-03,  7.9480e-01,  ...,  2.9896e-01,\n",
       "            7.9629e-01,  9.2801e-01]],\n",
       "\n",
       "         [[ 1.9845e-02,  4.9133e-03, -3.3145e-02,  ...,  7.2793e-02,\n",
       "            5.9300e-02, -5.7760e-02],\n",
       "          [-3.6504e-01,  5.4651e-01, -4.3530e-02,  ..., -3.2015e-01,\n",
       "            7.9082e-01, -9.7559e-02]],\n",
       "\n",
       "         [[ 3.4483e-02, -1.2532e-02,  1.5040e-02,  ...,  1.7609e-02,\n",
       "           -2.3566e-02, -2.2959e-02],\n",
       "          [-1.1245e+00, -6.8237e-01,  1.0025e-01,  ..., -2.7405e-01,\n",
       "           -5.1046e-01, -1.9640e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 2.3286e+00, -4.2951e-02,  3.0110e+00,  ...,  1.0627e+00,\n",
       "           -9.1236e-01,  2.6603e+00],\n",
       "          [ 3.0073e+00, -1.5674e-01,  2.8979e+00,  ...,  9.7826e-01,\n",
       "           -5.3163e-01,  3.0233e+00]],\n",
       "\n",
       "         [[ 1.7130e+00, -2.9926e+00,  1.8776e+00,  ...,  7.5416e-01,\n",
       "           -8.7124e-01, -4.8129e-01],\n",
       "          [ 2.5120e+00, -3.2266e+00,  2.2682e+00,  ...,  4.4046e-01,\n",
       "           -5.1476e-01, -5.2342e-01]],\n",
       "\n",
       "         [[-8.1486e-01, -9.5213e-01, -8.3369e-04,  ...,  1.5024e+00,\n",
       "           -5.7569e-01,  1.9130e-01],\n",
       "          [-8.1358e-01, -1.2385e+00,  9.3572e-01,  ...,  1.1406e+00,\n",
       "           -9.5044e-01, -4.8016e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.1763e-01, -9.2276e-01,  1.5260e+00,  ...,  2.9562e-02,\n",
       "            1.5475e-02, -8.2439e-01],\n",
       "          [ 1.4520e-02, -1.5225e+00,  1.9413e+00,  ..., -3.6908e-01,\n",
       "            5.3651e-01, -2.1469e-01]],\n",
       "\n",
       "         [[-1.0017e+00, -5.5066e-01, -1.8923e+00,  ..., -5.8160e-01,\n",
       "            4.2548e-01, -6.7959e-01],\n",
       "          [-5.8291e-01, -8.2588e-01, -2.0550e+00,  ..., -2.2966e-01,\n",
       "            2.4397e-02, -2.6139e-01]],\n",
       "\n",
       "         [[-1.4829e+00, -8.8995e-01,  9.4026e-01,  ...,  1.4175e+00,\n",
       "           -3.9160e-01, -9.2237e-01],\n",
       "          [-1.0111e+00, -1.1450e+00,  1.1993e+00,  ...,  2.0617e+00,\n",
       "           -5.9144e-01, -1.3860e+00]]]], grad_fn=<CopyBackwards>), tensor([[[[ 0.1935, -0.1730,  0.3934,  ..., -0.0840,  0.2339,  0.1091],\n",
       "          [-0.0569, -0.3551,  0.3823,  ...,  0.0197, -0.0043, -0.0436]],\n",
       "\n",
       "         [[ 0.2364,  0.4606,  0.5622,  ...,  0.4820,  0.1865,  0.6264],\n",
       "          [ 0.5973,  0.2811,  0.2784,  ...,  0.1489, -0.4533,  0.4468]],\n",
       "\n",
       "         [[ 0.4116,  0.4325, -0.3306,  ..., -0.7509,  0.2645, -0.1624],\n",
       "          [ 0.8045,  0.3654, -0.4785,  ..., -0.7986, -0.0484, -0.1889]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1706, -1.0074,  0.2970,  ...,  0.4921,  0.5458,  0.1225],\n",
       "          [ 0.3865, -1.1976, -0.2150,  ...,  0.6561,  0.4510,  0.1755]],\n",
       "\n",
       "         [[ 0.0047, -0.7317,  0.3213,  ...,  0.5871, -0.2654, -0.4047],\n",
       "          [-0.1921, -0.4592,  0.0943,  ...,  0.3975, -0.2417, -0.3156]],\n",
       "\n",
       "         [[-0.1002, -0.3230,  0.6674,  ..., -0.2355, -0.6963, -0.3525],\n",
       "          [-0.1739, -0.4883,  0.4101,  ..., -0.2514, -0.6257, -0.6858]]]],\n",
       "       grad_fn=<CopyBackwards>)), (tensor([[[[-0.1980, -0.8728,  0.6663,  ...,  0.2215,  0.3865, -0.0239],\n",
       "          [ 0.7417,  3.5312, -0.8480,  ..., -0.0536, -0.7790, -0.2229]],\n",
       "\n",
       "         [[ 0.3768, -0.2689, -0.0428,  ...,  0.1046, -0.1428, -0.9039],\n",
       "          [ 0.0478,  2.5229, -0.2297,  ..., -0.2463,  3.8656,  4.1837]],\n",
       "\n",
       "         [[-0.0777,  0.5079,  0.0822,  ...,  0.0193, -0.5585,  0.1365],\n",
       "          [ 0.6972, -2.6046,  1.8231,  ..., -1.2138,  2.4488,  0.6540]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4664,  0.2169,  0.0277,  ...,  1.1934,  0.6856,  0.1670],\n",
       "          [ 0.6041,  0.9994,  0.1424,  ..., -1.8193, -1.1613, -0.5548]],\n",
       "\n",
       "         [[ 0.0759,  0.1255, -0.0151,  ...,  0.0307,  0.1052, -0.6455],\n",
       "          [ 0.6701,  0.7716,  0.2974,  ..., -0.7394,  0.5873,  3.0509]],\n",
       "\n",
       "         [[ 0.1543,  0.2131, -0.0718,  ...,  0.0975, -0.0069, -0.3904],\n",
       "          [-0.5077, -1.8357,  2.1244,  ...,  0.3969,  1.3626, -0.0225]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 2.9269e-02,  1.1764e-01, -1.2732e-02,  ..., -8.6454e-02,\n",
       "            1.2252e-01,  6.7036e-03],\n",
       "          [ 3.9763e-01, -2.9863e-01, -4.3627e-01,  ..., -5.6594e-02,\n",
       "           -2.9131e-01, -6.3776e-01]],\n",
       "\n",
       "         [[ 1.6335e-02, -2.4424e-02, -4.8431e-03,  ..., -5.6252e-02,\n",
       "           -6.8835e-02,  1.2608e-02],\n",
       "          [ 3.5408e-01,  6.1424e-01,  3.5653e-01,  ..., -3.0892e-02,\n",
       "            7.4475e-02,  2.0799e-02]],\n",
       "\n",
       "         [[ 2.5243e-02,  1.0407e-02, -4.8344e-02,  ...,  6.4945e-03,\n",
       "            3.9794e-04,  1.2100e-01],\n",
       "          [ 7.1725e-01, -1.8262e-01, -3.0229e-01,  ..., -4.4057e-01,\n",
       "           -3.8583e-02, -2.3157e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.2560e-03,  1.4655e-02,  3.4054e-02,  ...,  9.6428e-03,\n",
       "           -6.3913e-03,  2.7569e-02],\n",
       "          [ 4.2214e-01,  3.7137e-01,  2.3890e-01,  ..., -1.7631e-01,\n",
       "            9.0582e-01,  1.0196e-01]],\n",
       "\n",
       "         [[ 3.1055e-03,  1.0484e-02, -4.7095e-03,  ...,  4.8638e-02,\n",
       "           -1.5250e-02, -7.0406e-02],\n",
       "          [ 9.7426e-02,  2.6014e-01,  3.1176e-01,  ..., -4.8579e-01,\n",
       "            9.3070e-01, -1.1125e-01]],\n",
       "\n",
       "         [[ 2.8621e-02, -2.8968e-03, -3.1328e-02,  ...,  2.5224e-02,\n",
       "            1.8680e-02, -4.3578e-02],\n",
       "          [ 3.0150e-01, -1.9468e-01, -1.7805e-01,  ...,  5.1854e-01,\n",
       "           -3.4875e-02,  9.8428e-02]]]], grad_fn=<CopyBackwards>), tensor([[[[-1.7399,  1.5544,  0.8420,  ...,  0.1949,  0.3739, -0.4898],\n",
       "          [-1.6240,  1.3219,  0.9978,  ..., -0.4160, -0.1783,  0.3793]],\n",
       "\n",
       "         [[-0.2877, -0.3362, -0.3745,  ...,  0.3365,  0.1496, -1.2037],\n",
       "          [-0.2730, -0.1071, -0.1413,  ...,  0.3996, -0.1407, -1.1605]],\n",
       "\n",
       "         [[ 1.4108, -0.6566,  1.7061,  ...,  1.4992,  0.5674, -0.9317],\n",
       "          [ 1.7853, -1.0445,  1.7326,  ...,  1.7643,  0.5169, -1.0316]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7319,  3.2136,  1.1013,  ..., -0.8693, -0.2972, -1.2679],\n",
       "          [-2.0636,  3.6187,  0.9261,  ..., -0.9856, -0.3694, -1.0883]],\n",
       "\n",
       "         [[-0.9236,  0.7800, -0.0765,  ...,  1.6758,  1.2948,  0.3508],\n",
       "          [-0.6022,  0.7458, -0.1418,  ...,  2.1779,  1.1909,  0.1315]],\n",
       "\n",
       "         [[ 0.4240,  0.0391, -1.3894,  ..., -1.0823, -0.4126,  0.9783],\n",
       "          [ 0.5731, -0.2723, -1.8803,  ..., -1.2079, -1.0119,  0.5113]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 0.0985, -0.6352, -0.0868,  ...,  0.0363,  0.0543, -0.3238],\n",
       "          [-0.2378, -0.1665, -0.3516,  ...,  0.3921, -0.2744, -0.3039]],\n",
       "\n",
       "         [[ 0.8450,  0.2317,  0.6335,  ...,  0.5318, -0.0949,  0.1750],\n",
       "          [ 0.5121,  0.0876,  0.5792,  ..., -0.0148, -0.4605,  0.2020]],\n",
       "\n",
       "         [[-0.2443, -0.0378,  0.2317,  ...,  0.0219, -0.1216,  0.0395],\n",
       "          [-0.4156,  0.0576,  0.1678,  ...,  0.0501, -0.3476, -0.2093]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1073,  0.2830,  0.1495,  ..., -1.0262,  0.5416,  0.5043],\n",
       "          [ 0.2258,  0.0643, -0.1481,  ..., -1.0380,  0.3420,  0.5458]],\n",
       "\n",
       "         [[-0.1796, -0.4815,  0.2412,  ..., -0.1129,  0.5764,  0.0777],\n",
       "          [-0.2803, -0.4700,  0.0848,  ...,  0.2658,  0.4753,  0.1039]],\n",
       "\n",
       "         [[ 0.5494,  0.6024, -0.6296,  ...,  0.1007,  0.8262, -0.1736],\n",
       "          [ 0.3254,  0.5532, -0.1605,  ..., -0.2396,  0.2754,  0.1460]]]],\n",
       "       grad_fn=<CopyBackwards>)), (tensor([[[[ 0.8659,  1.2230, -0.0036,  ..., -0.1768,  1.2656,  1.3975],\n",
       "          [-2.4391, -1.6445,  1.7410,  ..., -1.8302, -2.0103, -1.7548]],\n",
       "\n",
       "         [[ 0.4183,  0.5536,  0.7881,  ..., -0.2234,  0.4811, -0.0375],\n",
       "          [-1.6890, -0.3787, -1.0577,  ..., -0.8861, -1.5151, -0.2258]],\n",
       "\n",
       "         [[-0.5553, -1.0096,  0.1065,  ..., -0.4831,  1.4737, -0.0735],\n",
       "          [ 0.7138,  0.3943,  0.3157,  ...,  0.2931, -0.2829,  0.3843]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6875,  0.4129, -0.7369,  ..., -1.1018, -0.7937,  0.5081],\n",
       "          [ 1.8270,  0.4463, -1.1159,  ...,  0.7450,  1.0975,  0.1329]],\n",
       "\n",
       "         [[ 0.2528,  0.2051,  0.2412,  ...,  0.1542,  0.5065, -0.0168],\n",
       "          [ 0.0560,  1.4332,  0.3786,  ...,  0.1777, -0.5803,  0.0421]],\n",
       "\n",
       "         [[-0.2057,  0.4577,  0.8795,  ..., -0.3249, -0.0460,  0.9419],\n",
       "          [-1.3328,  0.4214, -0.5938,  ..., -0.5810,  0.0759, -0.4099]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[-4.0518e-02, -5.9250e-02, -1.6183e-02,  ..., -8.3794e-04,\n",
       "           -3.3078e-02,  7.6099e-02],\n",
       "          [-4.3446e-01, -1.9747e-01, -4.3507e-01,  ..., -4.8681e-01,\n",
       "           -2.7236e-01, -8.4327e-02]],\n",
       "\n",
       "         [[-1.4299e-01,  1.0976e-01, -3.2061e-02,  ..., -7.9136e-02,\n",
       "           -6.2019e-02,  1.1654e-03],\n",
       "          [ 5.5592e-01, -4.1032e-02,  1.5685e-01,  ...,  4.7759e-01,\n",
       "            4.6286e-01,  1.3250e-01]],\n",
       "\n",
       "         [[-1.0311e-02, -3.4038e-02, -1.5415e-01,  ...,  2.3261e-02,\n",
       "           -1.4703e-02,  2.4091e-02],\n",
       "          [-8.1498e-01, -3.5524e-01,  3.3233e-02,  ...,  2.5945e-01,\n",
       "            5.5901e-02,  1.0831e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8605e-02,  5.5119e-02,  2.7360e-03,  ..., -2.4560e-02,\n",
       "            6.2882e-03,  5.5262e-03],\n",
       "          [ 1.2290e-01, -4.1711e-01, -3.5411e-02,  ..., -2.1633e-01,\n",
       "           -4.8053e-01,  9.0854e-02]],\n",
       "\n",
       "         [[-8.3886e-04,  6.2181e-02, -3.9761e-02,  ...,  5.1470e-02,\n",
       "            7.0819e-02,  8.0597e-03],\n",
       "          [ 5.9445e-02,  5.7503e-01, -7.6639e-01,  ...,  4.2499e-03,\n",
       "           -7.7810e-02,  9.4071e-02]],\n",
       "\n",
       "         [[ 7.7253e-02,  7.0009e-02, -1.6194e-02,  ...,  2.5476e-02,\n",
       "           -8.1934e-03,  2.2595e-02],\n",
       "          [ 1.1499e-01, -3.9242e-01,  7.6922e-01,  ...,  2.9297e-01,\n",
       "            8.2074e-01,  6.4680e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 2.0849, -0.0636,  0.5000,  ...,  0.9966,  1.7627,  1.5514],\n",
       "          [ 1.7876, -0.7635,  1.6988,  ...,  2.0722,  1.4739,  1.1660]],\n",
       "\n",
       "         [[-0.8371,  0.9337,  0.7837,  ...,  0.0498,  1.6516,  0.1707],\n",
       "          [-0.5368,  1.0880,  0.5653,  ..., -0.0634,  1.3486, -0.6582]],\n",
       "\n",
       "         [[-0.0912,  0.6096, -0.6076,  ...,  0.7558, -0.0126, -1.5131],\n",
       "          [-0.2230,  0.5867, -0.7267,  ...,  0.8867, -0.1216, -1.8096]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6766,  0.6220,  1.5134,  ..., -0.1829,  0.0215,  1.1120],\n",
       "          [-0.8275,  0.6928,  1.6118,  ..., -0.2364,  0.0025,  1.4436]],\n",
       "\n",
       "         [[ 1.1364,  0.0790, -0.3696,  ...,  0.2541,  0.9125, -0.5037],\n",
       "          [ 1.5442,  0.0934, -0.4613,  ...,  0.0754,  0.0034, -0.9217]],\n",
       "\n",
       "         [[ 1.2640, -0.4548, -0.5475,  ...,  0.5674, -0.4214, -1.0081],\n",
       "          [ 1.2149, -0.7560, -0.2841,  ...,  0.4172, -0.3426, -0.9019]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[-0.0386, -0.1903,  0.1470,  ..., -0.3462, -0.1094, -0.1254],\n",
       "          [-0.0886,  0.0395,  0.0272,  ...,  0.0271, -0.3885,  0.0461]],\n",
       "\n",
       "         [[ 0.1720, -0.3733, -0.0356,  ...,  0.0848,  0.4297,  0.5137],\n",
       "          [ 0.2865, -0.2505, -0.2307,  ..., -0.2456,  0.3889,  0.3922]],\n",
       "\n",
       "         [[-0.5288, -0.7186,  0.3537,  ..., -0.7664,  0.2124,  0.3075],\n",
       "          [-0.3642, -0.0657,  0.0399,  ..., -0.5451,  0.2110,  0.1761]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1834, -0.7011,  0.8361,  ...,  0.3994, -0.3654, -0.3145],\n",
       "          [ 0.2181, -0.7129,  0.8148,  ...,  0.1566,  0.0218,  0.0515]],\n",
       "\n",
       "         [[-0.3867, -0.7703, -0.4015,  ..., -0.3819, -0.8259,  0.0101],\n",
       "          [ 0.2124,  0.1236, -0.8350,  ...,  0.3556, -1.1067, -0.0330]],\n",
       "\n",
       "         [[-0.1518, -0.0204,  0.3507,  ..., -0.0252, -0.2174,  0.3534],\n",
       "          [ 0.2348, -0.1401,  0.4585,  ...,  0.2866, -0.0423,  0.0067]]]],\n",
       "       grad_fn=<CopyBackwards>)), (tensor([[[[-0.2997,  1.0674, -0.2439,  ..., -0.2289, -0.6333, -0.6078],\n",
       "          [ 0.9438, -1.8757, -0.5755,  ...,  0.1229,  1.7929, -0.3130]],\n",
       "\n",
       "         [[ 0.3514,  1.5137,  0.4524,  ...,  1.1948, -1.3977,  0.3308],\n",
       "          [ 0.1387, -1.1616, -0.6226,  ..., -2.1536, -0.1766, -1.1653]],\n",
       "\n",
       "         [[-1.3330, -0.6003,  0.2709,  ...,  1.1001, -0.1418, -0.6230],\n",
       "          [-1.5638,  1.9531, -0.2184,  ..., -0.3042, -2.2814,  1.5291]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4103, -0.2594, -0.7356,  ...,  0.4831,  0.0690,  0.3132],\n",
       "          [-0.5332,  0.1774,  1.8028,  ...,  0.1322,  0.1915, -0.9951]],\n",
       "\n",
       "         [[-0.0831, -0.3862, -0.7452,  ..., -0.2725, -0.0534, -0.2660],\n",
       "          [-1.4382, -1.8134,  2.8000,  ..., -0.8421, -0.6358,  0.1198]],\n",
       "\n",
       "         [[-1.0351, -0.4564, -1.0894,  ...,  0.2800, -0.1461, -0.3104],\n",
       "          [ 0.2128, -0.7712, -0.1874,  ..., -0.7119, -0.5132, -1.6355]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[-3.3177e-02, -1.8028e-04,  4.5832e-04,  ...,  1.3248e-02,\n",
       "            1.9023e-02,  3.2562e-02],\n",
       "          [-3.2168e-02, -1.5418e-01,  1.4814e-01,  ..., -2.6376e-01,\n",
       "            1.0807e-02, -6.4121e-01]],\n",
       "\n",
       "         [[-1.0983e-02, -2.1240e-02, -4.1562e-02,  ..., -2.0584e-02,\n",
       "           -5.9072e-02, -6.3754e-02],\n",
       "          [-7.4979e-01,  4.7896e-01,  3.1803e-01,  ..., -2.9700e-01,\n",
       "           -1.4955e-01, -2.6639e-01]],\n",
       "\n",
       "         [[ 5.7588e-02,  8.7107e-02, -3.4391e-02,  ..., -1.3255e-02,\n",
       "            2.8237e-02,  1.2374e-01],\n",
       "          [-6.9403e-01,  5.8305e-01, -4.0448e-03,  ...,  2.2897e-02,\n",
       "           -6.2816e-01,  3.7408e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4895e-02,  7.3233e-03,  3.9967e-02,  ...,  4.8722e-02,\n",
       "           -6.5669e-02, -5.9926e-02],\n",
       "          [-1.0827e+00, -5.7699e-01,  4.4333e-01,  ...,  2.7596e-01,\n",
       "            9.1006e-01, -4.2223e-01]],\n",
       "\n",
       "         [[-2.7116e-02,  1.4112e-02, -1.0806e-01,  ..., -2.1597e-02,\n",
       "            1.6286e-02,  6.7959e-03],\n",
       "          [ 2.9614e-01,  6.9683e-01,  2.1900e-01,  ...,  1.0726e-02,\n",
       "            3.8513e-02,  1.0382e-02]],\n",
       "\n",
       "         [[ 5.4608e-03,  4.4768e-02, -1.2635e-02,  ...,  1.2816e-03,\n",
       "            3.0699e-02, -1.0643e-01],\n",
       "          [-3.3885e-01, -4.5146e-02,  4.8048e-02,  ..., -4.6988e-01,\n",
       "            2.6005e-01, -7.2162e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 1.0374,  0.3910, -0.6754,  ...,  0.2131, -0.7792,  0.1073],\n",
       "          [ 0.6857,  0.6310, -0.8816,  ..., -0.0665,  0.0525, -0.0755]],\n",
       "\n",
       "         [[ 0.5946, -0.2358, -1.0036,  ..., -0.7404, -1.1777, -2.7705],\n",
       "          [ 0.9685, -0.8442, -1.0034,  ..., -0.5312, -1.2558, -2.5045]],\n",
       "\n",
       "         [[-0.8795, -0.7718, -1.1451,  ...,  0.3562,  0.6508, -0.3904],\n",
       "          [-0.6928, -1.3858, -1.1689,  ...,  0.9893,  0.1329, -0.7229]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6684, -0.8720,  0.7093,  ...,  1.3669,  1.9079,  0.6156],\n",
       "          [-3.0017, -0.5989,  0.8993,  ...,  1.0432,  1.9339, -0.0553]],\n",
       "\n",
       "         [[-3.6058,  2.1486,  2.1966,  ...,  1.6174, -2.3318, -0.6465],\n",
       "          [-3.9024,  2.2764,  2.3965,  ...,  0.1705, -2.1405, -0.2133]],\n",
       "\n",
       "         [[-0.7480,  1.9170,  1.3470,  ...,  0.4011, -0.4394, -1.1463],\n",
       "          [-0.3069,  1.8317,  1.8609,  ...,  0.0209, -0.2684, -0.9492]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 0.7396, -0.1129,  0.1192,  ..., -0.0200, -0.2694, -0.1733],\n",
       "          [ 0.9639, -0.3486, -0.0451,  ..., -0.7172, -0.3156,  0.1609]],\n",
       "\n",
       "         [[ 0.0073, -0.7114, -0.4992,  ..., -0.3623, -0.2582,  0.3008],\n",
       "          [ 0.2753, -0.3529, -0.4996,  ..., -0.3469, -0.0021,  0.2831]],\n",
       "\n",
       "         [[ 0.1104,  0.1524, -0.2274,  ..., -0.2116,  0.0372,  0.3177],\n",
       "          [ 0.2157,  0.3495, -0.1770,  ...,  0.2640, -0.0096,  0.4679]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2203, -0.0463,  0.1329,  ...,  0.0979, -0.3664,  0.3431],\n",
       "          [-0.0973, -0.2557,  0.4457,  ...,  0.1551, -0.3278,  0.6508]],\n",
       "\n",
       "         [[ 0.5532, -0.3937,  0.4316,  ..., -0.0912,  0.6116, -0.1449],\n",
       "          [ 0.6388, -0.4841,  0.4255,  ..., -0.0629,  0.5913, -0.1810]],\n",
       "\n",
       "         [[ 0.4216, -0.3658, -0.3054,  ...,  0.1030,  0.0099, -0.1975],\n",
       "          [ 0.3812, -0.3219, -0.4682,  ..., -0.3154,  0.0673, -0.2982]]]],\n",
       "       grad_fn=<CopyBackwards>)), (tensor([[[[-0.0638, -0.3080,  0.1955,  ..., -0.2980,  0.1688,  0.0431],\n",
       "          [ 0.5026, -0.5220,  3.4995,  ..., -1.0278,  0.1422,  2.3666]],\n",
       "\n",
       "         [[ 0.4591,  0.1555, -0.1794,  ..., -0.2225, -0.4867,  0.2342],\n",
       "          [-0.4296, -0.2702, -0.8925,  ..., -1.1856,  0.8598, -0.2742]],\n",
       "\n",
       "         [[-0.3287, -0.1999, -0.2862,  ..., -0.5182,  0.0972,  0.6838],\n",
       "          [ 2.6562,  1.6259, -1.6430,  ...,  0.5375,  1.0974, -3.0638]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1022, -0.1004,  0.0337,  ..., -0.4126,  0.0917,  0.2785],\n",
       "          [-0.3013,  0.2233, -0.8632,  ..., -2.7654,  0.0675,  2.4467]],\n",
       "\n",
       "         [[ 0.3300,  0.2506,  0.0510,  ..., -0.0276, -0.1510, -0.1070],\n",
       "          [-3.6227,  0.0169, -1.4157,  ..., -0.7226, -1.0749,  1.1248]],\n",
       "\n",
       "         [[-0.0671, -0.4478, -0.0450,  ..., -0.1774, -0.1607, -0.0955],\n",
       "          [-4.6108,  0.6886,  0.8102,  ..., -0.4719,  0.8873, -2.4897]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[-0.0404, -0.0917,  0.0642,  ..., -0.0035, -0.0486,  0.0240],\n",
       "          [-0.2731,  0.0407,  0.5085,  ..., -0.1216, -0.2275, -0.7928]],\n",
       "\n",
       "         [[ 0.0031, -0.1010,  0.0053,  ...,  0.0069, -0.0100,  0.0144],\n",
       "          [-0.1159, -0.6017,  0.1824,  ..., -0.1040,  0.0132,  0.0196]],\n",
       "\n",
       "         [[ 0.1149, -0.0396, -0.0644,  ..., -0.1404,  0.0345,  0.0140],\n",
       "          [ 0.4707,  0.5479,  0.1769,  ..., -1.8493, -0.6008, -0.0666]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0385, -0.0342, -0.0351,  ...,  0.0089, -0.0578,  0.0940],\n",
       "          [ 0.3749,  0.0586, -0.0326,  ..., -0.1291, -0.1929,  0.6304]],\n",
       "\n",
       "         [[-0.0040,  0.0416,  0.0358,  ...,  0.0166,  0.0453,  0.0051],\n",
       "          [ 0.0923, -0.0818,  0.3751,  ...,  0.5956, -0.0576, -0.0671]],\n",
       "\n",
       "         [[ 0.0988,  0.0028,  0.0458,  ...,  0.1539,  0.0561,  0.0554],\n",
       "          [ 0.0944, -0.1632,  0.0327,  ...,  0.9541,  0.3676,  0.2072]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 0.4540, -0.9974, -2.6459,  ...,  1.1923, -0.3397,  3.7741],\n",
       "          [ 0.5595, -0.9436, -1.4177,  ...,  0.9573, -0.9510,  3.5285]],\n",
       "\n",
       "         [[ 0.5767, -1.4281, -0.0372,  ...,  0.2962,  1.1243,  1.1418],\n",
       "          [-0.3780, -1.4567,  1.4320,  ..., -0.2319,  0.4736,  0.6123]],\n",
       "\n",
       "         [[ 0.4139, -1.4614, -0.8103,  ..., -3.3714,  0.1478,  0.2090],\n",
       "          [-0.1716, -1.2067, -0.2029,  ..., -2.4051, -0.5143,  0.5125]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4578, -0.9712,  0.9847,  ..., -0.2011, -1.6939,  0.2227],\n",
       "          [-1.9282, -0.9421,  0.6625,  ..., -0.3203, -2.4944,  0.4157]],\n",
       "\n",
       "         [[-1.9077,  2.6054,  0.7046,  ...,  3.3153,  0.8114, -1.1166],\n",
       "          [-0.5560,  2.4935,  1.0945,  ...,  3.5782,  0.8835, -1.7877]],\n",
       "\n",
       "         [[-0.7894, -0.6044, -0.4530,  ...,  2.1209, -1.0290,  1.3274],\n",
       "          [-1.5356,  0.6271, -1.3167,  ...,  1.9269, -1.3602,  2.0155]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 0.2468,  0.4531, -0.2456,  ..., -0.2639, -0.4747,  0.2349],\n",
       "          [ 0.6563,  0.5046, -0.2421,  ...,  0.0345, -0.6680,  0.2661]],\n",
       "\n",
       "         [[ 0.1554,  0.0104,  0.0888,  ...,  0.5652,  0.1155,  0.2966],\n",
       "          [ 0.2705, -0.4564,  0.2788,  ...,  0.3807,  0.1667,  0.0607]],\n",
       "\n",
       "         [[-0.5218, -0.1890,  0.0533,  ..., -0.1139,  0.2080, -0.0636],\n",
       "          [-0.3670, -0.1278, -0.1607,  ...,  0.1446, -0.0988, -0.1946]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0757,  0.8512,  0.1290,  ...,  0.5617,  0.4623, -0.4476],\n",
       "          [-0.1185,  0.9600,  0.4644,  ...,  0.6976,  0.4706,  0.1709]],\n",
       "\n",
       "         [[ 0.0076, -0.1633,  0.0613,  ..., -0.4322, -0.1017,  0.0051],\n",
       "          [ 0.0926, -0.3790,  0.3583,  ..., -0.1947, -0.1139, -0.2700]],\n",
       "\n",
       "         [[ 0.8125,  0.0627,  0.4241,  ...,  0.3436,  0.0131, -0.7254],\n",
       "          [ 0.4459,  0.2707,  0.4448,  ...,  0.2226,  0.4030, -0.7320]]]],\n",
       "       grad_fn=<CopyBackwards>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 0.4624, -0.2475,  0.0902,  ...,  0.1127,  0.6529,  0.2203],\n",
       "         [ 0.4538, -0.2948,  0.2556,  ..., -0.0442,  0.6858,  0.4372]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartModel, BartForSequenceClassification\n",
    "from kobart import get_pytorch_kobart_model\n",
    "\n",
    "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
    "inputs = kobart_tokenizer(['안녕하세요.'], return_tensors='pt')\n",
    "model(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[27616, 25161]], 'token_type_ids': [[0, 0]], 'attention_mask': [[1, 1]]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = kobart_tokenizer(['안녕하세요.'])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.45k/1.45k [00:00<00:00, 485kB/s]\n",
      "Downloading: 100%|██████████| 496M/496M [00:44<00:00, 11.1MB/s]  \n"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('Sehong/kobart-QuestionGeneration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'BartForSequenceClassification' object has no attribute 'get_encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-fa69bf6b3110>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkobart_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"그게 있으면 당사자는 유리해지니까, 그걸 악용하는 일도 아주 쉬워진다고 생각해요.\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkobart_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkobart_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0meos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0moutput_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkobart_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;31m# add encoder_outputs to model_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m             \u001b[0mmodel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_encoder_decoder_kwargs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[1;31m# set input_ids as decoder_input_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, input_ids, model_kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m     ) -> Dict[str, Any]:\n\u001b[0;32m    374\u001b[0m         \u001b[1;31m# retrieve encoder hidden states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m         encoder_kwargs = {\n\u001b[0;32m    377\u001b[0m             \u001b[0margument\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0margument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0margument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"decoder_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 779\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'BartForSequenceClassification' object has no attribute 'get_encoder'"
     ]
    }
   ],
   "source": [
    "inputs = kobart_tokenizer([\"그게 있으면 당사자는 유리해지니까, 그걸 악용하는 일도 아주 쉬워진다고 생각해요.\"])\n",
    "input_ids = [kobart_tokenizer.bos_token_id] + inputs['input_ids'][0] + [kobart_tokenizer.eos_token_id]\n",
    "output = model.generate(torch.tensor([input_ids]), num_beams=4,  max_length=512,  eos_token_id=1)\n",
    "output_text = kobart_tokenizer.decode(*output)\n",
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\leejoon-byeong\\vsprojects\\TIL\\2022\\5\\.cache\\kobart_base_cased_ff4bda5738.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqModelOutput(last_hidden_state=tensor([[[ 1.5910,  2.5640,  1.3747,  ...,  1.5569, -2.0884,  1.0474],\n",
       "         [ 1.2950,  3.1038,  0.5874,  ..., -0.7788, -2.6099, -1.2955],\n",
       "         [ 0.0955,  1.1776, -1.2186,  ..., -0.8767, -0.4566,  1.9931],\n",
       "         ...,\n",
       "         [-0.2919,  5.5982, -0.7164,  ..., -1.3540, -1.3418,  1.8016],\n",
       "         [ 2.5879,  4.9507, -1.9064,  ..., -4.6818, -0.0630,  0.9077],\n",
       "         [ 1.7470,  3.4171, -0.3249,  ...,  1.3519, -5.5119, -0.4601]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), past_key_values=((tensor([[[[-0.0980, -0.6658, -1.8089,  ...,  0.9602, -0.1882, -1.3252],\n",
       "          [ 0.3193, -0.3126, -1.1064,  ...,  1.2095, -0.6838, -0.1999],\n",
       "          [-0.4619,  0.5222, -0.0483,  ..., -0.1861, -0.9331, -1.9777],\n",
       "          ...,\n",
       "          [ 0.6180,  0.6750,  1.0192,  ..., -0.5556, -0.0201, -1.5416],\n",
       "          [-0.6512,  0.3872,  0.9493,  ..., -1.8143,  0.0551, -1.6363],\n",
       "          [-1.0744,  0.7144,  0.6679,  ..., -1.1685,  0.6331, -2.1730]],\n",
       "\n",
       "         [[ 0.5460, -0.2399,  1.5901,  ...,  0.4365,  0.7951,  0.0899],\n",
       "          [-0.3874,  0.1520, -0.2866,  ...,  1.4500,  0.1341, -0.8373],\n",
       "          [-0.9559, -0.0140,  0.1974,  ..., -0.6377, -0.5705, -0.3805],\n",
       "          ...,\n",
       "          [-1.2089, -0.2550,  0.2856,  ...,  0.2147, -1.2255, -0.5103],\n",
       "          [-0.7849, -1.1702,  0.3202,  ..., -0.0446, -0.9980,  0.6151],\n",
       "          [-0.3047, -0.0058,  0.4399,  ..., -0.0768, -1.3859,  1.4365]],\n",
       "\n",
       "         [[ 1.4621,  1.8980, -0.7670,  ...,  1.5695,  0.0679, -0.3937],\n",
       "          [ 0.4253,  1.3003,  0.3111,  ...,  0.4402, -0.4776,  0.2804],\n",
       "          [-0.9022,  1.1841,  2.2055,  ..., -1.2888, -0.9599,  0.0395],\n",
       "          ...,\n",
       "          [-1.4167, -0.9874,  1.5692,  ..., -0.5505,  0.0746,  0.7960],\n",
       "          [-2.2800, -0.2638, -0.2711,  ...,  1.7619, -0.1382,  0.6785],\n",
       "          [-2.1814,  0.1577, -2.3321,  ...,  0.1530,  1.1731,  0.0386]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4887,  1.2633, -0.1166,  ..., -0.3199,  1.2202, -0.0790],\n",
       "          [-0.0174,  0.3663,  0.7628,  ..., -0.6306, -0.2474,  0.0723],\n",
       "          [ 0.4118, -0.3813,  0.6950,  ...,  1.9309, -0.2970,  0.1212],\n",
       "          ...,\n",
       "          [ 0.9256,  1.0946,  1.3340,  ..., -0.5638, -0.1982,  0.0050],\n",
       "          [-0.4167,  1.2203, -0.5556,  ..., -0.3231,  0.1248,  0.5229],\n",
       "          [ 0.1992,  0.2592,  0.4476,  ..., -0.1242,  0.0231, -1.6038]],\n",
       "\n",
       "         [[ 1.5854,  0.3246,  3.0826,  ..., -1.6728,  1.2071, -0.3567],\n",
       "          [-0.0465, -1.1574,  1.2660,  ...,  0.3990,  0.6414, -0.6437],\n",
       "          [ 0.4270, -0.4386,  0.1840,  ..., -1.2011,  0.1822, -0.3840],\n",
       "          ...,\n",
       "          [ 1.0526, -0.2017, -0.9437,  ...,  0.5719, -2.3324, -0.4082],\n",
       "          [-1.2254, -1.3547, -1.3281,  ..., -1.7556, -2.9536,  0.5323],\n",
       "          [-0.5224, -0.3490, -2.0725,  ...,  0.6816, -2.6522,  1.0940]],\n",
       "\n",
       "         [[ 0.8708, -0.4609, -2.8388,  ...,  1.6038, -1.0963, -0.1873],\n",
       "          [ 0.3314, -0.2727, -1.2393,  ...,  1.3338,  1.1844,  0.5025],\n",
       "          [-0.9832, -1.5591, -2.9091,  ...,  0.5685,  2.0929, -0.4950],\n",
       "          ...,\n",
       "          [-0.9899, -0.5036,  0.5154,  ...,  0.3603,  0.6623, -0.0257],\n",
       "          [-0.5023,  0.3046, -1.2328,  ...,  0.8051,  0.0549,  0.0232],\n",
       "          [-0.7997, -2.0098, -0.1828,  ...,  2.2296, -0.4811, -2.3755]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 2.1869e-01,  1.3322e+00, -1.6291e-03,  ..., -1.2005e-01,\n",
       "           -3.9491e-02,  9.7080e-02],\n",
       "          [ 8.1377e-02, -4.1508e-01, -1.8799e-01,  ..., -1.4759e-01,\n",
       "           -2.1547e-02,  9.5687e-02],\n",
       "          [ 1.7376e-01, -5.6084e-01, -2.6398e-01,  ...,  1.4446e-01,\n",
       "            5.4262e-01, -7.2005e-02],\n",
       "          ...,\n",
       "          [-3.3783e-01, -1.5189e-01,  4.5652e-01,  ..., -1.7985e-01,\n",
       "            1.5255e-02, -5.5458e-02],\n",
       "          [-1.1336e-02, -3.4214e-01, -1.3581e-01,  ...,  1.8519e-01,\n",
       "           -6.6445e-02, -5.1757e-01],\n",
       "          [-5.2776e-01, -4.5560e-01, -2.1157e-01,  ...,  3.3455e-02,\n",
       "            4.4225e-01, -6.3775e-01]],\n",
       "\n",
       "         [[ 1.4390e-01,  7.4313e-03,  2.4931e-02,  ...,  2.1482e-01,\n",
       "           -5.0158e-01,  1.2633e-01],\n",
       "          [ 1.9689e-01,  2.3088e-02, -2.2038e-01,  ..., -6.0789e-01,\n",
       "            6.4384e-01, -2.7129e-01],\n",
       "          [ 7.3137e-01,  8.0141e-01,  2.0903e-01,  ..., -1.5729e-01,\n",
       "            5.0176e-01, -1.0316e-02],\n",
       "          ...,\n",
       "          [-1.6840e-01,  6.9145e-02, -8.6295e-01,  ...,  1.4809e-01,\n",
       "            2.9638e-01,  3.8338e-01],\n",
       "          [ 1.2769e-01, -5.8584e-01,  1.9898e-01,  ..., -3.2237e-01,\n",
       "            3.4865e-01,  3.0843e-01],\n",
       "          [-1.7740e-01,  2.8206e-01,  1.0596e+00,  ...,  2.9206e-01,\n",
       "            3.3982e-01,  3.8538e-01]],\n",
       "\n",
       "         [[-8.6198e-02, -7.2890e-03, -4.7940e-02,  ...,  1.1030e-02,\n",
       "            1.9806e-02,  1.9093e-01],\n",
       "          [ 1.3720e-02, -1.2560e-01, -1.8786e-02,  ...,  1.6112e-01,\n",
       "            1.7621e-02,  2.2448e-01],\n",
       "          [ 4.8760e-01, -4.6191e-01,  4.3442e-02,  ..., -1.3900e-01,\n",
       "           -2.9805e-02,  6.6834e-02],\n",
       "          ...,\n",
       "          [-8.4123e-01,  3.1633e-01, -3.9461e-01,  ...,  3.9654e-01,\n",
       "            1.8807e-01, -6.0610e-01],\n",
       "          [-5.3630e-01, -1.6091e-02, -7.9899e-02,  ..., -2.6289e-01,\n",
       "           -1.4267e-03,  1.7589e-01],\n",
       "          [ 5.1291e-01, -1.9005e-01,  3.6342e-01,  ...,  3.1147e-02,\n",
       "           -2.0891e-01, -7.0763e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.6785e-02, -1.3294e-01,  1.8621e-01,  ..., -4.8933e-02,\n",
       "           -8.4042e-03,  1.5098e-02],\n",
       "          [ 1.4429e-01,  3.1051e-01, -3.2807e-01,  ..., -6.9052e-02,\n",
       "           -3.9413e-02, -7.0818e-02],\n",
       "          [ 2.7982e-01, -4.1093e-02, -5.0011e-01,  ..., -1.7115e-01,\n",
       "            3.5744e-01,  2.6670e-02],\n",
       "          ...,\n",
       "          [-8.4216e-02, -3.3489e-01, -1.0744e-01,  ...,  4.7215e-01,\n",
       "            3.5259e-01,  1.2382e-01],\n",
       "          [-7.8875e-02,  4.9735e-02, -2.4204e-01,  ...,  1.9269e-01,\n",
       "           -1.2434e-02,  6.7849e-02],\n",
       "          [-1.1449e-01, -4.1389e-01, -1.3875e-01,  ...,  3.8461e-01,\n",
       "            1.7393e-01, -7.8139e-01]],\n",
       "\n",
       "         [[ 1.2563e-01,  1.1696e-01,  9.1216e-02,  ...,  6.2305e-02,\n",
       "           -5.7390e-02,  6.1103e-02],\n",
       "          [ 6.8706e-02,  8.7275e-02, -1.1350e-02,  ...,  1.4822e-02,\n",
       "            4.6517e-02, -2.7850e-02],\n",
       "          [ 1.9619e-01, -1.9311e-01,  4.5915e-01,  ..., -2.9901e-01,\n",
       "            2.8785e-01,  3.0531e-01],\n",
       "          ...,\n",
       "          [ 5.2875e-01, -1.7547e-01, -6.7282e-01,  ..., -1.7818e-01,\n",
       "           -1.6626e-01,  2.4416e-01],\n",
       "          [-7.9164e-01, -1.7919e-01,  2.8401e-01,  ...,  1.9505e-01,\n",
       "            4.7852e-01,  4.9824e-01],\n",
       "          [-8.5332e-01, -5.7312e-01, -5.8149e-01,  ...,  3.7065e-02,\n",
       "            1.3622e-01, -2.0370e-01]],\n",
       "\n",
       "         [[ 7.0189e-02,  2.2690e-02,  3.1148e-02,  ..., -2.0265e-02,\n",
       "            6.0246e-02,  3.3156e-03],\n",
       "          [-3.7221e-02, -8.5510e-02, -2.1313e-01,  ..., -2.8858e-04,\n",
       "           -1.3219e-01,  6.3911e-02],\n",
       "          [ 5.8555e-01,  5.6879e-01, -8.5600e-01,  ...,  1.2682e-01,\n",
       "           -3.9213e-01, -5.5489e-01],\n",
       "          ...,\n",
       "          [ 1.3135e-01,  6.5995e-01, -9.7305e-02,  ...,  2.7139e-02,\n",
       "            1.0793e-01,  1.7651e-01],\n",
       "          [ 1.3536e-01,  4.3742e-01, -1.9834e-01,  ...,  2.8876e-02,\n",
       "            7.4212e-02,  2.9428e-01],\n",
       "          [ 3.5906e-01, -3.4744e-01, -5.2295e-01,  ..., -3.0950e-01,\n",
       "            6.8466e-01, -3.4948e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 1.2018, -2.1242, -0.3600,  ...,  1.0865, -0.0462,  1.1819],\n",
       "          [ 0.0807, -2.5211, -0.6341,  ...,  1.9512,  1.9520,  0.9778],\n",
       "          [ 0.0148, -1.6511, -0.4534,  ...,  0.8939, -0.1337, -0.1978],\n",
       "          ...,\n",
       "          [-0.3976, -1.7061, -0.6934,  ..., -0.7256, -0.6717,  1.3095],\n",
       "          [ 0.5231, -1.2830,  0.2541,  ..., -0.4175, -1.2454,  0.2385],\n",
       "          [-0.7175,  0.8112, -0.2112,  ...,  0.1360, -0.5836,  0.7151]],\n",
       "\n",
       "         [[-0.3594,  0.5862,  0.8117,  ...,  0.7733,  1.3617,  0.3958],\n",
       "          [-0.8853, -0.1168, -0.0676,  ...,  0.4887,  0.2306,  1.5280],\n",
       "          [-1.3882,  0.4890, -0.5870,  ...,  0.7068,  1.1101, -0.3321],\n",
       "          ...,\n",
       "          [ 0.3186, -0.1331, -0.0849,  ...,  0.4019,  0.5413, -0.4379],\n",
       "          [ 0.5099,  0.7519,  0.3689,  ...,  0.7430,  1.2674, -0.2500],\n",
       "          [-0.7097,  0.5786,  0.2450,  ...,  0.6895, -0.2998,  1.1776]],\n",
       "\n",
       "         [[ 0.1823,  1.2227, -0.2570,  ...,  0.3726, -0.4629, -0.5241],\n",
       "          [ 1.9248, -0.2845, -0.5591,  ...,  0.6360, -0.3685,  0.2096],\n",
       "          [ 0.9133, -0.5931, -0.4029,  ...,  0.2500, -0.0653, -0.0771],\n",
       "          ...,\n",
       "          [ 0.3331,  0.0724, -0.0596,  ...,  0.5020, -0.1913, -1.0760],\n",
       "          [ 0.7142, -0.2259, -0.8561,  ...,  0.0337, -0.3185, -0.1968],\n",
       "          [ 1.7395, -1.7558,  0.3191,  ..., -0.7466, -1.0141,  0.4453]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2531,  0.8287,  0.0154,  ..., -0.0131, -0.4808,  0.2039],\n",
       "          [-0.8081, -0.5556,  0.1401,  ..., -0.4674, -1.7237,  0.5001],\n",
       "          [-1.1122, -1.0244,  0.1792,  ...,  0.0643, -1.4604, -0.4231],\n",
       "          ...,\n",
       "          [ 0.4798, -0.0388, -0.0425,  ...,  1.2130,  0.8382, -0.1407],\n",
       "          [ 0.1964,  0.2114,  0.1230,  ...,  0.3795,  1.1037, -0.1388],\n",
       "          [ 0.0980, -0.5310, -0.3326,  ...,  0.3186,  0.0492,  0.2322]],\n",
       "\n",
       "         [[ 0.8111,  0.4732,  0.3426,  ..., -1.1109,  1.0642,  0.4494],\n",
       "          [-0.4300,  0.3881, -1.5612,  ...,  1.4328,  0.4334, -0.0356],\n",
       "          [-0.3394,  0.0142, -1.9284,  ...,  0.8491, -0.8928,  1.2409],\n",
       "          ...,\n",
       "          [ 0.4569, -1.3210, -3.1617,  ...,  0.3204, -1.2105, -0.2477],\n",
       "          [ 0.5071, -0.5252, -2.8523,  ..., -0.4868, -0.8825,  0.6634],\n",
       "          [-0.6638, -0.5613,  0.3220,  ..., -0.2757, -0.1880,  0.2586]],\n",
       "\n",
       "         [[-0.3399, -0.0963,  0.0083,  ..., -0.5848, -0.8462,  0.3099],\n",
       "          [-0.7669,  0.0262,  0.1151,  ..., -0.5076, -1.0486,  1.1637],\n",
       "          [ 0.1714, -0.0778,  0.3359,  ...,  0.1321, -0.3680,  0.2073],\n",
       "          ...,\n",
       "          [ 0.5591,  2.3105,  0.7708,  ..., -0.4601, -2.3614, -0.2423],\n",
       "          [ 0.1783,  2.4647,  0.7609,  ...,  0.4281, -1.6593,  0.3640],\n",
       "          [ 0.4395,  0.2067, -0.6439,  ...,  0.4080,  0.0124,  0.3382]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 2.5662e-01,  9.7769e-01, -7.6888e-01,  ..., -1.4879e-01,\n",
       "            1.5504e-03, -6.6607e-01],\n",
       "          [ 5.6709e-01,  1.4698e+00, -8.0362e-01,  ...,  2.7564e-01,\n",
       "            6.3883e-01,  4.9258e-01],\n",
       "          [ 1.1087e+00,  1.3923e+00, -1.0262e-01,  ...,  6.1675e-01,\n",
       "           -3.0398e-01, -2.4334e-01],\n",
       "          ...,\n",
       "          [ 2.5451e-01,  2.6739e-01,  2.1333e-01,  ..., -2.2173e-03,\n",
       "           -3.9546e-01, -4.8141e-02],\n",
       "          [ 7.3364e-02,  8.2997e-01,  1.3428e-01,  ...,  1.1504e-01,\n",
       "           -4.3422e-02, -2.0037e-01],\n",
       "          [ 1.5047e-02, -3.6097e-02, -8.4658e-02,  ...,  7.0816e-03,\n",
       "            3.1138e-02,  9.7295e-02]],\n",
       "\n",
       "         [[ 5.4783e-01,  2.9875e-01, -1.7981e-01,  ...,  2.2901e-01,\n",
       "           -4.2050e-01, -6.1047e-01],\n",
       "          [ 1.7110e-01, -5.3383e-03, -1.5062e-01,  ..., -8.5731e-02,\n",
       "           -1.2128e+00,  4.2047e-01],\n",
       "          [-3.1707e-01, -3.6604e-01,  4.1912e-01,  ..., -4.0836e-01,\n",
       "           -1.4493e+00, -9.9315e-01],\n",
       "          ...,\n",
       "          [-3.9447e-01, -1.7868e-01, -3.3570e-01,  ..., -4.9590e-01,\n",
       "            3.2277e-01,  6.1249e-01],\n",
       "          [-8.2073e-01, -2.1362e-01,  5.1355e-01,  ..., -2.3263e-01,\n",
       "            6.1107e-01,  8.2925e-01],\n",
       "          [-1.0931e+00, -6.8515e-01, -1.7943e-01,  ...,  1.5417e-01,\n",
       "            3.9991e-01, -2.4114e-01]],\n",
       "\n",
       "         [[-9.6932e-02,  8.2023e-01, -5.2236e-01,  ..., -7.8545e-01,\n",
       "            2.5715e-02,  8.2939e-01],\n",
       "          [-7.6372e-01, -1.2210e-01,  1.8373e-01,  ..., -9.4401e-01,\n",
       "           -1.2901e-01,  4.9417e-01],\n",
       "          [ 2.0111e-01,  2.7366e-01, -2.4799e-01,  ...,  1.4580e-01,\n",
       "            1.4182e-01,  1.9935e-01],\n",
       "          ...,\n",
       "          [ 9.0143e-01, -1.0043e+00, -7.7346e-01,  ...,  1.3130e+00,\n",
       "            4.2137e-01, -6.3094e-02],\n",
       "          [ 3.4896e-01, -1.0752e+00, -5.4007e-01,  ...,  6.2237e-01,\n",
       "            1.6913e-01, -3.6715e-01],\n",
       "          [-8.1926e-01, -1.6014e-01,  3.6440e-01,  ...,  1.7890e-01,\n",
       "            3.3091e-02, -2.4902e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.8532e-02,  6.1112e-01,  1.9099e-01,  ...,  8.1381e-02,\n",
       "            1.1497e+00,  2.3954e-02],\n",
       "          [-2.2009e-02,  7.1385e-01,  8.7289e-01,  ...,  1.0408e-01,\n",
       "            7.4196e-01,  3.2706e-02],\n",
       "          [-9.9208e-02,  2.3242e-01,  9.9846e-02,  ...,  5.1748e-01,\n",
       "            1.0834e+00, -8.5444e-02],\n",
       "          ...,\n",
       "          [ 3.4121e-01,  9.0641e-02, -3.7992e-01,  ...,  3.8860e-01,\n",
       "            2.0989e-01, -1.3891e+00],\n",
       "          [-8.5482e-02,  3.9595e-01, -1.1043e-01,  ...,  5.7198e-02,\n",
       "            7.3333e-01, -1.2349e+00],\n",
       "          [ 4.4426e-01,  4.2015e-01,  8.0114e-01,  ..., -2.8965e+00,\n",
       "           -5.4037e-01,  2.5791e-01]],\n",
       "\n",
       "         [[-6.9084e-01, -2.1357e-01, -7.7627e-02,  ..., -5.0653e-02,\n",
       "           -4.9299e-01,  5.3270e-02],\n",
       "          [-1.1315e-01,  4.2053e-01,  3.2382e-01,  ..., -1.0211e+00,\n",
       "            3.8701e-01,  1.7409e-01],\n",
       "          [ 1.3702e-01,  1.0221e+00,  1.2003e+00,  ...,  3.7076e-01,\n",
       "           -9.2975e-01, -9.5548e-04],\n",
       "          ...,\n",
       "          [ 4.3344e-01, -3.0090e-01, -2.3873e-01,  ..., -6.7886e-01,\n",
       "            5.9562e-01, -1.1256e-01],\n",
       "          [-5.1483e-01, -7.0973e-01,  4.8923e-02,  ..., -5.6237e-01,\n",
       "           -1.7873e-01,  3.0911e-01],\n",
       "          [ 8.5868e-01,  2.0858e-01, -1.8725e-01,  ...,  2.8936e-01,\n",
       "            1.6064e-01, -2.2871e-01]],\n",
       "\n",
       "         [[ 7.0956e-01, -3.7260e-01, -6.5605e-01,  ..., -1.1048e+00,\n",
       "           -6.2454e-01,  6.3009e-01],\n",
       "          [-5.1892e-02, -1.1219e+00,  2.2151e-01,  ..., -1.1701e+00,\n",
       "           -7.5099e-01, -5.3297e-01],\n",
       "          [ 7.1807e-01, -1.6982e-01,  1.1498e+00,  ..., -4.4052e-01,\n",
       "           -1.4037e+00,  4.2641e-01],\n",
       "          ...,\n",
       "          [-2.6150e-01,  1.1248e-01,  6.0909e-01,  ...,  7.2734e-01,\n",
       "           -5.9576e-01,  5.5078e-01],\n",
       "          [ 3.1565e-01,  4.0248e-01, -2.1129e-01,  ...,  8.5758e-01,\n",
       "            8.3932e-02, -1.4919e-01],\n",
       "          [-1.9908e-01,  3.1318e-01,  7.3118e-01,  ...,  2.1152e-01,\n",
       "           -1.2638e-01,  9.3561e-01]]]], grad_fn=<CopyBackwards>)), (tensor([[[[ 9.9927e-03,  2.0362e-01,  2.8391e-01,  ..., -8.5959e-02,\n",
       "           -1.6640e-01, -2.6245e-02],\n",
       "          [ 1.2316e-01, -1.6031e+00, -1.2892e+00,  ..., -7.5414e-01,\n",
       "            8.4991e-01, -1.7974e+00],\n",
       "          [ 4.5277e-02,  1.6040e-01,  1.9619e-01,  ..., -8.3728e-02,\n",
       "           -1.4974e-01, -5.7875e-02],\n",
       "          ...,\n",
       "          [ 3.8539e-01, -1.4817e+00, -3.9091e-01,  ...,  1.2591e+00,\n",
       "            3.1860e+00,  1.7373e+00],\n",
       "          [ 1.9363e-01, -2.3983e+00, -7.3408e-01,  ...,  1.4076e-01,\n",
       "            1.7354e+00, -2.7694e-01],\n",
       "          [ 1.1326e+00, -2.9049e+00, -1.4573e-01,  ...,  1.5977e+00,\n",
       "            2.4120e+00, -8.6326e-01]],\n",
       "\n",
       "         [[ 1.5503e-01, -4.1775e-01, -3.6249e-01,  ...,  2.5254e-01,\n",
       "           -1.1138e-01,  1.4275e+00],\n",
       "          [ 3.2361e-01,  7.5270e-01,  5.3001e-01,  ..., -9.8694e-01,\n",
       "           -8.9875e-02, -3.2847e+00],\n",
       "          [ 8.2555e-02, -4.1741e-01, -2.8708e-01,  ...,  2.1725e-01,\n",
       "           -5.3289e-02,  1.2769e+00],\n",
       "          ...,\n",
       "          [-7.1560e-01,  2.1294e+00,  1.2408e+00,  ..., -1.4639e+00,\n",
       "            8.2105e-01, -5.2308e+00],\n",
       "          [-7.2380e-01,  4.0007e-01,  3.7365e+00,  ..., -6.1867e-01,\n",
       "            2.6658e+00, -4.0198e+00],\n",
       "          [-9.8234e-01,  1.2357e+00,  3.0927e+00,  ...,  5.4959e-01,\n",
       "            9.2842e-01, -4.1842e+00]],\n",
       "\n",
       "         [[-9.8974e-02,  6.6254e-01, -5.0638e-01,  ...,  4.2780e-02,\n",
       "           -1.2090e+00, -3.6762e-01],\n",
       "          [-7.0836e-01, -4.2480e+00,  1.4855e+00,  ...,  2.8556e+00,\n",
       "            1.4045e+00,  2.3309e+00],\n",
       "          [-1.0388e-01,  5.9228e-01, -5.0196e-01,  ...,  7.0810e-02,\n",
       "           -1.1058e+00, -2.6536e-01],\n",
       "          ...,\n",
       "          [-6.5590e-01, -2.5084e+00, -8.6009e-01,  ...,  1.8491e+00,\n",
       "            3.3987e+00,  3.1740e+00],\n",
       "          [ 1.2153e+00, -2.7989e+00, -4.9514e-01,  ...,  3.6839e+00,\n",
       "            2.2429e+00,  8.6230e-01],\n",
       "          [ 9.7581e-01, -3.3019e+00, -1.3768e+00,  ...,  1.8429e+00,\n",
       "            3.0495e+00,  2.1058e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7249e-02,  9.1983e-02,  1.7138e-01,  ...,  5.0174e-02,\n",
       "            1.3064e-01,  1.0235e+00],\n",
       "          [-1.3537e-01, -1.0525e+00, -6.4640e-01,  ...,  6.8286e-02,\n",
       "            5.3818e-01, -9.3786e-01],\n",
       "          [ 2.0640e-02,  3.1683e-02,  1.6122e-01,  ...,  4.7642e-02,\n",
       "            1.1779e-01,  9.3556e-01],\n",
       "          ...,\n",
       "          [-1.1516e+00, -7.2115e-02, -1.9682e+00,  ..., -6.3739e-01,\n",
       "           -1.0719e-02, -2.0717e+00],\n",
       "          [-3.1350e-01, -9.1703e-01, -1.2717e+00,  ..., -9.9536e-01,\n",
       "            5.4059e-01, -1.4080e+00],\n",
       "          [-3.3715e-02,  5.0819e-01, -7.8940e-01,  ..., -1.8575e+00,\n",
       "           -2.0784e-01, -8.6892e-01]],\n",
       "\n",
       "         [[ 1.3329e-01,  2.0704e-01, -4.0424e-03,  ..., -6.7127e-02,\n",
       "           -2.6968e-01,  1.3482e-01],\n",
       "          [-6.0044e-01,  1.5259e-02, -1.0245e+00,  ...,  1.8594e-01,\n",
       "           -3.3278e-03, -3.7119e-01],\n",
       "          [ 1.2942e-01,  1.6360e-01, -4.5296e-02,  ..., -8.6709e-02,\n",
       "           -1.9641e-01,  6.8002e-02],\n",
       "          ...,\n",
       "          [-7.9924e-01, -1.6646e-01,  1.0734e+00,  ...,  4.8706e-01,\n",
       "            1.6988e+00,  1.3046e+00],\n",
       "          [-4.1689e-01, -1.3926e+00,  2.9764e-01,  ..., -4.5270e-01,\n",
       "           -3.9286e-01, -4.7126e-01],\n",
       "          [ 8.3968e-01,  9.9738e-01, -2.8560e-01,  ..., -2.5005e-01,\n",
       "            1.3961e+00, -5.0472e-01]],\n",
       "\n",
       "         [[ 3.4195e-01,  1.9873e-01,  4.0800e-01,  ..., -1.3828e-01,\n",
       "           -5.4173e-02,  3.0190e-01],\n",
       "          [ 3.8884e-01, -1.0268e+00, -1.4550e+00,  ..., -1.4302e-01,\n",
       "            4.9223e-01, -1.2826e+00],\n",
       "          [ 3.3892e-01,  1.4995e-01,  3.4199e-01,  ..., -1.3519e-01,\n",
       "           -8.1160e-03,  2.3121e-01],\n",
       "          ...,\n",
       "          [ 6.5313e-01, -1.3420e+00,  1.4367e-01,  ...,  1.9019e-02,\n",
       "            2.4512e+00,  2.1993e-01],\n",
       "          [ 7.3971e-01,  7.3338e-01, -1.7306e-01,  ...,  8.7207e-01,\n",
       "            2.3242e+00, -1.8567e+00],\n",
       "          [-5.2464e-01,  1.2197e+00,  7.6325e-01,  ..., -5.6333e-01,\n",
       "            4.1627e-01, -2.7843e+00]]]], grad_fn=<CopyBackwards>), tensor([[[[-1.4715e-02,  1.6211e-02,  1.6042e-02,  ..., -1.3972e-02,\n",
       "           -1.2170e-04, -1.1264e-02],\n",
       "          [ 3.4853e-01,  1.1522e-01, -3.6191e-01,  ..., -1.5616e-01,\n",
       "           -9.8087e-02,  1.1270e-01],\n",
       "          [-1.8790e-02,  1.4832e-02,  2.4127e-02,  ..., -3.1474e-03,\n",
       "            9.1658e-03,  1.3238e-02],\n",
       "          ...,\n",
       "          [-1.7934e-01,  2.9478e-02,  1.6597e-01,  ..., -1.4434e-01,\n",
       "           -3.5666e-01, -7.0307e-01],\n",
       "          [ 8.9003e-01,  1.5525e-01, -6.8089e-01,  ..., -1.7012e-01,\n",
       "           -3.8898e-01, -3.9627e-02],\n",
       "          [ 5.4161e-01, -3.5895e-01, -2.7929e-01,  ...,  2.5026e-01,\n",
       "            3.0833e-01,  1.0437e-01]],\n",
       "\n",
       "         [[-1.1027e-02, -1.9882e-02, -4.6626e-02,  ..., -1.4117e-02,\n",
       "           -9.5754e-03, -2.5675e-02],\n",
       "          [-5.6898e-01, -6.3811e-01, -7.6156e-01,  ..., -3.8731e-02,\n",
       "            3.0907e-02, -3.3597e-01],\n",
       "          [-1.7192e-02, -1.2242e-02, -4.6846e-02,  ...,  1.4059e-02,\n",
       "           -1.9007e-02,  9.0187e-03],\n",
       "          ...,\n",
       "          [ 1.3326e-01, -5.1013e-01,  4.2589e-01,  ...,  6.4620e-01,\n",
       "            6.9172e-01, -3.7785e-02],\n",
       "          [ 8.5221e-02,  1.2857e+00,  2.5707e-01,  ...,  4.4552e-01,\n",
       "            1.2224e+00,  4.3562e-01],\n",
       "          [ 3.6988e-02,  7.5367e-01,  3.2760e-01,  ...,  4.6891e-01,\n",
       "            4.4599e-01,  6.8625e-01]],\n",
       "\n",
       "         [[ 3.2813e-02, -1.6660e-02, -3.3008e-02,  ..., -1.0979e-02,\n",
       "            3.0053e-03, -4.9714e-02],\n",
       "          [-1.2984e-01,  2.2768e-02,  3.0181e-01,  ...,  2.8329e-02,\n",
       "           -1.6551e-01,  9.6231e-02],\n",
       "          [ 3.9612e-02, -1.9990e-02, -3.0225e-02,  ..., -2.5834e-03,\n",
       "           -2.5052e-02, -4.7277e-02],\n",
       "          ...,\n",
       "          [-2.5168e-01,  4.4259e-01, -8.0002e-01,  ..., -9.0770e-02,\n",
       "            4.7449e-01,  2.6597e-02],\n",
       "          [ 5.2561e-01,  5.2763e-01,  3.2623e-01,  ..., -4.2988e-02,\n",
       "            2.0129e-01,  8.8164e-01],\n",
       "          [ 9.1607e-01,  5.3136e-01,  1.1553e-01,  ...,  4.0137e-01,\n",
       "           -5.0298e-01,  5.3270e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4227e-02, -3.2706e-02, -7.1165e-02,  ..., -1.9583e-02,\n",
       "            9.9361e-04,  1.2411e-02],\n",
       "          [-4.8983e-02, -6.2986e-01,  4.4238e-02,  ..., -7.0887e-02,\n",
       "            4.5945e-01, -3.8091e-01],\n",
       "          [ 7.4060e-03, -3.5590e-02, -9.1606e-02,  ..., -1.2685e-03,\n",
       "           -3.1725e-02,  1.2968e-02],\n",
       "          ...,\n",
       "          [-5.3475e-01, -3.7589e-02,  5.5970e-01,  ..., -1.2899e-01,\n",
       "            5.1841e-01, -6.5219e-01],\n",
       "          [-1.4102e+00, -5.0775e-01,  8.6571e-02,  ..., -2.5010e-01,\n",
       "           -6.4806e-01,  7.8118e-01],\n",
       "          [-5.3833e-01, -4.8725e-02,  9.1979e-01,  ..., -1.2733e-01,\n",
       "           -3.0105e-01,  5.3762e-01]],\n",
       "\n",
       "         [[ 8.1538e-04, -1.0758e-02, -1.9091e-02,  ...,  2.5434e-02,\n",
       "            2.3786e-03, -2.3707e-02],\n",
       "          [ 5.3751e-01,  3.8376e-01, -1.5250e-01,  ...,  1.9641e-01,\n",
       "            2.7584e-01, -2.3350e-01],\n",
       "          [-5.2376e-03, -4.9644e-03, -3.0935e-02,  ...,  1.5417e-02,\n",
       "            1.2415e-02, -4.2380e-03],\n",
       "          ...,\n",
       "          [-8.2584e-01, -1.1918e-01,  3.2866e-01,  ..., -9.3903e-01,\n",
       "            1.6696e-01,  3.8500e-03],\n",
       "          [-4.0158e-01, -7.1006e-01, -5.9811e-01,  ..., -3.6980e-01,\n",
       "            1.3662e+00, -3.4487e-01],\n",
       "          [-4.9202e-01,  2.7971e-01,  4.0735e-05,  ..., -8.9399e-01,\n",
       "            6.4075e-01, -7.7518e-01]],\n",
       "\n",
       "         [[ 2.3202e-02,  1.3538e-02,  1.2573e-02,  ...,  2.9410e-02,\n",
       "            2.0381e-02, -2.4350e-02],\n",
       "          [-6.2076e-01, -1.9581e-01,  8.9323e-01,  ...,  7.4045e-01,\n",
       "            2.4003e-01,  8.9242e-01],\n",
       "          [ 1.0364e-03, -2.0674e-04,  1.3382e-02,  ...,  2.8890e-02,\n",
       "            2.8872e-02, -6.5260e-02],\n",
       "          ...,\n",
       "          [-1.5237e-01, -5.2362e-01, -8.1405e-01,  ...,  2.5847e-02,\n",
       "            1.2742e-01, -7.9563e-01],\n",
       "          [ 6.4962e-01,  7.1183e-01, -6.5015e-01,  ..., -8.9700e-01,\n",
       "           -8.9293e-02,  3.9264e-01],\n",
       "          [ 4.7258e-01, -6.8799e-02, -6.1677e-01,  ..., -2.9936e-01,\n",
       "            2.3542e-01, -1.4542e-02]]]], grad_fn=<CopyBackwards>), tensor([[[[ 1.0005e+00,  8.8865e-01, -3.2312e-01,  ...,  7.4949e-01,\n",
       "           -9.3392e-01,  9.9067e-02],\n",
       "          [ 1.6290e+00, -1.6325e-01,  3.7201e-01,  ...,  1.0403e+00,\n",
       "           -1.9913e+00,  1.1691e+00],\n",
       "          [ 5.7219e-01, -6.0521e-01,  6.0030e-01,  ..., -6.4943e-01,\n",
       "           -9.1180e-01,  1.3724e+00],\n",
       "          ...,\n",
       "          [ 1.8969e+00, -7.4593e-01,  9.5027e-01,  ..., -1.4870e-01,\n",
       "            5.6457e-01,  4.4402e-01],\n",
       "          [ 1.3815e+00,  7.0938e-01,  1.7171e+00,  ...,  9.0582e-01,\n",
       "            7.6077e-01,  5.0295e-01],\n",
       "          [ 7.7626e-01,  1.0699e+00,  5.0696e-01,  ..., -2.0051e+00,\n",
       "           -3.3714e-01, -6.2730e-01]],\n",
       "\n",
       "         [[ 1.4379e+00, -1.2388e+00,  1.2842e+00,  ...,  5.9829e-02,\n",
       "            3.5976e-03, -8.2028e-01],\n",
       "          [ 1.6833e+00, -3.1710e+00,  7.0419e-01,  ...,  5.3712e-03,\n",
       "           -3.4900e-01, -9.1746e-01],\n",
       "          [ 1.7884e+00, -2.4504e+00,  8.5789e-01,  ...,  6.9636e-01,\n",
       "            5.2626e-01, -6.6682e-01],\n",
       "          ...,\n",
       "          [ 3.0201e+00, -3.5978e+00, -4.6013e-01,  ...,  2.2399e-01,\n",
       "           -2.8300e-01, -9.1620e-01],\n",
       "          [ 2.4529e+00, -3.8194e+00, -3.9419e-01,  ...,  2.0160e-01,\n",
       "            6.0352e-01, -1.0475e+00],\n",
       "          [ 2.7411e+00, -2.1491e+00,  7.5399e-01,  ..., -1.2466e+00,\n",
       "           -1.5362e+00,  1.7495e+00]],\n",
       "\n",
       "         [[-7.4472e-01,  1.5803e-01,  3.0009e-02,  ...,  1.6034e+00,\n",
       "           -2.3893e-01,  7.0525e-01],\n",
       "          [ 4.9748e-01, -2.4646e-01,  9.3049e-01,  ...,  1.9421e+00,\n",
       "           -1.4486e+00,  1.2812e+00],\n",
       "          [-5.5045e-01, -9.4427e-01,  1.0137e-01,  ...,  1.8812e-01,\n",
       "           -1.0494e-01,  7.6781e-01],\n",
       "          ...,\n",
       "          [-1.2426e+00,  7.4225e-01,  5.7290e-01,  ...,  5.8059e-01,\n",
       "           -2.5796e+00, -1.3193e+00],\n",
       "          [-1.0896e+00,  7.9164e-01, -2.1325e-01,  ..., -1.6775e-01,\n",
       "           -1.4106e+00, -9.9403e-01],\n",
       "          [-3.3869e-01, -1.4791e+00, -1.1308e+00,  ...,  1.9206e+00,\n",
       "            1.1543e+00, -9.7354e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.5471e-01, -1.1205e+00, -5.0089e-01,  ...,  7.3872e-02,\n",
       "            5.0740e-01, -3.3951e-01],\n",
       "          [-5.8641e-01, -1.6813e-01,  1.9027e+00,  ..., -6.8007e-01,\n",
       "            1.5390e+00, -2.1268e+00],\n",
       "          [ 2.9470e-01, -5.2591e-01,  1.2885e-01,  ..., -1.8289e-01,\n",
       "            2.0543e-01, -1.7608e+00],\n",
       "          ...,\n",
       "          [ 6.4569e-01, -9.8301e-01,  1.6064e+00,  ..., -7.8745e-01,\n",
       "           -3.3683e-01, -5.6315e-01],\n",
       "          [ 2.8836e-02, -7.3702e-01,  1.3556e+00,  ..., -2.1683e+00,\n",
       "           -2.3726e-01,  1.5732e-01],\n",
       "          [ 3.3491e-01,  4.3413e-01, -6.6882e-01,  ..., -7.3355e-01,\n",
       "           -1.2538e+00, -4.1276e-01]],\n",
       "\n",
       "         [[-2.1103e+00,  9.5479e-01, -7.1373e-01,  ..., -1.4478e+00,\n",
       "            5.9079e-01,  2.9719e-01],\n",
       "          [-1.5691e+00, -7.7827e-01, -2.3897e+00,  ..., -4.3147e-01,\n",
       "            2.8894e-01,  4.8693e-01],\n",
       "          [-4.0637e-01, -1.4142e-01, -2.0798e+00,  ..., -5.2754e-01,\n",
       "            9.9975e-01, -1.0304e+00],\n",
       "          ...,\n",
       "          [-2.1714e+00, -1.0273e+00, -1.1093e+00,  ..., -1.3853e+00,\n",
       "           -5.0255e-02,  1.3733e+00],\n",
       "          [-2.3437e+00, -1.8532e-01, -1.2147e+00,  ..., -6.8437e-01,\n",
       "            1.4746e+00,  1.7757e-02],\n",
       "          [ 4.6824e-01, -2.8609e-01, -7.8810e-01,  ...,  1.7214e+00,\n",
       "           -2.1928e+00,  9.0908e-01]],\n",
       "\n",
       "         [[-3.6446e-01, -4.5647e-02,  4.0260e-01,  ...,  2.2578e-01,\n",
       "           -1.5655e+00, -1.9404e+00],\n",
       "          [-6.0591e-01, -9.5140e-01,  1.9431e-01,  ...,  1.6542e+00,\n",
       "           -8.0293e-01, -1.3566e+00],\n",
       "          [-1.5984e+00, -1.6304e+00,  1.1443e+00,  ...,  3.1869e-01,\n",
       "           -4.0352e-01, -6.5709e-01],\n",
       "          ...,\n",
       "          [ 4.4205e-01, -3.4035e-01,  6.2876e-01,  ...,  1.4110e+00,\n",
       "           -1.2695e+00,  8.4432e-01],\n",
       "          [ 9.7596e-01, -9.1389e-03,  8.5560e-01,  ...,  1.1242e+00,\n",
       "           -8.6855e-01,  5.5673e-01],\n",
       "          [ 4.7841e-01, -3.0745e+00,  8.8697e-01,  ...,  3.7198e-02,\n",
       "           -1.8216e+00,  3.4160e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 4.3740e-02, -7.0026e-03,  8.7396e-02,  ..., -1.2951e-01,\n",
       "            3.2994e-01,  7.7491e-02],\n",
       "          [-5.0964e-02,  1.9368e-01, -2.9010e-01,  ..., -4.1494e-01,\n",
       "            6.7293e-01,  2.0363e-01],\n",
       "          [ 2.3723e-01,  1.7661e-01,  3.2684e-01,  ...,  2.4664e-01,\n",
       "            2.2361e-01,  3.7287e-01],\n",
       "          ...,\n",
       "          [ 7.3454e-01,  3.7216e-02,  3.0882e-01,  ..., -3.6372e-01,\n",
       "           -9.5765e-02,  3.0626e-01],\n",
       "          [ 2.6725e-01, -1.3817e-01,  1.9143e-01,  ..., -7.3675e-01,\n",
       "           -8.7573e-02,  2.4472e-02],\n",
       "          [-6.8536e-04,  9.5573e-02, -1.0779e-01,  ...,  2.2236e-01,\n",
       "            6.4181e-02,  1.3236e-01]],\n",
       "\n",
       "         [[-5.4955e-01, -1.6107e-01,  2.6597e-01,  ...,  2.4531e-01,\n",
       "           -7.9971e-01, -2.1539e-01],\n",
       "          [-4.4338e-01,  1.5915e-01,  2.0618e-01,  ...,  1.3449e-01,\n",
       "           -4.6859e-02,  2.0260e-01],\n",
       "          [-1.7134e-01,  2.1119e-01, -2.2399e-01,  ...,  4.4017e-01,\n",
       "            3.3030e-01,  9.7505e-01],\n",
       "          ...,\n",
       "          [ 1.6782e-02, -1.6606e+00, -3.4736e-01,  ..., -4.9724e-02,\n",
       "            4.0143e-02, -2.8424e-01],\n",
       "          [ 2.9416e-01, -1.5511e-01,  2.2505e-01,  ..., -1.1493e-01,\n",
       "           -4.9580e-01, -1.3280e-01],\n",
       "          [ 1.6007e-01,  1.6548e-02,  5.8567e-01,  ...,  9.5761e-02,\n",
       "           -1.6540e-02,  1.6672e-03]],\n",
       "\n",
       "         [[ 4.4206e-02,  2.2314e-01, -1.1653e-01,  ..., -3.3315e-01,\n",
       "            8.4780e-01, -3.4465e-01],\n",
       "          [ 4.4997e-01,  8.9258e-01,  2.3129e-01,  ...,  2.3017e-01,\n",
       "            3.3910e-01, -1.3228e+00],\n",
       "          [-5.2457e-01,  9.2599e-01, -1.0031e+00,  ...,  5.1809e-01,\n",
       "            4.8173e-01,  1.0341e-01],\n",
       "          ...,\n",
       "          [-5.4117e-02, -9.7353e-03,  3.5121e-01,  ...,  7.5444e-01,\n",
       "            9.2161e-02, -6.7752e-02],\n",
       "          [ 1.7707e-01,  9.4631e-02,  4.0263e-01,  ...,  5.0826e-01,\n",
       "           -3.6505e-01,  6.7964e-02],\n",
       "          [ 1.4725e-01,  2.3586e-01, -3.0479e-01,  ...,  1.1060e-01,\n",
       "           -5.6477e-02, -2.4638e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9191e-01, -2.4441e-01,  2.0542e-01,  ...,  6.5747e-01,\n",
       "            4.5899e-01, -2.9383e-01],\n",
       "          [-1.9628e-01, -7.9747e-01,  4.1065e-01,  ...,  9.2608e-02,\n",
       "           -2.1948e-02,  7.4073e-01],\n",
       "          [ 4.0844e-01, -2.0252e-02,  1.1800e+00,  ..., -1.3716e+00,\n",
       "            1.4722e-01, -1.0310e+00],\n",
       "          ...,\n",
       "          [ 2.5304e-01, -4.5455e-01, -3.9974e-01,  ...,  5.2469e-01,\n",
       "            5.1402e-01,  7.1840e-01],\n",
       "          [-6.9562e-02, -4.3220e-01, -1.3413e-03,  ...,  7.6587e-01,\n",
       "            2.4897e-01,  2.5438e-01],\n",
       "          [ 1.9724e-01, -3.5453e-02,  2.9102e-01,  ...,  2.7631e-01,\n",
       "           -1.6897e-01, -4.0970e-02]],\n",
       "\n",
       "         [[-3.6366e-02,  1.9142e-01,  4.1446e-01,  ...,  8.1007e-01,\n",
       "            3.9245e-02,  1.0482e-01],\n",
       "          [ 4.1943e-01,  5.1830e-03, -2.1411e-01,  ..., -5.9670e-01,\n",
       "           -4.1033e-01, -1.6279e+00],\n",
       "          [ 6.2353e-01, -3.1228e-01,  1.0066e-01,  ...,  1.1111e+00,\n",
       "           -1.1464e-01,  5.5706e-01],\n",
       "          ...,\n",
       "          [-1.6430e-01,  6.2230e-01, -4.9983e-01,  ..., -3.7303e-01,\n",
       "           -6.7358e-01,  1.0765e+00],\n",
       "          [-5.9495e-01,  2.0970e-01,  1.6731e-01,  ..., -2.7627e-01,\n",
       "           -5.8253e-01,  6.9763e-01],\n",
       "          [ 8.5674e-02, -2.5145e-01,  1.6555e-01,  ...,  1.9041e-01,\n",
       "            6.9049e-02,  4.2353e-02]],\n",
       "\n",
       "         [[-4.5960e-01,  2.4134e-01,  3.4365e-01,  ...,  4.6111e-01,\n",
       "            2.8564e-01, -7.3090e-02],\n",
       "          [-4.1093e-01, -3.9910e-01, -6.2666e-02,  ..., -4.5048e-02,\n",
       "           -2.7177e-01, -3.4648e-01],\n",
       "          [-3.9905e-01, -4.0503e-01,  9.5487e-03,  ..., -2.7106e-01,\n",
       "           -1.1202e+00,  1.5107e-01],\n",
       "          ...,\n",
       "          [ 4.8414e-01, -1.6006e-01,  8.8154e-01,  ...,  5.3325e-01,\n",
       "           -4.9331e-02, -6.8542e-01],\n",
       "          [ 5.6806e-01, -2.2635e-01,  4.5036e-01,  ...,  4.1927e-01,\n",
       "           -2.9455e-01, -1.0243e+00],\n",
       "          [ 6.9907e-02, -1.4946e-01,  1.6505e-01,  ...,  4.5291e-01,\n",
       "           -7.3106e-02,  9.2629e-02]]]], grad_fn=<CopyBackwards>)), (tensor([[[[-2.0490e-01, -8.6113e-01,  6.3653e-01,  ...,  2.2243e-01,\n",
       "            4.0421e-01, -1.6381e-02],\n",
       "          [ 4.5272e-01,  4.1280e+00, -5.2920e-01,  ..., -6.5112e-01,\n",
       "           -3.8284e-01, -8.5582e-02],\n",
       "          [-2.0914e-01, -8.8353e-01,  6.5016e-01,  ...,  2.3422e-01,\n",
       "            4.0534e-01, -3.5708e-03],\n",
       "          ...,\n",
       "          [ 3.1767e-02,  3.2421e+00,  8.3954e-02,  ..., -4.2990e-01,\n",
       "            2.9455e-02,  2.5205e+00],\n",
       "          [ 1.3341e-01,  4.0189e+00,  1.7666e-01,  ...,  4.1482e-01,\n",
       "            4.2137e-01,  8.3960e-01],\n",
       "          [ 5.4251e-01,  4.4682e+00,  2.8106e-01,  ..., -4.2220e-01,\n",
       "            1.8353e-02,  2.8085e-01]],\n",
       "\n",
       "         [[ 4.0902e-01, -3.1724e-01, -7.1671e-02,  ...,  1.3649e-01,\n",
       "           -1.5222e-01, -8.8826e-01],\n",
       "          [-2.1658e+00, -1.6206e+00, -1.1309e+00,  ...,  1.0353e+00,\n",
       "            2.7022e+00,  4.3665e+00],\n",
       "          [ 4.0589e-01, -3.0326e-01, -7.3363e-02,  ...,  1.2632e-01,\n",
       "           -1.6460e-01, -9.0644e-01],\n",
       "          ...,\n",
       "          [-4.1318e+00, -4.5192e-01, -3.2447e-01,  ...,  6.1865e-01,\n",
       "            2.3834e+00,  2.2775e+00],\n",
       "          [-2.7826e+00, -7.1759e-01,  8.9551e-01,  ...,  5.6462e-01,\n",
       "            1.3623e+00,  2.6662e+00],\n",
       "          [-2.6044e+00, -1.0424e+00,  2.6543e-01,  ..., -5.2147e-01,\n",
       "            3.4052e-01,  3.4840e+00]],\n",
       "\n",
       "         [[-6.1761e-02,  5.4159e-01,  4.7866e-02,  ...,  3.4939e-02,\n",
       "           -5.5050e-01,  9.8510e-02],\n",
       "          [-1.6160e-01, -1.9865e+00,  8.4163e-01,  ...,  5.3079e-01,\n",
       "            2.6091e+00,  7.2813e-01],\n",
       "          [-3.8904e-02,  5.4805e-01,  5.1890e-02,  ...,  2.4029e-02,\n",
       "           -5.5365e-01,  1.0116e-01],\n",
       "          ...,\n",
       "          [ 2.7908e-01, -1.2192e+00, -7.6035e-01,  ...,  1.3722e+00,\n",
       "            2.8183e+00, -2.4980e-01],\n",
       "          [ 2.7585e-01, -6.6608e-01,  9.0860e-02,  ...,  1.3057e-01,\n",
       "            3.2422e+00,  5.4838e-01],\n",
       "          [-2.0740e-01, -5.5208e-01,  7.8398e-01,  ..., -2.9941e-01,\n",
       "            2.8401e+00, -7.4476e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.8828e-01,  1.9538e-01, -1.0726e-02,  ...,  1.1944e+00,\n",
       "            6.9785e-01,  1.6036e-01],\n",
       "          [ 1.9568e+00, -1.4724e+00, -5.7890e-01,  ..., -1.8160e+00,\n",
       "           -2.0122e+00,  1.0905e-01],\n",
       "          [-4.7705e-01,  1.9550e-01,  3.5356e-03,  ...,  1.1824e+00,\n",
       "            6.8226e-01,  1.6253e-01],\n",
       "          ...,\n",
       "          [ 1.8359e+00,  3.7595e-01,  2.7524e-02,  ..., -2.4362e+00,\n",
       "           -1.2253e+00, -3.6409e-01],\n",
       "          [ 5.3256e-01, -2.1168e-01, -2.5620e-01,  ..., -1.7244e+00,\n",
       "           -7.1996e-01, -1.5111e+00],\n",
       "          [ 1.4432e+00, -9.3170e-01, -2.3853e-02,  ..., -2.3252e+00,\n",
       "           -8.4064e-01, -1.5577e+00]],\n",
       "\n",
       "         [[ 6.8574e-02,  1.0870e-01, -2.7636e-02,  ...,  4.4531e-02,\n",
       "            1.2277e-01, -6.7200e-01],\n",
       "          [ 5.2265e-01, -3.4539e-01,  4.1301e-01,  ..., -2.6465e-01,\n",
       "           -2.8143e-01,  3.8624e+00],\n",
       "          [ 7.9734e-02,  1.0634e-01, -2.1334e-02,  ...,  3.1786e-02,\n",
       "            1.0860e-01, -6.7453e-01],\n",
       "          ...,\n",
       "          [-5.0933e-01,  1.9758e-01, -1.9794e-01,  ..., -4.4198e-01,\n",
       "            1.0945e+00,  3.2670e+00],\n",
       "          [ 7.9410e-01, -2.6005e-01, -1.0932e-01,  ..., -9.5870e-01,\n",
       "            2.9900e-01,  3.3927e+00],\n",
       "          [ 4.0630e-01,  1.2192e-01, -2.8408e-01,  ..., -1.2707e+00,\n",
       "            4.7836e-01,  3.9115e+00]],\n",
       "\n",
       "         [[ 1.4525e-01,  2.2893e-01, -1.1090e-01,  ...,  6.0828e-02,\n",
       "            7.4582e-03, -4.0473e-01],\n",
       "          [ 1.0071e+00,  1.1987e+00,  1.3911e+00,  ...,  3.5063e-01,\n",
       "            4.9345e-01,  1.4681e+00],\n",
       "          [ 1.5882e-01,  2.2521e-01, -1.0230e-01,  ...,  5.0697e-02,\n",
       "           -2.0104e-02, -3.7855e-01],\n",
       "          ...,\n",
       "          [-2.8521e-01, -1.3886e+00,  1.6607e+00,  ...,  2.7183e-01,\n",
       "            1.0531e+00,  5.9241e-01],\n",
       "          [-8.1662e-01, -2.9022e-01,  6.2135e-01,  ...,  4.7387e-02,\n",
       "            3.6511e-01,  1.1008e+00],\n",
       "          [ 3.6433e-01,  4.6057e-01,  7.0208e-01,  ..., -1.4187e-01,\n",
       "            2.2825e-01,  6.2212e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 1.6713e-02,  1.0382e-01, -5.3384e-03,  ..., -9.4975e-02,\n",
       "            1.3506e-01, -1.7271e-02],\n",
       "          [-3.0809e-01,  3.3910e-01,  4.5103e-02,  ...,  6.5455e-01,\n",
       "           -6.6602e-01,  9.8681e-02],\n",
       "          [ 1.1508e-02,  9.6642e-02, -1.4934e-02,  ..., -8.8413e-02,\n",
       "            1.3407e-01, -3.0535e-03],\n",
       "          ...,\n",
       "          [ 5.1393e-01, -2.2471e-01, -8.3125e-01,  ..., -4.0630e-01,\n",
       "           -8.4624e-01,  2.2786e-01],\n",
       "          [-2.0466e-01,  1.4994e-01, -5.0785e-01,  ..., -1.1024e-01,\n",
       "           -9.0386e-01,  5.7677e-01],\n",
       "          [-1.8141e-01, -1.4083e-01, -8.4947e-01,  ...,  5.4353e-01,\n",
       "           -1.2156e+00,  5.5864e-01]],\n",
       "\n",
       "         [[ 1.7522e-02, -2.7841e-02, -1.1202e-02,  ..., -4.7174e-02,\n",
       "           -7.8810e-02,  1.2582e-02],\n",
       "          [ 1.4037e-01,  1.9832e-01,  2.1159e-01,  ...,  3.4991e-01,\n",
       "           -1.5027e-01,  2.9406e-02],\n",
       "          [ 1.1949e-02, -2.6713e-02, -1.4009e-02,  ..., -4.8603e-02,\n",
       "           -8.3091e-02,  1.2020e-02],\n",
       "          ...,\n",
       "          [ 6.7638e-01,  3.6953e-01, -1.6534e-01,  ...,  2.3978e-01,\n",
       "            3.0250e-01,  1.7174e-02],\n",
       "          [ 4.7940e-01, -2.4130e-01, -1.0994e-01,  ..., -1.8977e-01,\n",
       "            3.9955e-03,  1.2770e-01],\n",
       "          [ 4.2789e-01, -3.1491e-01, -1.8025e-01,  ...,  1.7319e-01,\n",
       "            1.5768e-02, -2.2945e-01]],\n",
       "\n",
       "         [[ 1.3591e-02, -4.8167e-03, -1.5073e-02,  ...,  8.8584e-03,\n",
       "           -9.2513e-04,  1.2103e-01],\n",
       "          [ 2.1015e-01, -1.9584e-01, -3.0960e-01,  ..., -2.4007e-01,\n",
       "            2.3706e-01, -3.1287e-01],\n",
       "          [ 1.5157e-02,  6.5711e-03, -1.9378e-02,  ...,  1.5858e-03,\n",
       "           -1.6581e-03,  1.1853e-01],\n",
       "          ...,\n",
       "          [-7.6625e-01, -1.0012e+00, -2.5810e-02,  ..., -6.0046e-01,\n",
       "           -6.2607e-01, -3.1391e-01],\n",
       "          [-3.9001e-01,  1.3023e-01, -8.5473e-02,  ..., -2.0817e-01,\n",
       "           -7.3622e-01, -5.2876e-01],\n",
       "          [-3.2813e-01,  6.4700e-01, -4.6914e-02,  ..., -1.5790e-01,\n",
       "           -1.7560e-01, -3.9346e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1452e-03,  6.3983e-03,  2.1633e-02,  ...,  1.1679e-02,\n",
       "           -3.6151e-03,  2.1994e-02],\n",
       "          [-1.2089e-01, -1.2329e-01,  2.8559e-01,  ..., -3.2196e-01,\n",
       "           -3.7210e-02,  4.3804e-01],\n",
       "          [ 1.0059e-02,  8.1769e-03,  2.2334e-02,  ...,  3.1595e-03,\n",
       "           -6.6637e-03,  2.3917e-02],\n",
       "          ...,\n",
       "          [ 1.7550e-01, -3.6828e-01,  1.1872e-01,  ..., -7.9150e-02,\n",
       "            4.9241e-01,  3.7912e-01],\n",
       "          [ 1.6002e-02,  3.1731e-01, -7.2434e-03,  ..., -4.5947e-01,\n",
       "            4.9980e-01, -2.2379e-02],\n",
       "          [ 1.8741e-01,  5.0515e-01,  5.8239e-01,  ..., -8.8050e-01,\n",
       "           -4.9819e-01, -8.6735e-01]],\n",
       "\n",
       "         [[-8.7999e-03,  2.1361e-02, -2.6117e-02,  ...,  4.3924e-02,\n",
       "           -2.9714e-02, -6.8203e-02],\n",
       "          [ 3.3238e-01, -9.2914e-02,  1.9035e-01,  ..., -8.8211e-01,\n",
       "            4.2262e-01,  1.0082e+00],\n",
       "          [-2.9670e-03,  2.1955e-02, -2.1995e-02,  ...,  4.8925e-02,\n",
       "           -2.3205e-02, -7.3149e-02],\n",
       "          ...,\n",
       "          [-8.4419e-01, -8.6077e-02,  4.9224e-01,  ..., -3.3076e-01,\n",
       "            7.2463e-01,  4.2125e-01],\n",
       "          [-7.5824e-01, -3.7654e-01,  9.1687e-02,  ..., -6.1430e-01,\n",
       "            9.1626e-01,  5.0360e-01],\n",
       "          [-6.6173e-01, -5.3766e-01, -2.1153e-01,  ..., -1.3624e+00,\n",
       "            3.7718e-01,  3.1472e-01]],\n",
       "\n",
       "         [[ 3.5780e-02, -7.9826e-04, -2.7575e-02,  ...,  1.4422e-02,\n",
       "            2.7494e-02, -3.6092e-02],\n",
       "          [-1.9653e-01, -1.7142e-01, -8.8735e-01,  ..., -8.0687e-01,\n",
       "            5.3173e-01, -3.2138e-02],\n",
       "          [ 3.7494e-02, -3.8835e-03, -3.1187e-02,  ...,  2.2949e-02,\n",
       "            2.5981e-02, -3.3507e-02],\n",
       "          ...,\n",
       "          [ 3.9138e-01,  2.8181e-01,  3.5310e-01,  ...,  2.2982e-01,\n",
       "           -3.6680e-01,  4.4010e-01],\n",
       "          [ 3.8089e-01, -3.9481e-01, -1.0080e+00,  ...,  1.7403e-01,\n",
       "            6.9215e-01, -5.3396e-02],\n",
       "          [ 2.4366e-01, -6.8113e-01, -1.0201e+00,  ...,  4.8793e-02,\n",
       "            4.2634e-01, -5.3963e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 0.0892,  0.7404,  1.8047,  ..., -1.3032, -0.1346, -0.8145],\n",
       "          [-1.2619,  0.5972,  1.5104,  ..., -1.6343,  0.5092, -0.2074],\n",
       "          [-2.3282,  1.0029, -0.0737,  ..., -0.0998, -0.7547, -0.6585],\n",
       "          ...,\n",
       "          [-0.4195,  0.7697,  0.6477,  ...,  1.6424, -0.5876,  0.9104],\n",
       "          [-0.3344,  0.0863,  1.9703,  ...,  1.9979,  0.3143, -0.1362],\n",
       "          [ 0.8307,  0.3504,  1.0997,  ..., -0.8808, -1.2045,  1.3169]],\n",
       "\n",
       "         [[-0.1049,  1.2764, -0.9032,  ..., -0.1837, -0.1023, -0.7790],\n",
       "          [ 0.0359,  0.4838,  1.3848,  ..., -0.7957,  0.8351, -1.5183],\n",
       "          [ 1.5872, -0.8626, -1.1353,  ..., -0.9112,  0.0974, -1.3479],\n",
       "          ...,\n",
       "          [ 1.3743,  1.4976,  1.4407,  ...,  0.3891, -0.4257, -0.3640],\n",
       "          [ 0.1680,  1.4974, -0.2435,  ...,  0.3181,  0.5988,  0.1601],\n",
       "          [-0.0707,  0.9058,  0.1487,  ..., -0.1305,  0.5050,  1.2241]],\n",
       "\n",
       "         [[ 1.2935,  0.8329, -0.0895,  ...,  2.3093, -0.5510,  0.2128],\n",
       "          [ 1.2859, -2.5036,  0.8700,  ...,  1.0578, -1.2675,  0.1280],\n",
       "          [ 1.3606, -2.4208, -0.0906,  ..., -1.2099,  0.0155, -1.0468],\n",
       "          ...,\n",
       "          [ 1.4986, -1.7760,  1.0818,  ..., -0.2197,  0.3529, -0.2896],\n",
       "          [ 1.4308, -0.8506,  0.5168,  ...,  0.6157,  0.3245,  0.2303],\n",
       "          [ 1.4605, -0.7537,  1.2172,  ..., -0.2555, -0.0826, -0.3561]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4706, -0.1709, -0.3352,  ...,  0.6548, -0.2643,  1.2635],\n",
       "          [-1.6517,  2.0562, -0.2377,  ..., -1.4894,  1.1588, -0.6944],\n",
       "          [ 0.9071,  1.6064,  0.9046,  ..., -0.7798,  1.5641, -0.6169],\n",
       "          ...,\n",
       "          [-1.0763,  2.0874,  1.0333,  ..., -0.3153, -0.8497, -0.6453],\n",
       "          [-1.3854,  0.9435,  1.3001,  ..., -0.0872, -1.1005, -0.2137],\n",
       "          [-0.1227, -0.5445, -0.5405,  ...,  0.3181, -0.3026, -0.0970]],\n",
       "\n",
       "         [[ 1.5736,  0.6529,  0.4677,  ...,  1.1082,  0.5912,  0.8043],\n",
       "          [ 1.1017, -0.1684, -0.0332,  ...,  1.0803,  1.2228,  1.6984],\n",
       "          [-0.2992,  0.1301,  0.4535,  ..., -0.0084,  0.2391,  1.4451],\n",
       "          ...,\n",
       "          [ 1.2355,  0.6793, -0.5968,  ...,  1.6196,  0.6640,  0.9655],\n",
       "          [ 0.3095,  0.0352, -0.2908,  ...,  1.7710,  0.5868,  0.3559],\n",
       "          [ 0.9644, -0.7381, -1.9089,  ..., -0.5048,  1.4048, -0.6378]],\n",
       "\n",
       "         [[-0.7694,  0.3690,  0.3920,  ..., -0.5529, -0.4480, -1.5094],\n",
       "          [ 1.0373,  0.2712, -1.1285,  ..., -0.0177,  0.0061, -1.0076],\n",
       "          [-0.4520, -1.0907, -1.2636,  ..., -1.7397,  0.3026,  0.4351],\n",
       "          ...,\n",
       "          [ 0.7193, -1.1288, -0.4184,  ..., -0.6091, -1.3446,  0.0467],\n",
       "          [-0.3733, -0.6942,  0.6280,  ..., -1.1922, -0.7267,  0.4426],\n",
       "          [-1.1560, -0.4790,  1.2826,  ..., -1.5887, -0.6540, -3.0733]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 4.1427e-01,  1.1639e-02,  8.0603e-01,  ...,  5.8179e-02,\n",
       "            1.8959e-01, -6.1311e-01],\n",
       "          [ 2.6797e-01, -3.6553e-01,  3.0403e-01,  ..., -9.4325e-01,\n",
       "            6.2504e-01,  7.0214e-02],\n",
       "          [ 5.5912e-01, -2.2749e-01, -2.4894e-01,  ...,  1.8536e-01,\n",
       "            1.0613e+00,  1.0891e+00],\n",
       "          ...,\n",
       "          [ 1.0585e+00, -8.5714e-01,  4.9467e-01,  ...,  1.2985e+00,\n",
       "           -1.0268e-01,  2.6852e-01],\n",
       "          [ 6.6155e-01, -6.9155e-01,  4.0838e-01,  ...,  2.0694e-01,\n",
       "           -5.1408e-01,  9.8254e-03],\n",
       "          [ 5.9148e-04,  5.1520e-02, -6.7858e-02,  ..., -2.6390e-02,\n",
       "            2.2544e-03,  4.6056e-04]],\n",
       "\n",
       "         [[ 5.6267e-01, -1.2554e-02,  4.0050e-01,  ...,  7.2791e-01,\n",
       "            3.2284e-01, -2.9475e-02],\n",
       "          [ 1.7503e-01,  1.4022e-01,  2.1780e-01,  ..., -1.4980e-01,\n",
       "           -4.9550e-01, -2.5906e-03],\n",
       "          [ 6.1086e-01,  3.4011e-01, -1.9826e-01,  ...,  4.3705e-01,\n",
       "            5.7294e-01, -2.1026e-01],\n",
       "          ...,\n",
       "          [ 1.9770e-01, -6.8545e-01, -1.4133e-01,  ..., -6.7938e-01,\n",
       "           -5.4236e-01,  1.6584e-01],\n",
       "          [ 5.3270e-01, -1.5837e-01,  2.0484e-01,  ..., -1.2692e+00,\n",
       "           -7.9340e-01, -2.0635e-02],\n",
       "          [-2.1829e-02, -2.9031e+00, -2.6802e-01,  ...,  5.1835e-01,\n",
       "            8.9854e-02, -3.2112e-03]],\n",
       "\n",
       "         [[ 1.8711e-01, -8.8539e-02,  3.1651e-01,  ..., -2.0019e-01,\n",
       "           -6.9395e-02,  6.6651e-01],\n",
       "          [-2.3052e-01,  2.4598e-02, -4.8264e-02,  ..., -4.4856e-01,\n",
       "           -7.3827e-01,  1.9495e-01],\n",
       "          [ 2.4432e-01, -5.2444e-01, -1.7515e-01,  ..., -3.0561e-01,\n",
       "           -8.2109e-02, -2.7275e-01],\n",
       "          ...,\n",
       "          [-2.8874e-01, -2.9300e-01,  2.2342e-01,  ...,  1.5449e-01,\n",
       "            1.3214e-01, -4.3122e-01],\n",
       "          [-1.5632e-01, -4.1791e-01,  1.8200e-01,  ..., -2.0464e-01,\n",
       "           -4.4658e-02, -3.8680e-01],\n",
       "          [-4.5714e-02,  1.6779e-01, -2.0547e-01,  ..., -1.0904e-01,\n",
       "           -1.1552e-01,  7.2527e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.7112e-02, -2.1327e-01,  5.9691e-01,  ..., -4.9115e-01,\n",
       "            2.4305e-01,  4.2173e-01],\n",
       "          [-4.7254e-01,  5.1743e-01,  3.4074e-01,  ..., -1.0638e-01,\n",
       "            1.1781e-02,  2.9887e-01],\n",
       "          [ 1.8001e-01, -1.1153e+00,  7.6950e-02,  ...,  9.0276e-01,\n",
       "           -1.0666e+00,  1.2056e+00],\n",
       "          ...,\n",
       "          [ 3.8258e-01, -9.0264e-01, -5.5785e-01,  ..., -8.7501e-01,\n",
       "            6.6113e-01, -4.8659e-01],\n",
       "          [-4.1132e-02, -5.1636e-01, -1.8938e-01,  ..., -1.0941e-01,\n",
       "            4.2697e-01,  2.5108e-02],\n",
       "          [-1.0037e-01,  1.5453e-01, -1.0592e-01,  ..., -5.8683e-02,\n",
       "            5.6880e-02, -1.3645e-01]],\n",
       "\n",
       "         [[ 2.4758e-01, -1.9672e-01,  1.2344e-01,  ..., -5.8960e-01,\n",
       "           -1.5308e-02, -3.6896e-01],\n",
       "          [ 4.3544e-01,  1.9704e-01,  4.3909e-01,  ..., -1.8883e-01,\n",
       "           -6.3396e-01,  7.8337e-01],\n",
       "          [-1.8576e-01,  6.5050e-01,  2.1896e-01,  ..., -1.1228e+00,\n",
       "           -1.0979e-01, -3.1483e-01],\n",
       "          ...,\n",
       "          [-3.4002e-01,  4.1815e-01,  1.0901e+00,  ..., -2.2167e-01,\n",
       "            1.8469e-01,  1.3536e-01],\n",
       "          [-3.2079e-01,  9.1803e-02,  3.1501e-01,  ...,  4.8566e-02,\n",
       "            7.2177e-01, -3.0125e-01],\n",
       "          [ 8.7289e-02, -2.1763e-02,  2.3641e-02,  ...,  8.4793e-03,\n",
       "           -1.9040e-03,  4.5364e-01]],\n",
       "\n",
       "         [[ 2.2564e-01, -2.2921e-03, -4.1271e-01,  ..., -2.5000e-01,\n",
       "            2.4177e-01, -3.6672e-01],\n",
       "          [-1.8939e-02,  4.5090e-01, -3.3902e-01,  ...,  1.3989e-01,\n",
       "            1.6870e+00, -8.5581e-02],\n",
       "          [ 3.8941e-01,  4.4114e-01,  2.3267e-01,  ..., -6.2857e-01,\n",
       "            3.0926e-01,  1.4003e-01],\n",
       "          ...,\n",
       "          [ 1.5593e+00,  8.2415e-02, -7.8478e-01,  ...,  1.6701e-01,\n",
       "           -4.2955e-01, -5.7624e-01],\n",
       "          [ 8.7198e-01,  3.9492e-01, -7.3470e-01,  ...,  4.9489e-01,\n",
       "           -3.5940e-01, -8.4641e-01],\n",
       "          [-1.5645e-01, -1.1303e-01,  9.2896e-02,  ..., -1.7266e-01,\n",
       "           -2.8413e-02,  2.3312e-01]]]], grad_fn=<CopyBackwards>)), (tensor([[[[ 0.8134,  1.1350, -0.0372,  ..., -0.0847,  1.2953,  1.3621],\n",
       "          [-2.2993, -2.4632,  1.0951,  ..., -0.4848, -1.5290, -3.2515],\n",
       "          [ 0.8354,  1.1170, -0.0454,  ..., -0.0843,  1.2918,  1.3790],\n",
       "          ...,\n",
       "          [-3.8456, -1.5131,  1.2240,  ..., -2.6965, -1.5035, -3.7601],\n",
       "          [-3.6338, -1.1650,  0.1777,  ..., -0.1238, -1.5178, -3.7192],\n",
       "          [-3.7569, -1.4038,  0.4546,  ..., -1.1043, -1.0857, -3.5401]],\n",
       "\n",
       "         [[ 0.3940,  0.5515,  0.7690,  ..., -0.1353,  0.4348, -0.0769],\n",
       "          [-1.9026,  0.8882, -2.1242,  ..., -0.2859, -1.8447,  0.0541],\n",
       "          [ 0.4156,  0.5516,  0.7733,  ..., -0.1342,  0.4375, -0.0908],\n",
       "          ...,\n",
       "          [-1.5701, -0.7846, -2.0646,  ..., -0.4948, -2.3558,  0.2160],\n",
       "          [-1.5822, -0.2655, -1.8370,  ..., -0.3529, -1.8143, -0.0378],\n",
       "          [-1.2934, -0.4253, -1.9171,  ..., -0.1201, -1.7832,  0.4343]],\n",
       "\n",
       "         [[-0.5077, -0.8940,  0.1037,  ..., -0.4361,  1.3347, -0.0895],\n",
       "          [-0.9927,  1.7463,  0.0736,  ...,  1.6155, -2.2400,  0.7434],\n",
       "          [-0.5170, -0.9054,  0.0974,  ..., -0.4606,  1.3060, -0.1031],\n",
       "          ...,\n",
       "          [ 1.0253,  4.0019,  0.1762,  ..., -0.9096, -3.0428, -0.1263],\n",
       "          [-0.9477,  1.2432, -0.9094,  ..., -0.2134, -3.2374,  0.1303],\n",
       "          [-1.2250,  1.0858, -0.8875,  ...,  2.5595, -4.4463, -2.4440]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.7328,  0.3725, -0.6296,  ..., -1.1096, -0.8318,  0.4963],\n",
       "          [ 2.1457,  1.4277, -0.8266,  ...,  1.0285,  0.4499, -0.4140],\n",
       "          [-0.7413,  0.3745, -0.6532,  ..., -1.1246, -0.8027,  0.4995],\n",
       "          ...,\n",
       "          [ 2.3153,  1.0153, -0.2042,  ...,  2.1682,  3.1723,  0.7528],\n",
       "          [ 0.8315, -0.2284, -0.7041,  ...,  1.3759,  3.0856,  1.0273],\n",
       "          [ 1.1193,  0.0728, -1.5205,  ...,  1.1219,  3.3201, -0.0126]],\n",
       "\n",
       "         [[ 0.2204,  0.1547,  0.2173,  ...,  0.1090,  0.5136, -0.0514],\n",
       "          [ 1.1105,  0.8736,  0.4574,  ...,  1.1462, -0.0401, -0.1860],\n",
       "          [ 0.2289,  0.1550,  0.2147,  ...,  0.1025,  0.5185, -0.0516],\n",
       "          ...,\n",
       "          [ 0.2301,  0.5118,  1.0389,  ..., -0.0272, -1.4723,  0.4116],\n",
       "          [ 0.4355, -0.4763,  0.9100,  ..., -0.0545, -0.8076,  0.0045],\n",
       "          [ 0.5943, -0.6306,  1.5626,  ...,  0.7095, -1.4394, -0.0465]],\n",
       "\n",
       "         [[-0.1725,  0.4707,  0.8340,  ..., -0.3116, -0.1377,  0.9338],\n",
       "          [-1.4906, -0.7800, -0.6151,  ..., -0.7894, -0.2033, -0.4299],\n",
       "          [-0.1461,  0.4686,  0.8173,  ..., -0.3137, -0.1385,  0.9368],\n",
       "          ...,\n",
       "          [-1.0807, -1.3599, -0.5108,  ..., -0.6703,  0.0175, -0.3490],\n",
       "          [-0.7064, -1.9298, -1.0691,  ...,  0.4924,  0.0368,  0.0879],\n",
       "          [-0.7823, -1.7987, -1.8778,  ..., -0.0251, -0.1731, -0.6599]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[-2.7752e-02,  1.6321e-03, -2.5725e-03,  ..., -2.5358e-02,\n",
       "           -2.3859e-02,  3.8925e-02],\n",
       "          [ 2.5054e-03,  9.6340e-01, -1.5792e-02,  ..., -1.3475e+00,\n",
       "           -7.3249e-02,  3.9437e-01],\n",
       "          [-2.2960e-02, -8.6822e-04,  1.6415e-03,  ..., -3.0648e-02,\n",
       "           -3.0862e-02,  3.3577e-02],\n",
       "          ...,\n",
       "          [-1.0767e+00,  3.4215e-01, -2.1060e-01,  ...,  6.4648e-02,\n",
       "           -9.2465e-02, -4.0960e-01],\n",
       "          [-2.3259e-01,  2.6171e-01,  2.0173e-01,  ..., -3.5296e-01,\n",
       "           -9.8811e-02, -1.2606e-01],\n",
       "          [-1.2238e-01,  3.6254e-01,  2.2936e-01,  ..., -6.2790e-01,\n",
       "           -5.8415e-01,  8.5911e-01]],\n",
       "\n",
       "         [[-1.2670e-01,  2.8659e-02, -2.2483e-02,  ..., -1.6007e-02,\n",
       "           -5.9623e-02, -3.0004e-02],\n",
       "          [ 9.5249e-01,  5.8366e-01,  1.4838e-01,  ..., -1.7798e-01,\n",
       "            2.2319e-01,  1.9118e-01],\n",
       "          [-1.2185e-01,  3.3644e-02, -3.5736e-02,  ..., -1.8580e-02,\n",
       "           -5.8799e-02, -1.6466e-02],\n",
       "          ...,\n",
       "          [ 1.3254e-01, -3.9629e-01, -4.4959e-01,  ..., -2.3106e-01,\n",
       "           -5.3642e-01, -1.0575e-01],\n",
       "          [-2.8354e-01, -6.6961e-01, -7.5041e-01,  ...,  5.6108e-02,\n",
       "           -3.9800e-01, -4.0113e-02],\n",
       "          [-1.2979e-01, -4.3662e-01, -6.6795e-01,  ..., -4.9149e-02,\n",
       "           -1.7793e-01,  1.5942e-01]],\n",
       "\n",
       "         [[ 1.4306e-02, -2.5426e-03, -8.0851e-02,  ..., -5.1455e-03,\n",
       "           -4.9214e-03, -4.0598e-03],\n",
       "          [ 7.2212e-02, -1.5176e+00,  9.7418e-01,  ...,  1.2148e+00,\n",
       "           -4.8553e-01, -9.6219e-01],\n",
       "          [ 1.7890e-02, -1.1739e-02, -6.6050e-02,  ..., -1.5548e-02,\n",
       "           -5.0546e-03,  4.3652e-03],\n",
       "          ...,\n",
       "          [ 5.3172e-01, -7.7072e-01,  9.5048e-01,  ..., -1.1275e+00,\n",
       "           -4.1576e-02,  9.3450e-01],\n",
       "          [ 3.1174e-01, -6.6108e-01,  1.4680e+00,  ..., -1.8813e-01,\n",
       "           -8.2578e-01,  1.1448e+00],\n",
       "          [-1.3606e-01, -9.5149e-01,  3.8670e-01,  ..., -4.4538e-01,\n",
       "            1.4921e-01,  6.7484e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0818e-03,  8.1405e-03,  1.9474e-02,  ..., -6.4939e-03,\n",
       "            1.2406e-02, -4.8734e-03],\n",
       "          [ 5.4506e-02,  5.5627e-01, -1.5279e-01,  ..., -1.0009e-01,\n",
       "           -1.0238e-01, -2.9411e-01],\n",
       "          [ 1.5737e-02,  8.2339e-03,  1.0101e-02,  ...,  6.0616e-04,\n",
       "           -4.4394e-03, -1.5451e-02],\n",
       "          ...,\n",
       "          [-4.4241e-02, -1.3565e+00, -2.2605e-01,  ..., -4.3601e-01,\n",
       "            3.8211e-01,  5.7138e-02],\n",
       "          [ 1.4381e-02, -6.1820e-01,  3.5570e-01,  ..., -1.1561e+00,\n",
       "            2.3794e-01, -4.7617e-01],\n",
       "          [ 4.6286e-03, -2.0643e-01, -1.6830e-01,  ..., -5.8283e-01,\n",
       "            2.1380e-01, -2.5230e-01]],\n",
       "\n",
       "         [[-1.7307e-02,  4.2332e-02, -4.8741e-02,  ...,  4.6545e-02,\n",
       "            2.6402e-02,  2.1639e-02],\n",
       "          [ 1.4923e-01, -1.0112e+00,  6.5489e-01,  ..., -5.7365e-01,\n",
       "           -2.2836e-01, -3.9191e-01],\n",
       "          [-1.6805e-02,  5.1741e-02, -3.5982e-02,  ...,  5.2602e-02,\n",
       "            1.8086e-02,  1.6952e-02],\n",
       "          ...,\n",
       "          [-2.2786e-01,  2.7624e-02, -1.1006e+00,  ...,  1.0756e-01,\n",
       "           -7.8591e-01, -9.9961e-01],\n",
       "          [-1.0689e-01, -5.4785e-02,  2.6380e-02,  ...,  6.4836e-01,\n",
       "           -3.5099e-01, -2.4791e-01],\n",
       "          [-8.2615e-01, -2.3483e-01, -2.0184e-01,  ...,  1.3267e-01,\n",
       "           -3.9816e-01, -7.9561e-01]],\n",
       "\n",
       "         [[ 7.6053e-02,  4.4095e-02, -3.4846e-04,  ..., -1.1540e-02,\n",
       "           -2.5429e-02,  1.9231e-02],\n",
       "          [-1.3117e-01,  7.0852e-02,  5.4021e-02,  ...,  3.7746e-01,\n",
       "            4.2594e-01, -4.8818e-01],\n",
       "          [ 8.1295e-02,  4.2152e-02, -2.4788e-03,  ..., -1.4497e-02,\n",
       "           -2.1489e-02,  1.3084e-02],\n",
       "          ...,\n",
       "          [ 1.4022e-01,  7.7581e-01,  1.5920e-02,  ..., -5.2000e-01,\n",
       "            4.8890e-01,  1.7370e+00],\n",
       "          [-3.1622e-01,  3.2066e-01,  6.3973e-01,  ..., -4.9134e-01,\n",
       "            2.5631e-01,  5.6812e-01],\n",
       "          [-3.1917e-01,  7.4210e-01,  1.2731e+00,  ..., -6.3775e-01,\n",
       "            6.8733e-02,  7.9822e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[ 1.0137e+00, -5.6780e-01,  1.2524e+00,  ...,  2.1720e+00,\n",
       "           -1.2991e+00, -1.2905e+00],\n",
       "          [-3.8963e-01, -2.2241e+00,  2.8053e+00,  ...,  1.2174e+00,\n",
       "           -1.0885e+00, -2.0397e+00],\n",
       "          [-6.0315e-01, -9.9360e-01,  1.3850e+00,  ...,  9.0938e-01,\n",
       "           -1.1092e-01, -1.5351e+00],\n",
       "          ...,\n",
       "          [ 5.9032e+00, -1.3798e+00,  2.3949e-01,  ...,  4.6279e-01,\n",
       "            5.3431e+00, -2.3927e+00],\n",
       "          [ 1.0914e+00, -2.5002e+00, -6.6662e-01,  ..., -1.9196e+00,\n",
       "            2.5709e+00, -3.0973e+00],\n",
       "          [ 1.4720e+00,  2.8441e-01,  3.7955e-03,  ...,  1.8037e+00,\n",
       "            1.1913e+00,  9.5864e-01]],\n",
       "\n",
       "         [[-1.0797e+00,  3.7271e-01, -8.6387e-01,  ...,  1.1513e+00,\n",
       "           -8.8502e-01, -3.1875e-01],\n",
       "          [-1.3523e+00,  1.4814e-01,  6.1590e-01,  ..., -1.8980e-01,\n",
       "            6.7710e-01, -4.1572e-01],\n",
       "          [-1.0543e+00,  3.5701e-01,  8.0553e-01,  ..., -1.4226e+00,\n",
       "            1.2929e+00, -2.3343e-01],\n",
       "          ...,\n",
       "          [-1.7687e+00, -2.5248e-01, -3.0461e-01,  ..., -2.4891e-02,\n",
       "            8.4728e-01, -6.9297e-01],\n",
       "          [-1.1402e+00,  9.9607e-01,  3.2108e-01,  ...,  7.2685e-01,\n",
       "            7.5460e-01, -3.9081e-01],\n",
       "          [-1.3555e+00,  8.6142e-01,  1.4386e+00,  ...,  1.4888e-01,\n",
       "            1.5149e+00, -1.7852e+00]],\n",
       "\n",
       "         [[-8.3589e-01, -2.7607e-01,  8.0608e-01,  ..., -6.6661e-01,\n",
       "            1.4207e+00, -2.3398e-01],\n",
       "          [-9.4660e-01,  8.5718e-01,  1.2701e-01,  ..., -5.6105e-01,\n",
       "            1.1482e+00, -1.8194e+00],\n",
       "          [-1.8686e+00,  1.3061e-01, -1.3844e+00,  ...,  4.8114e-01,\n",
       "            6.0134e-01, -1.4229e+00],\n",
       "          ...,\n",
       "          [-1.0727e+00,  5.8331e-01,  4.3816e-01,  ...,  1.1390e+00,\n",
       "            2.0695e+00, -2.9606e+00],\n",
       "          [-1.8479e+00,  8.7270e-01,  5.1010e-01,  ...,  1.2451e+00,\n",
       "            3.1208e+00, -1.4718e+00],\n",
       "          [-1.1857e+00,  5.0123e-01, -5.2577e-01,  ..., -9.9533e-01,\n",
       "            3.7894e-02,  2.9547e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6760e+00,  3.0664e-01, -2.1878e-01,  ..., -1.1183e-01,\n",
       "           -1.6441e+00,  8.4858e-01],\n",
       "          [-6.0358e-01,  2.2261e+00,  1.0515e+00,  ..., -4.1507e-02,\n",
       "           -7.6383e-01, -6.8196e-01],\n",
       "          [-1.1301e+00,  1.2786e+00,  1.4677e+00,  ..., -2.5497e-01,\n",
       "            1.2768e+00, -4.5910e-01],\n",
       "          ...,\n",
       "          [-1.4557e+00,  3.4180e-01, -1.5978e+00,  ...,  1.1175e+00,\n",
       "            1.7355e+00, -3.7599e-01],\n",
       "          [-1.4717e+00,  4.7101e-01, -9.0475e-01,  ...,  7.2135e-01,\n",
       "            4.1806e-01,  2.6234e-01],\n",
       "          [-1.3792e+00, -1.2865e-01,  2.5779e-02,  ..., -9.7116e-01,\n",
       "            1.3280e-01,  2.7156e-01]],\n",
       "\n",
       "         [[-3.6678e-02,  2.0156e-01, -1.8768e-01,  ..., -2.8919e-01,\n",
       "           -5.5359e-01, -2.7688e-01],\n",
       "          [ 1.3911e+00,  2.0433e+00,  1.7498e+00,  ..., -1.7076e+00,\n",
       "            1.3779e+00,  7.8792e-01],\n",
       "          [ 1.6458e+00, -3.5219e-01,  1.8034e-01,  ...,  2.7173e-01,\n",
       "            4.7699e-01,  1.5756e+00],\n",
       "          ...,\n",
       "          [ 1.4625e+00, -9.8333e-01, -1.4637e-01,  ..., -9.0442e-01,\n",
       "           -1.8188e+00,  3.0521e-01],\n",
       "          [ 1.2648e+00, -5.9494e-03,  6.5043e-01,  ..., -8.7755e-01,\n",
       "           -7.7328e-01, -1.1412e+00],\n",
       "          [ 5.3391e-01,  6.0332e-01, -8.4151e-01,  ..., -1.9933e-01,\n",
       "           -1.1172e+00,  2.3139e-02]],\n",
       "\n",
       "         [[ 1.9229e+00, -1.7942e-01, -6.7423e-01,  ...,  6.4226e-01,\n",
       "           -4.0519e-01,  3.8806e-01],\n",
       "          [ 1.4854e+00, -1.6013e+00, -1.1362e+00,  ..., -5.0215e-01,\n",
       "           -1.2095e+00,  1.0608e-01],\n",
       "          [ 1.7492e-01, -1.4683e+00, -8.8653e-01,  ..., -3.3509e-01,\n",
       "           -1.2767e+00,  1.0200e+00],\n",
       "          ...,\n",
       "          [-1.2009e+00,  5.8686e-01,  2.4354e-02,  ...,  2.2096e+00,\n",
       "           -1.5900e-01, -3.0032e-01],\n",
       "          [ 1.3866e-01,  4.7058e-01,  5.8360e-01,  ...,  1.8137e+00,\n",
       "            1.5114e-01, -4.0760e-01],\n",
       "          [-7.8764e-01,  2.7477e-01, -9.5293e-01,  ..., -5.5062e-01,\n",
       "           -9.5637e-01,  1.5291e+00]]]], grad_fn=<CopyBackwards>), tensor([[[[ 3.4588e-01, -1.1236e-01, -1.4882e-01,  ..., -8.0944e-02,\n",
       "           -3.0221e-01, -4.2882e-01],\n",
       "          [-7.2107e-01, -2.4375e-01,  1.5926e-01,  ..., -6.4896e-03,\n",
       "           -6.7328e-01,  2.2116e-01],\n",
       "          [ 2.0649e-01, -2.6981e-01, -1.2147e-01,  ...,  1.8937e-01,\n",
       "           -2.3831e-01,  4.6670e-02],\n",
       "          ...,\n",
       "          [ 7.4807e-01, -2.5550e-01, -1.3698e-01,  ...,  2.1814e-01,\n",
       "           -2.7957e-01,  1.4357e-01],\n",
       "          [ 7.0306e-01, -2.3247e-01, -4.4473e-02,  ...,  1.1519e-01,\n",
       "           -3.8716e-01,  6.6941e-02],\n",
       "          [ 4.1381e-01, -3.1472e-01, -1.1965e+00,  ..., -5.5126e-01,\n",
       "           -2.0193e+00, -5.1063e-02]],\n",
       "\n",
       "         [[-4.9880e-01,  1.6801e-01,  1.6431e-01,  ...,  3.7056e-01,\n",
       "            9.7195e-03, -1.2414e-01],\n",
       "          [-1.3414e-01, -2.0006e-01,  5.8508e-01,  ..., -3.2606e-01,\n",
       "           -5.0346e-01, -7.2827e-02],\n",
       "          [-1.1390e-01,  1.1194e-01,  6.2200e-01,  ...,  3.4468e-02,\n",
       "            7.9936e-01, -6.0081e-02],\n",
       "          ...,\n",
       "          [-4.7059e-02, -1.1171e-01, -3.6842e-01,  ..., -6.9331e-01,\n",
       "            9.9716e-02,  4.0432e-01],\n",
       "          [ 3.5648e-02,  3.0642e-01, -6.3586e-01,  ..., -2.7641e-01,\n",
       "            5.5664e-01, -1.0186e-01],\n",
       "          [ 2.5374e-01, -4.9411e-02,  1.7618e-02,  ..., -4.8243e-02,\n",
       "           -6.6727e-02, -1.9271e-01]],\n",
       "\n",
       "         [[-3.1824e-01, -2.1605e-01, -6.1235e-01,  ..., -1.9953e-01,\n",
       "           -9.3732e-02,  1.5257e-01],\n",
       "          [-1.6768e-01, -9.5159e-01,  6.6919e-02,  ..., -9.0706e-02,\n",
       "           -3.5057e-01, -5.8890e-01],\n",
       "          [ 3.4081e-02, -2.9031e-01,  6.8439e-01,  ...,  4.4964e-01,\n",
       "            4.4254e-01,  5.3674e-01],\n",
       "          ...,\n",
       "          [-3.2782e-01,  4.9901e-01,  3.4018e-01,  ..., -9.6037e-01,\n",
       "            3.5829e-01, -8.1346e-01],\n",
       "          [ 3.9698e-01,  5.8489e-01, -5.3015e-01,  ..., -2.7909e-01,\n",
       "           -4.5224e-01,  2.6382e-02],\n",
       "          [-3.9941e-02,  2.6957e-03, -4.1076e-02,  ..., -5.2776e-02,\n",
       "           -6.4471e-03, -4.8816e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.2174e-01, -3.9179e-01,  2.5731e-01,  ..., -8.0044e-01,\n",
       "           -4.4742e-01,  4.0617e-01],\n",
       "          [-1.0658e+00, -6.2593e-01, -2.0339e-01,  ..., -7.5364e-01,\n",
       "           -9.3093e-02,  3.2014e-01],\n",
       "          [ 3.8084e-01, -1.0592e+00,  9.2525e-01,  ...,  1.6245e-01,\n",
       "           -3.3639e-01,  5.0450e-01],\n",
       "          ...,\n",
       "          [ 1.2734e-01, -3.0956e-01, -7.0285e-01,  ...,  3.1857e-01,\n",
       "            2.4354e-01,  1.1571e-01],\n",
       "          [-1.0382e-01, -7.0035e-01, -3.2320e-01,  ...,  3.2071e-01,\n",
       "           -3.4610e-01,  1.3100e-01],\n",
       "          [-9.8828e-02, -2.1522e-01,  9.1879e-02,  ...,  7.2955e-03,\n",
       "            5.2047e-03, -7.7468e-02]],\n",
       "\n",
       "         [[ 2.5510e-01,  4.7261e-01, -3.1822e-01,  ...,  1.9489e-01,\n",
       "           -3.0667e-01,  2.0714e-01],\n",
       "          [ 4.3333e-01, -8.0029e-01, -5.1451e-01,  ..., -5.8195e-01,\n",
       "            5.6547e-02, -1.2180e-03],\n",
       "          [-1.3229e-02, -1.0510e+00, -2.3739e-01,  ...,  7.1355e-01,\n",
       "            2.9340e-01, -6.3374e-01],\n",
       "          ...,\n",
       "          [ 1.8055e-01,  5.1217e-01, -3.5432e-01,  ...,  6.1648e-01,\n",
       "           -9.3638e-02, -1.4586e+00],\n",
       "          [-5.1361e-01, -1.4510e-01,  3.0874e-01,  ...,  6.0086e-01,\n",
       "           -3.7740e-01, -1.1824e+00],\n",
       "          [-3.5707e-03,  7.3149e-02, -1.6797e-01,  ...,  5.8451e-01,\n",
       "            1.2883e-01,  1.0916e-01]],\n",
       "\n",
       "         [[-5.1895e-02, -2.3197e-01,  9.4906e-02,  ...,  2.4577e-01,\n",
       "           -3.4855e-01,  2.2293e-01],\n",
       "          [ 5.4102e-01, -2.7712e-01,  8.9534e-03,  ...,  3.4034e-01,\n",
       "            2.1951e-01,  4.6168e-01],\n",
       "          [ 1.3889e-01,  4.7288e-01,  1.5120e-01,  ...,  1.0646e+00,\n",
       "           -7.2596e-02, -3.8010e-01],\n",
       "          ...,\n",
       "          [ 3.8291e-01, -3.3616e-01, -2.5373e-02,  ...,  2.8352e-01,\n",
       "           -1.5605e+00, -1.1449e+00],\n",
       "          [-1.2125e-01, -3.3136e-01, -1.3360e-01,  ...,  4.5343e-01,\n",
       "           -3.8127e-01, -1.2905e+00],\n",
       "          [ 1.6106e-01, -1.9248e-01,  2.9812e-01,  ..., -4.7275e-01,\n",
       "            4.6982e-01,  2.6391e-01]]]], grad_fn=<CopyBackwards>)), (tensor([[[[-3.1424e-01,  1.1871e+00, -2.4239e-01,  ..., -2.6461e-01,\n",
       "           -6.5012e-01, -4.1936e-01],\n",
       "          [-1.3021e+00, -8.2344e-02,  1.1189e+00,  ..., -3.9186e-01,\n",
       "            7.4950e-01,  5.0328e-02],\n",
       "          [-3.1355e-01,  1.1843e+00, -2.2052e-01,  ..., -2.3697e-01,\n",
       "           -6.5493e-01, -4.2452e-01],\n",
       "          ...,\n",
       "          [ 3.0894e-01, -2.8426e+00,  1.0455e+00,  ...,  5.3069e-01,\n",
       "            2.1004e+00, -3.7606e-01],\n",
       "          [ 3.8979e-01, -3.1218e+00,  1.1811e-01,  ...,  7.3254e-01,\n",
       "            2.3976e+00,  1.3589e+00],\n",
       "          [ 1.3207e+00, -2.3251e+00,  1.1011e+00,  ...,  3.3412e-01,\n",
       "            3.4561e+00,  1.3619e+00]],\n",
       "\n",
       "         [[ 2.5088e-01,  1.4615e+00,  4.4393e-01,  ...,  1.2886e+00,\n",
       "           -1.2842e+00,  3.5226e-01],\n",
       "          [-1.3369e+00,  9.9381e-01,  4.1615e-01,  ..., -3.0087e+00,\n",
       "            9.3622e-01,  2.0471e-01],\n",
       "          [ 2.4322e-01,  1.4769e+00,  4.4993e-01,  ...,  1.3032e+00,\n",
       "           -1.2831e+00,  3.5935e-01],\n",
       "          ...,\n",
       "          [-1.4668e+00, -1.1155e+00, -8.7410e-01,  ..., -2.0226e+00,\n",
       "            3.4553e+00, -1.8239e-01],\n",
       "          [-1.5300e+00, -4.6737e-01, -3.5101e-01,  ..., -1.8064e+00,\n",
       "            3.3618e+00, -5.9406e-02],\n",
       "          [-2.0188e+00, -1.5266e-01,  2.3415e-01,  ..., -2.0885e+00,\n",
       "            2.8881e+00, -3.0433e-01]],\n",
       "\n",
       "         [[-1.1534e+00, -6.5536e-01,  2.1142e-01,  ...,  9.7712e-01,\n",
       "            4.0234e-02, -6.8630e-01],\n",
       "          [-1.6949e+00,  8.9160e-01, -3.9954e-01,  ..., -1.1871e+00,\n",
       "           -3.9657e+00, -2.6074e-01],\n",
       "          [-1.1333e+00, -6.8468e-01,  1.7740e-01,  ...,  1.0080e+00,\n",
       "            7.2581e-02, -6.9113e-01],\n",
       "          ...,\n",
       "          [-1.3919e+00,  8.2474e-01, -3.5582e+00,  ..., -1.5947e+00,\n",
       "           -2.8193e+00, -2.1330e-01],\n",
       "          [ 1.7419e-01,  4.0309e-01, -9.2257e-01,  ..., -7.7894e-01,\n",
       "           -3.5099e+00, -2.5866e+00],\n",
       "          [ 4.0007e-01, -1.4075e+00, -2.7832e+00,  ..., -6.4752e-01,\n",
       "           -2.8789e+00, -2.7979e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.8752e-01, -2.4928e-01, -7.5212e-01,  ...,  4.9552e-01,\n",
       "            3.0521e-02,  3.5195e-01],\n",
       "          [-9.6952e-01, -1.6511e-01,  3.5803e+00,  ...,  1.5276e-02,\n",
       "            2.2335e+00,  6.2473e-01],\n",
       "          [-3.6275e-01, -2.1758e-01, -7.7428e-01,  ...,  5.0935e-01,\n",
       "            3.8025e-02,  3.5421e-01],\n",
       "          ...,\n",
       "          [ 1.7264e-02, -1.0631e+00,  2.6602e+00,  ..., -1.1974e+00,\n",
       "           -9.6310e-02, -1.4384e-01],\n",
       "          [-4.9256e-01, -6.2708e-01,  2.2555e+00,  ..., -1.0622e+00,\n",
       "           -4.0048e-01, -2.7720e-01],\n",
       "          [-7.8264e-01, -8.9279e-01,  2.0104e+00,  ..., -2.0126e-01,\n",
       "           -6.5600e-01,  1.1032e-01]],\n",
       "\n",
       "         [[-8.2193e-03, -2.9576e-01, -7.5576e-01,  ..., -3.0160e-01,\n",
       "           -1.8257e-02, -2.2096e-01],\n",
       "          [-2.7759e-01,  7.2988e-01,  1.7638e+00,  ..., -7.5421e-01,\n",
       "            2.3857e+00,  1.3472e-01],\n",
       "          [ 8.8776e-03, -3.0078e-01, -7.7699e-01,  ..., -3.0545e-01,\n",
       "           -1.3623e-02, -2.3207e-01],\n",
       "          ...,\n",
       "          [-1.2653e+00,  8.6798e-01,  3.2914e+00,  ..., -7.2469e-01,\n",
       "           -1.1472e+00,  7.8755e-01],\n",
       "          [-1.5221e+00,  2.4278e-01,  2.4603e+00,  ..., -1.3752e+00,\n",
       "           -8.7769e-01,  5.1637e-01],\n",
       "          [-1.9124e+00,  6.8911e-01,  2.1413e+00,  ..., -1.1125e+00,\n",
       "           -5.6911e-01,  1.2066e-01]],\n",
       "\n",
       "         [[-1.0405e+00, -4.6234e-01, -1.0891e+00,  ...,  2.4527e-01,\n",
       "           -2.3732e-01, -2.5978e-01],\n",
       "          [-3.3215e-01,  1.2598e+00,  1.3100e+00,  ...,  1.1111e+00,\n",
       "           -2.3554e-02, -1.9107e+00],\n",
       "          [-1.0453e+00, -4.3475e-01, -1.1043e+00,  ...,  2.6525e-01,\n",
       "           -2.0129e-01, -2.4066e-01],\n",
       "          ...,\n",
       "          [-3.9033e-02,  6.2053e-01,  9.1219e-01,  ...,  1.8435e-01,\n",
       "           -1.2086e+00, -2.2188e-01],\n",
       "          [ 9.0655e-01,  2.1613e-03,  6.8975e-01,  ..., -4.0464e-02,\n",
       "           -1.9016e+00,  6.8926e-01],\n",
       "          [ 8.1753e-01, -8.7947e-01,  8.4753e-01,  ..., -7.7662e-01,\n",
       "           -1.8275e+00,  1.4327e+00]]]], grad_fn=<CopyBackwards>), tensor([[[[ 4.9255e-03, -2.1261e-02,  7.8156e-04,  ..., -1.6782e-02,\n",
       "            3.2595e-02,  6.7029e-02],\n",
       "          [ 2.0143e-03,  4.4200e-01, -3.6446e-01,  ..., -8.6670e-01,\n",
       "           -2.2889e-01,  3.6407e-02],\n",
       "          [-6.7355e-04, -1.1795e-02, -6.6793e-03,  ..., -2.1442e-02,\n",
       "            1.6838e-02,  5.7199e-02],\n",
       "          ...,\n",
       "          [ 2.0093e-01,  3.2763e-01, -1.8034e-01,  ...,  2.2643e-02,\n",
       "           -3.0986e-01, -6.5273e-01],\n",
       "          [ 4.5568e-01,  8.3538e-02, -8.3620e-01,  ..., -2.4221e-01,\n",
       "            3.6052e-01, -8.1662e-01],\n",
       "          [ 7.4372e-01,  1.0583e-01, -9.0792e-01,  ...,  4.0101e-01,\n",
       "            3.1041e-01, -1.2719e+00]],\n",
       "\n",
       "         [[-1.6656e-03,  1.9523e-02, -6.9370e-02,  ...,  9.3521e-03,\n",
       "            3.0768e-02, -3.5908e-02],\n",
       "          [-9.4824e-01,  3.4580e-01, -1.5609e-01,  ...,  3.7459e-01,\n",
       "            4.9792e-01, -6.9890e-02],\n",
       "          [ 1.2844e-04,  2.5347e-02, -6.4952e-02,  ...,  2.4720e-02,\n",
       "            3.9067e-02, -3.7585e-02],\n",
       "          ...,\n",
       "          [ 2.0844e-02, -2.3429e-01, -6.4372e-01,  ...,  8.0600e-02,\n",
       "            3.6094e-01,  1.4145e-01],\n",
       "          [ 3.5586e-02, -1.8011e-01, -7.8637e-01,  ..., -4.7761e-01,\n",
       "           -6.2966e-04,  1.6557e-01],\n",
       "          [ 1.0047e-01,  9.3202e-02, -1.1396e+00,  ..., -3.7504e-01,\n",
       "           -3.7952e-01,  4.8781e-02]],\n",
       "\n",
       "         [[ 7.7469e-02,  6.3344e-02, -4.8990e-02,  ..., -2.5800e-02,\n",
       "            2.8572e-02,  1.0124e-01],\n",
       "          [ 3.6717e-01, -1.8748e-02,  8.0235e-01,  ..., -5.9556e-01,\n",
       "           -2.5172e-01, -2.4950e-01],\n",
       "          [ 7.8930e-02,  6.7999e-02, -3.6727e-02,  ..., -2.6142e-02,\n",
       "            3.3276e-02,  9.6851e-02],\n",
       "          ...,\n",
       "          [-6.0683e-01,  4.4378e-01, -3.5900e-01,  ..., -6.7028e-01,\n",
       "           -4.9652e-01,  9.8308e-02],\n",
       "          [ 2.5021e-02,  1.7156e-01, -4.8189e-02,  ..., -4.8778e-01,\n",
       "           -7.3006e-01,  2.9959e-01],\n",
       "          [ 6.1336e-02,  2.6215e-01,  1.0381e-01,  ..., -2.3711e-01,\n",
       "           -4.7565e-01,  2.8310e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5832e-02,  8.5535e-03,  1.9275e-02,  ...,  3.3277e-02,\n",
       "           -4.0825e-02, -1.8935e-02],\n",
       "          [ 3.0533e-01, -3.8176e-01, -8.3258e-01,  ...,  5.2178e-01,\n",
       "            2.0951e-02, -4.4026e-01],\n",
       "          [ 2.8614e-02,  1.2484e-02,  2.9896e-02,  ...,  2.7254e-02,\n",
       "           -4.3087e-02, -1.7555e-02],\n",
       "          ...,\n",
       "          [-3.8627e-01, -5.6928e-01, -7.6582e-01,  ...,  5.8427e-01,\n",
       "           -1.5518e-01,  6.4076e-01],\n",
       "          [-2.9303e-01, -6.2967e-01, -1.2586e+00,  ...,  8.9125e-02,\n",
       "           -6.9744e-01, -9.5346e-02],\n",
       "          [ 9.0121e-02, -5.6817e-01, -8.6665e-01,  ...,  2.1768e-01,\n",
       "           -3.3476e-01, -1.4977e-01]],\n",
       "\n",
       "         [[-3.1933e-02,  3.6662e-04, -4.3349e-02,  ...,  1.9673e-02,\n",
       "           -1.0228e-02,  4.2976e-02],\n",
       "          [-6.7329e-02,  1.5284e-01, -1.0069e-01,  ..., -8.2640e-01,\n",
       "           -1.0713e+00,  1.3688e-01],\n",
       "          [-4.1038e-02, -2.3121e-04, -3.9594e-02,  ...,  2.1062e-02,\n",
       "           -1.6463e-02,  4.5335e-02],\n",
       "          ...,\n",
       "          [ 3.0618e-01, -1.0246e+00,  9.6900e-01,  ...,  7.0705e-01,\n",
       "           -3.1609e-01,  6.1194e-01],\n",
       "          [-5.4342e-01, -2.8574e-01,  1.0367e+00,  ...,  9.0188e-01,\n",
       "           -1.5075e-01,  1.5542e-01],\n",
       "          [-4.2785e-01, -2.3999e-01,  6.5723e-01,  ...,  5.0943e-01,\n",
       "           -1.3872e-01,  5.9643e-01]],\n",
       "\n",
       "         [[-3.4518e-04,  5.9864e-02, -1.9913e-02,  ..., -5.0640e-02,\n",
       "            2.1679e-02, -6.6060e-02],\n",
       "          [-3.3419e-01, -5.4096e-02, -1.2759e-01,  ..., -2.4844e-01,\n",
       "            6.0699e-02, -3.8197e-01],\n",
       "          [-3.8946e-03,  4.3557e-02, -1.6830e-02,  ..., -5.0534e-02,\n",
       "            1.5201e-02, -6.9589e-02],\n",
       "          ...,\n",
       "          [-4.2124e-01,  3.3370e-01, -7.0749e-01,  ..., -5.5396e-01,\n",
       "            3.4937e-01, -8.1025e-01],\n",
       "          [-4.9290e-01,  4.3184e-01, -1.1598e-01,  ..., -3.5875e-01,\n",
       "            2.3164e-04, -6.2413e-01],\n",
       "          [-3.7611e-01,  4.9454e-01, -1.5932e-01,  ..., -2.1373e-01,\n",
       "           -1.6451e-01, -4.5101e-01]]]], grad_fn=<CopyBackwards>), tensor([[[[-0.1128, -1.2418,  1.0733,  ...,  0.5806, -0.4897,  0.3651],\n",
       "          [ 1.6065, -2.9166,  0.9557,  ...,  1.7090, -0.6087,  0.5445],\n",
       "          [ 0.5046, -0.9563, -1.9493,  ...,  0.2352, -0.1629, -1.2992],\n",
       "          ...,\n",
       "          [ 1.0101, -0.4612,  0.0912,  ..., -0.2357, -0.7731, -1.0317],\n",
       "          [ 0.9992, -0.4424,  0.9760,  ..., -0.5337, -0.6247,  1.1750],\n",
       "          [ 0.9478,  1.1486,  0.0411,  ..., -0.6264,  0.8951,  1.7537]],\n",
       "\n",
       "         [[-1.7156, -0.5667,  1.8351,  ...,  1.7983, -0.8228,  0.8550],\n",
       "          [-2.0052, -0.8207,  1.3565,  ...,  1.4895, -1.3724, -0.4811],\n",
       "          [-1.7307, -0.8938,  0.2556,  ..., -0.6487, -0.4737, -1.1577],\n",
       "          ...,\n",
       "          [ 0.2505, -1.5520, -2.4922,  ...,  1.7463,  0.5115,  0.1374],\n",
       "          [ 0.0708, -1.7433, -1.8248,  ...,  1.4921,  0.8207,  0.1736],\n",
       "          [ 1.9288,  0.2657,  0.0931,  ...,  0.0655,  0.4261,  0.4254]],\n",
       "\n",
       "         [[-1.3085, -0.6170, -0.5180,  ...,  1.1365, -0.1693,  0.4482],\n",
       "          [-1.2037, -1.4695, -0.8190,  ...,  0.6576, -0.2020,  0.9014],\n",
       "          [-0.4917, -2.3707, -0.1759,  ...,  1.5778, -0.8256, -0.7863],\n",
       "          ...,\n",
       "          [ 0.2815, -0.2046, -2.1629,  ...,  0.3698,  1.7848, -2.0359],\n",
       "          [-1.2841,  1.7476, -1.6932,  ...,  1.4670,  2.6631, -1.9184],\n",
       "          [ 0.8291,  0.0465,  0.8031,  ...,  0.3033, -0.5485,  0.9038]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4513,  1.3185, -0.9483,  ..., -0.6017, -0.1278,  0.8513],\n",
       "          [-2.3070,  0.6933, -0.9432,  ...,  0.0321, -0.2351, -0.9914],\n",
       "          [-1.3291,  0.0640,  0.4267,  ...,  0.1189, -0.2277, -0.7227],\n",
       "          ...,\n",
       "          [-0.9053, -2.9441, -0.0212,  ...,  0.2154,  0.6257,  3.1348],\n",
       "          [ 0.5487, -2.2322, -0.0447,  ...,  0.6699,  0.5609,  2.9532],\n",
       "          [-1.1117,  0.4764,  0.2916,  ...,  0.5299,  0.0771, -0.4337]],\n",
       "\n",
       "         [[-0.7744, -0.7811,  1.1299,  ...,  2.2779,  2.3097, -2.4254],\n",
       "          [-1.3314, -1.2385,  2.9184,  ...,  0.8855,  1.2130, -0.6211],\n",
       "          [-0.0750,  0.3256,  1.4624,  ..., -1.0484,  0.2351, -0.2079],\n",
       "          ...,\n",
       "          [-1.8175,  2.5420,  1.7925,  ...,  1.2024, -0.4248, -0.8480],\n",
       "          [-1.3777,  2.3903,  0.9138,  ...,  1.3112, -1.3494, -1.2714],\n",
       "          [ 0.2355, -0.2819,  0.5835,  ...,  0.8604,  1.4339, -0.2801]],\n",
       "\n",
       "         [[-0.9619, -0.2282, -0.8912,  ...,  0.5430,  1.4870,  1.4483],\n",
       "          [-0.5776,  1.2609,  0.0658,  ...,  1.7339, -1.4733,  0.3060],\n",
       "          [ 0.5893,  3.8315,  1.0393,  ...,  1.1184, -0.6442, -1.2973],\n",
       "          ...,\n",
       "          [-0.8909,  2.3109,  0.6307,  ...,  0.9888,  1.0174,  0.4667],\n",
       "          [-0.6287,  0.9973, -0.0956,  ...,  0.7496,  1.9919,  0.9129],\n",
       "          [ 0.5594,  0.6870,  1.5918,  ..., -0.7570,  0.3347,  0.3930]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[-0.3884, -0.2048,  0.1780,  ...,  0.2176, -0.0477,  0.1173],\n",
       "          [ 0.2932,  0.5974,  1.1830,  ...,  1.2056,  0.1544, -0.5935],\n",
       "          [ 0.3436,  0.5405, -0.0390,  ..., -0.4886, -0.2064, -0.7867],\n",
       "          ...,\n",
       "          [ 0.6116, -0.4878, -0.2018,  ..., -0.1728, -0.8604,  0.4527],\n",
       "          [-0.0495, -0.0144, -0.3011,  ..., -0.3194, -1.0011,  0.7669],\n",
       "          [-0.3297,  0.0986,  0.3006,  ..., -0.1783, -0.3068, -0.1183]],\n",
       "\n",
       "         [[ 0.2916,  0.0228, -0.1824,  ..., -0.8052,  0.0253, -0.5618],\n",
       "          [ 0.0888, -0.6453,  0.1109,  ...,  0.7818, -0.1088, -0.1187],\n",
       "          [ 0.2098, -0.3459,  0.1711,  ..., -0.5001,  0.4613,  0.4001],\n",
       "          ...,\n",
       "          [ 1.3199, -0.0357,  0.2080,  ..., -1.0789, -0.3039,  0.9187],\n",
       "          [ 0.8938,  0.0794, -0.2298,  ..., -0.3578,  0.0474,  0.1915],\n",
       "          [-0.0557, -0.0408,  0.0799,  ..., -0.0527, -0.0548,  0.0221]],\n",
       "\n",
       "         [[-0.1525,  0.2759,  0.1455,  ..., -0.1979, -0.0267, -0.1071],\n",
       "          [-0.2402, -0.0203,  0.4195,  ..., -0.4790, -0.3282, -0.4352],\n",
       "          [-0.3266, -0.1400,  0.6141,  ...,  0.1470,  0.1301,  0.1556],\n",
       "          ...,\n",
       "          [ 0.1107,  0.5574, -0.3246,  ..., -0.1610, -0.6370, -0.4753],\n",
       "          [-0.0107, -0.2753,  0.4298,  ..., -0.0112, -0.3614,  0.0086],\n",
       "          [ 0.0196, -0.0389,  0.0656,  ...,  0.1681,  0.0163, -0.0197]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4233,  0.0497, -0.7816,  ...,  0.0215, -0.3932,  0.1196],\n",
       "          [ 0.3362,  0.3709,  0.1936,  ..., -0.2175,  0.5101, -0.4162],\n",
       "          [-0.0062, -0.2665, -0.8344,  ...,  0.0680, -0.2418, -0.1406],\n",
       "          ...,\n",
       "          [ 0.8214, -0.2423,  0.0142,  ..., -0.0795, -0.0993, -0.2089],\n",
       "          [ 0.4885,  0.3901,  0.1016,  ..., -0.2112, -0.2051, -0.2458],\n",
       "          [-0.0076, -0.0315, -0.0227,  ...,  0.0081, -0.0444, -0.0222]],\n",
       "\n",
       "         [[-0.5160,  0.1339,  0.2799,  ...,  0.0266,  0.3684, -0.0054],\n",
       "          [-0.8167,  0.5732,  0.3844,  ..., -0.2931,  0.3600,  0.1080],\n",
       "          [-0.4047, -0.8780, -0.0960,  ...,  0.1287,  0.7068,  0.3660],\n",
       "          ...,\n",
       "          [-0.3476,  0.5418,  0.5022,  ...,  0.3663,  0.0611, -0.5487],\n",
       "          [-0.4081,  0.6269,  0.4711,  ..., -0.2644,  0.1612, -0.3848],\n",
       "          [-0.1000, -0.1962,  0.5232,  ..., -0.0600, -0.0485, -0.2647]],\n",
       "\n",
       "         [[ 0.0393, -0.4531,  0.1161,  ...,  0.3490,  0.4452, -0.4855],\n",
       "          [ 0.1742, -0.4859, -0.2045,  ..., -0.2072, -0.0567,  0.5521],\n",
       "          [-0.5240,  0.2420,  0.2972,  ..., -0.1678, -0.3629,  0.4323],\n",
       "          ...,\n",
       "          [-0.1695, -0.5634, -0.0781,  ..., -0.2495, -0.2637,  0.0838],\n",
       "          [-0.4746, -0.5790, -0.1544,  ..., -0.0394,  0.2255,  0.1977],\n",
       "          [-0.2301,  0.2717, -0.1595,  ...,  0.5334,  0.2126,  0.1524]]]],\n",
       "       grad_fn=<CopyBackwards>)), (tensor([[[[-1.5581e-01, -6.3882e-02, -3.3653e-01,  ..., -7.6630e-02,\n",
       "            9.6708e-02, -1.3310e-01],\n",
       "          [-2.8914e-01, -7.6321e-02,  4.9538e+00,  ..., -5.8476e-01,\n",
       "            7.7757e-01,  1.9358e+00],\n",
       "          [-6.2508e-02, -2.8214e-01,  4.3492e-01,  ...,  4.7253e-02,\n",
       "            6.1049e-01,  5.8801e-02],\n",
       "          ...,\n",
       "          [ 2.0622e+00, -1.0836e+00,  5.7178e+00,  ..., -2.2811e+00,\n",
       "            2.2141e-01,  1.0303e+00],\n",
       "          [ 1.4050e+00, -5.6738e-02,  5.4647e+00,  ..., -2.3747e+00,\n",
       "            6.3497e-01,  1.6723e+00],\n",
       "          [ 1.0218e+00, -1.5543e+00,  5.2700e+00,  ..., -2.4226e+00,\n",
       "            1.0266e+00,  2.1964e+00]],\n",
       "\n",
       "         [[ 3.7975e-01,  1.0639e-01,  3.7458e-02,  ..., -8.2343e-02,\n",
       "           -3.3463e-01,  1.3513e-01],\n",
       "          [ 4.1711e-01, -6.6753e-01, -1.3688e+00,  ...,  1.5749e+00,\n",
       "           -4.2028e-01,  4.3823e-01],\n",
       "          [ 4.1487e-01,  1.2041e-01, -4.3180e-01,  ...,  1.9221e-02,\n",
       "           -6.6055e-01,  2.1620e-01],\n",
       "          ...,\n",
       "          [-2.0572e-01, -1.0046e+00, -1.5236e+00,  ...,  8.2436e-01,\n",
       "            8.4810e-01,  5.1786e-01],\n",
       "          [ 1.1783e-01, -8.3272e-01, -1.8462e+00,  ...,  4.6757e-01,\n",
       "            8.5168e-02, -5.5858e-02],\n",
       "          [-1.5941e-01, -7.0941e-01, -1.4792e+00,  ..., -8.0485e-02,\n",
       "           -2.7211e-01,  1.6193e+00]],\n",
       "\n",
       "         [[-6.3742e-01, -3.7217e-01, -1.6800e-01,  ..., -7.7673e-01,\n",
       "           -3.7373e-02,  9.6438e-01],\n",
       "          [ 1.4436e+00,  7.7120e-01,  1.3674e+00,  ...,  2.7810e+00,\n",
       "           -1.3934e+00, -4.5673e+00],\n",
       "          [-4.3179e-01, -3.5942e-01, -2.3042e-01,  ..., -2.3018e-01,\n",
       "            3.0649e-01,  6.6861e-01],\n",
       "          ...,\n",
       "          [ 1.7595e+00,  8.0624e-01, -9.4300e-01,  ...,  3.5344e+00,\n",
       "           -6.1116e-01, -4.5997e+00],\n",
       "          [ 1.7631e+00,  1.3560e+00, -6.2940e-01,  ...,  3.0545e+00,\n",
       "           -8.2493e-01, -4.7792e+00],\n",
       "          [ 1.8686e+00,  2.2091e+00, -1.0592e+00,  ...,  2.8242e+00,\n",
       "           -1.4157e+00, -4.4351e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.7568e-02, -1.3156e-01,  2.5609e-03,  ..., -8.0819e-02,\n",
       "           -2.0498e-02,  5.4875e-02],\n",
       "          [ 1.0301e+00,  1.9397e-01,  1.9264e-01,  ..., -1.6182e+00,\n",
       "            5.4772e-01,  1.8886e+00],\n",
       "          [-9.3621e-02,  7.7350e-03,  5.3161e-02,  ..., -1.1686e-01,\n",
       "           -8.2607e-02,  2.0687e-02],\n",
       "          ...,\n",
       "          [-8.1084e-03,  8.7328e-01,  6.2979e-02,  ..., -5.0766e-01,\n",
       "            1.0067e+00,  1.0928e+00],\n",
       "          [ 6.0628e-01,  1.0723e+00, -5.6596e-01,  ...,  3.9359e-01,\n",
       "           -2.9925e-03,  1.7863e+00],\n",
       "          [-1.6573e-01,  5.5467e-01, -9.9270e-01,  ...,  2.4655e-01,\n",
       "            8.2337e-01,  1.6169e+00]],\n",
       "\n",
       "         [[ 8.1660e-01,  3.1495e-02,  3.6310e-01,  ...,  2.8374e-02,\n",
       "            8.7942e-03, -2.2475e-02],\n",
       "          [-5.3443e+00,  1.6816e-01, -1.5525e+00,  ..., -3.7418e-01,\n",
       "           -3.9913e-01,  9.7600e-01],\n",
       "          [ 6.4426e-02,  1.1100e-01, -7.8075e-02,  ..., -1.2217e-01,\n",
       "            2.6224e-02, -7.5316e-03],\n",
       "          ...,\n",
       "          [-3.7704e+00,  7.7108e-01, -1.6639e+00,  ..., -9.0064e-01,\n",
       "           -6.8814e-01,  2.2727e+00],\n",
       "          [-2.6918e+00,  8.7986e-01, -2.5781e+00,  ..., -6.8424e-01,\n",
       "           -8.1481e-01,  2.8587e+00],\n",
       "          [-3.0426e+00,  9.1049e-01, -2.6922e+00,  ...,  1.2169e-01,\n",
       "           -9.9839e-01,  2.1100e+00]],\n",
       "\n",
       "         [[ 5.4967e-01, -3.1668e-01, -1.8345e-02,  ...,  1.2691e-01,\n",
       "           -1.1695e-01,  1.9581e-01],\n",
       "          [-8.1404e+00, -3.7858e-01,  2.2797e+00,  ..., -7.8361e-01,\n",
       "           -2.2012e-01, -2.7261e+00],\n",
       "          [-5.7523e-01, -4.8207e-01,  3.1735e-01,  ..., -1.7608e-01,\n",
       "           -3.8690e-02, -4.4916e-01],\n",
       "          ...,\n",
       "          [-5.8566e+00,  1.5177e+00,  1.1830e+00,  ..., -1.2210e+00,\n",
       "           -1.4768e+00, -1.5782e+00],\n",
       "          [-5.6735e+00,  7.5635e-01,  1.2263e+00,  ..., -7.3290e-01,\n",
       "           -3.8674e-01, -1.8622e+00],\n",
       "          [-6.1326e+00,  6.6343e-01,  1.2526e+00,  ..., -1.5917e+00,\n",
       "           -3.0909e-01, -1.2802e+00]]]], grad_fn=<CopyBackwards>), tensor([[[[-1.3056e-02,  2.8380e-03, -1.1226e-02,  ...,  9.5187e-04,\n",
       "           -1.8653e-02,  1.3132e-02],\n",
       "          [ 2.4018e-01,  1.1183e+00,  3.8166e-01,  ..., -4.0641e-01,\n",
       "           -6.8308e-01,  7.0084e-01],\n",
       "          [-9.2117e-03, -3.0535e-02, -1.1038e-02,  ...,  2.1713e-02,\n",
       "           -4.8438e-02, -3.6426e-03],\n",
       "          ...,\n",
       "          [ 7.4229e-01,  1.0652e-01, -6.6571e-01,  ..., -1.7175e-01,\n",
       "           -4.7483e-02, -4.4736e-01],\n",
       "          [-1.0056e-01,  6.0130e-01,  3.1985e-01,  ...,  2.2594e-01,\n",
       "            2.0029e-01,  1.4717e-01],\n",
       "          [-2.7367e-01, -5.5257e-02,  2.9491e-01,  ..., -1.0404e+00,\n",
       "            3.3914e-01, -2.6097e-01]],\n",
       "\n",
       "         [[ 8.8524e-03, -1.3688e-02,  7.4470e-03,  ...,  2.0977e-02,\n",
       "            1.5477e-02,  1.1068e-02],\n",
       "          [ 8.8779e-04, -1.8523e-02,  9.6999e-02,  ..., -1.0916e-01,\n",
       "           -1.2763e-01, -6.6443e-02],\n",
       "          [-8.6355e-03, -5.2815e-03, -2.8556e-02,  ...,  8.0243e-02,\n",
       "            4.8000e-02,  3.4102e-02],\n",
       "          ...,\n",
       "          [ 4.1900e-01, -1.8183e-01,  1.7278e-01,  ...,  1.0920e-01,\n",
       "           -2.1796e-01,  4.6210e-02],\n",
       "          [ 1.4036e-01,  1.0438e-01,  2.4812e-01,  ..., -1.3377e-01,\n",
       "           -3.1285e-01,  1.9379e-02],\n",
       "          [ 3.4235e-01, -5.8104e-02,  8.5620e-02,  ..., -1.0950e-01,\n",
       "           -2.3579e-01, -1.8174e-01]],\n",
       "\n",
       "         [[ 1.3333e-02,  9.5467e-03,  2.0398e-02,  ..., -1.8190e-02,\n",
       "            3.0476e-02,  1.9913e-02],\n",
       "          [ 5.3383e-01,  6.0928e-02,  2.6514e-01,  ..., -6.7339e-01,\n",
       "           -3.2988e-01,  1.2411e-01],\n",
       "          [ 9.4912e-02, -1.7769e-02, -1.0545e-02,  ..., -2.2072e-02,\n",
       "           -1.4209e-02,  6.9231e-02],\n",
       "          ...,\n",
       "          [ 1.4221e-01, -8.1781e-02, -5.8245e-01,  ..., -3.0343e-01,\n",
       "           -4.8035e-01,  3.3001e-01],\n",
       "          [ 4.6062e-01,  6.2975e-01, -4.5628e-01,  ..., -4.1008e-01,\n",
       "           -2.4584e-01,  1.9084e-01],\n",
       "          [ 9.5934e-02,  4.7724e-01, -2.4923e-01,  ..., -5.1767e-01,\n",
       "           -4.1259e-01,  4.9546e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9903e-02, -2.9050e-02, -4.9044e-03,  ...,  7.6355e-03,\n",
       "           -9.5253e-02,  7.7174e-03],\n",
       "          [-5.4984e-01,  2.4920e-01, -5.9739e-02,  ...,  1.7404e-01,\n",
       "            2.0357e-01,  2.4834e-01],\n",
       "          [-3.3720e-02,  7.5398e-03, -3.9882e-02,  ...,  2.3297e-02,\n",
       "            8.8513e-02, -3.3376e-03],\n",
       "          ...,\n",
       "          [-1.3126e-01, -5.3138e-01,  8.6258e-02,  ...,  3.5674e-01,\n",
       "           -1.1639e-01,  1.3144e-01],\n",
       "          [-5.4834e-01, -5.7044e-01, -5.6389e-01,  ...,  5.4902e-02,\n",
       "            2.7177e-01,  5.6636e-01],\n",
       "          [-7.3079e-01, -3.7366e-01,  8.2954e-02,  ...,  1.9219e-01,\n",
       "            7.8412e-02,  5.5914e-01]],\n",
       "\n",
       "         [[ 3.1207e-03, -5.7597e-03, -1.5423e-02,  ...,  7.5428e-03,\n",
       "           -1.3102e-02,  1.1050e-02],\n",
       "          [-9.4576e-02, -6.2497e-01, -9.2377e-02,  ...,  2.0990e-01,\n",
       "           -1.3928e-01,  8.1447e-02],\n",
       "          [-2.3799e-02, -1.3626e-03, -1.3672e-01,  ...,  1.6307e-02,\n",
       "           -1.1632e-01,  7.7526e-02],\n",
       "          ...,\n",
       "          [-3.7720e-01,  2.0181e-01, -2.0828e-01,  ...,  3.2217e-01,\n",
       "            4.9052e-01, -3.5506e-02],\n",
       "          [-1.5406e-01, -2.5566e-01, -3.6814e-01,  ...,  8.3959e-01,\n",
       "            4.5164e-01,  1.3213e-01],\n",
       "          [-3.9862e-01, -4.4230e-01, -4.0560e-01,  ...,  3.5746e-01,\n",
       "           -6.6937e-02,  1.9493e-01]],\n",
       "\n",
       "         [[-1.9810e-03,  2.1796e-02,  8.6033e-03,  ...,  1.3407e-02,\n",
       "            8.8352e-03,  4.3534e-02],\n",
       "          [ 3.1238e-01, -5.0101e-01,  3.6113e-01,  ...,  1.6091e-01,\n",
       "            6.4531e-02,  1.8914e-01],\n",
       "          [-1.4511e-02,  2.9772e-02, -2.1401e-02,  ...,  4.0746e-02,\n",
       "            4.3604e-02,  1.2301e-01],\n",
       "          ...,\n",
       "          [ 1.4291e-01, -1.1272e-01, -2.2231e-01,  ...,  3.7879e-01,\n",
       "            3.6899e-01,  3.0230e-01],\n",
       "          [ 3.6320e-01,  1.2252e-02, -6.2073e-01,  ...,  3.5384e-01,\n",
       "            2.2281e-01,  1.0156e-01],\n",
       "          [ 3.7456e-01,  2.5375e-01, -1.8210e-01,  ...,  3.7157e-01,\n",
       "            3.1116e-01,  5.7692e-02]]]], grad_fn=<CopyBackwards>), tensor([[[[-1.5330, -3.9228, -1.6163,  ...,  0.6412,  1.7008,  0.6786],\n",
       "          [ 0.1413, -3.3862, -2.7413,  ..., -1.4142,  0.2928,  1.8239],\n",
       "          [ 0.3585, -0.9006, -2.3623,  ..., -1.9888,  0.2113, -0.6227],\n",
       "          ...,\n",
       "          [ 1.0544, -0.8778, -0.8760,  ...,  0.8168, -2.6881,  1.8955],\n",
       "          [ 1.1370, -0.2008, -0.1035,  ...,  2.0980, -1.4991,  1.9758],\n",
       "          [-1.6102,  1.1422, -1.8406,  ..., -1.5014,  0.6336, -0.0986]],\n",
       "\n",
       "         [[ 1.7410, -2.7056,  0.3654,  ...,  0.0883,  0.9876,  0.2271],\n",
       "          [ 0.2614, -3.4169,  0.1096,  ..., -0.2954,  0.7152,  1.3477],\n",
       "          [-0.2773, -1.2558, -1.3756,  ..., -1.4341,  0.0181,  0.0701],\n",
       "          ...,\n",
       "          [-1.6351,  0.1240,  0.9392,  ..., -1.8362,  2.4343,  0.1554],\n",
       "          [-0.0695, -0.4288,  1.4765,  ..., -0.7920,  1.1393,  0.5511],\n",
       "          [-0.7235,  1.2872, -0.5898,  ...,  0.2707, -0.0068, -0.8234]],\n",
       "\n",
       "         [[-0.1352, -1.9540, -0.6750,  ..., -1.2207, -0.9043,  2.5814],\n",
       "          [-0.5609, -1.4152,  0.1224,  ...,  0.5741, -0.3075,  3.6958],\n",
       "          [ 0.1314, -0.8429,  3.4471,  ..., -0.0324,  1.1750,  0.9021],\n",
       "          ...,\n",
       "          [-0.0706, -2.0978, -3.0386,  ..., -0.1948,  0.5818, -0.7307],\n",
       "          [-0.8041, -2.5720, -2.9066,  ..., -1.0383,  1.2570, -1.4279],\n",
       "          [ 3.2075,  1.6836,  0.9801,  ..., -0.5483, -2.1328, -1.3186]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7360, -1.0293, -1.2225,  ..., -0.2311, -0.5193, -0.3807],\n",
       "          [-2.3331, -1.9541, -1.2257,  ..., -0.2615, -1.0648, -0.6739],\n",
       "          [-2.6826, -0.4113, -0.8951,  ...,  0.4076, -2.4080,  0.0607],\n",
       "          ...,\n",
       "          [ 0.0891,  0.8494, -0.9413,  ...,  1.5137, -1.0396,  0.1352],\n",
       "          [-1.4768,  0.4712, -1.2947,  ...,  1.6796, -0.9261,  0.7367],\n",
       "          [-1.0263, -0.9958, -0.5231,  ..., -0.1265,  1.6273, -0.4518]],\n",
       "\n",
       "         [[-2.7245,  1.0747, -1.9464,  ...,  0.0513,  1.8107,  1.1521],\n",
       "          [-3.3408,  3.5794, -0.9934,  ...,  1.0353,  1.9698,  0.3505],\n",
       "          [-2.6654,  2.9583,  0.8553,  ..., -0.3533,  1.2175, -0.0774],\n",
       "          ...,\n",
       "          [-0.3697,  2.5337,  0.3673,  ..., -1.3306, -0.0387,  0.9186],\n",
       "          [ 0.3334,  2.2655,  0.3380,  ..., -1.8162,  1.3394,  1.2163],\n",
       "          [-1.2065, -0.1441, -1.6876,  ..., -1.0068,  1.2688, -0.1778]],\n",
       "\n",
       "         [[-1.5178, -1.1510,  1.4233,  ...,  2.5923, -1.9249, -0.6630],\n",
       "          [-1.6239, -0.9509,  0.0978,  ...,  3.4673, -2.7371,  0.9482],\n",
       "          [-1.4011,  2.6661,  0.2974,  ...,  2.4250, -1.9964,  1.3535],\n",
       "          ...,\n",
       "          [-0.7933, -0.7235,  1.1534,  ..., -0.3233, -1.6921,  1.7940],\n",
       "          [-1.3615, -2.6461,  1.3799,  ..., -0.2469, -1.6008,  1.1569],\n",
       "          [-0.1866, -0.3863,  0.3760,  ..., -0.3254,  0.1167, -0.1917]]]],\n",
       "       grad_fn=<CopyBackwards>), tensor([[[[ 1.1501e-01,  4.5917e-01, -1.1516e-01,  ..., -1.5727e-02,\n",
       "           -6.7616e-01, -1.3230e-01],\n",
       "          [ 7.0990e-01, -3.0379e-01, -3.4189e-01,  ...,  3.1820e-01,\n",
       "           -4.7377e-01, -4.5544e-01],\n",
       "          [-2.3525e-01, -6.3127e-01, -2.7043e-01,  ..., -7.2513e-02,\n",
       "            3.2111e-02,  5.9124e-01],\n",
       "          ...,\n",
       "          [ 7.6857e-01,  6.1715e-02, -2.9055e-01,  ...,  4.0900e-01,\n",
       "           -3.8261e-02,  1.6091e-01],\n",
       "          [ 1.7440e-01, -3.7987e-01, -1.7221e-01,  ..., -1.8675e-01,\n",
       "           -3.5142e-01,  4.4395e-02],\n",
       "          [-1.3778e-02, -1.5116e-02, -3.2804e-02,  ..., -2.6812e-03,\n",
       "            1.2902e-02, -4.4087e-02]],\n",
       "\n",
       "         [[-3.4481e-01,  3.3255e-01, -1.8414e-01,  ...,  5.3566e-02,\n",
       "           -2.1925e-01, -1.1506e-01],\n",
       "          [-1.4217e+00, -3.1159e-01,  9.9477e-02,  ..., -5.9288e-01,\n",
       "            6.6882e-01,  1.2907e-02],\n",
       "          [ 3.7929e-01,  6.0458e-01, -2.7541e-01,  ...,  2.3121e-01,\n",
       "           -3.4369e-01,  1.7429e+00],\n",
       "          ...,\n",
       "          [ 7.3538e-02, -5.8113e-01,  1.7551e-01,  ..., -2.0220e-01,\n",
       "            5.0875e-01, -1.0014e-02],\n",
       "          [ 1.6353e-01, -2.7525e-01, -5.8887e-01,  ..., -7.9070e-02,\n",
       "            1.7878e-01,  8.0678e-02],\n",
       "          [ 3.7520e-02,  5.9058e-03, -2.5749e-02,  ...,  7.7495e-02,\n",
       "           -8.1857e-03, -4.0963e-03]],\n",
       "\n",
       "         [[ 2.2927e-01, -2.5411e-01, -4.1473e-01,  ..., -4.9272e-02,\n",
       "            6.3547e-01, -2.3098e-01],\n",
       "          [ 5.2722e-03, -5.0947e-01, -6.6322e-01,  ...,  3.4749e-02,\n",
       "           -8.7526e-02,  6.8166e-01],\n",
       "          [ 8.5344e-01, -7.1071e-02, -1.6368e-01,  ...,  2.6567e-02,\n",
       "           -1.7788e-01,  2.7389e-02],\n",
       "          ...,\n",
       "          [ 1.1322e-01,  1.4280e-01, -3.8590e-01,  ...,  4.9730e-01,\n",
       "           -5.4134e-01, -2.5140e-01],\n",
       "          [ 4.3843e-01, -3.6761e-01, -6.3680e-01,  ...,  1.5653e-01,\n",
       "           -7.1860e-01, -7.0221e-01],\n",
       "          [-1.5133e-02, -1.3735e-02,  1.1493e-02,  ..., -5.8330e-03,\n",
       "            1.5759e-02, -7.3347e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6085e-01,  4.1920e-01,  1.0484e-01,  ..., -2.3087e-01,\n",
       "           -7.0583e-02, -4.8020e-02],\n",
       "          [ 6.4700e-02, -1.7568e-01,  9.0581e-01,  ...,  3.8439e-01,\n",
       "           -1.3891e-01,  2.5750e-01],\n",
       "          [-6.1997e-02,  1.6328e-01,  1.1251e-01,  ..., -3.6287e-01,\n",
       "           -1.4333e-01, -2.8851e-01],\n",
       "          ...,\n",
       "          [-2.1394e-01,  3.7051e-01,  4.2441e-01,  ...,  2.8228e-01,\n",
       "           -1.8054e-01,  2.7975e-01],\n",
       "          [ 5.7642e-02,  9.7751e-01, -4.0001e-01,  ...,  3.7501e-01,\n",
       "            5.4256e-01, -5.2005e-01],\n",
       "          [ 1.1329e-02, -1.6697e-03,  1.1914e-02,  ...,  2.2030e-02,\n",
       "            3.4721e-03, -2.0657e-02]],\n",
       "\n",
       "         [[-1.5434e-01, -4.0273e-01, -4.6603e-01,  ...,  1.0636e-01,\n",
       "           -1.3125e-01,  4.7031e-01],\n",
       "          [ 3.9893e-01, -3.9377e-01, -3.8384e-01,  ..., -1.0066e+00,\n",
       "            2.6826e-01,  1.0098e+00],\n",
       "          [-1.9217e-01,  4.3025e-01,  1.5068e-01,  ...,  4.4081e-01,\n",
       "           -2.8782e-01,  7.9911e-01],\n",
       "          ...,\n",
       "          [-7.4733e-01, -1.0228e-01,  3.7105e-02,  ..., -5.7695e-02,\n",
       "           -1.4712e-01,  7.8051e-01],\n",
       "          [-2.9854e-01, -2.0354e-02,  6.7224e-02,  ..., -1.6195e-01,\n",
       "            3.6554e-01,  3.5182e-01],\n",
       "          [ 3.9810e-02,  1.5659e-02,  3.1458e-02,  ..., -2.3368e-02,\n",
       "           -2.2753e-02, -1.1869e-03]],\n",
       "\n",
       "         [[-3.3805e-01,  2.5827e-01, -3.4257e-01,  ...,  6.5300e-01,\n",
       "           -4.9827e-01,  9.8607e-02],\n",
       "          [-1.3970e-01,  3.8584e-02, -1.1756e+00,  ...,  1.1804e+00,\n",
       "           -4.2253e-01, -6.2475e-01],\n",
       "          [ 9.9566e-01,  9.6870e-02, -1.1931e+00,  ...,  1.0520e-01,\n",
       "           -1.3000e-01,  7.7713e-01],\n",
       "          ...,\n",
       "          [ 3.6535e-01,  2.6906e-01,  5.6806e-01,  ...,  7.1432e-01,\n",
       "            2.8932e-01, -4.8795e-01],\n",
       "          [-1.0084e-01,  8.8040e-02, -4.0294e-01,  ..., -8.1329e-01,\n",
       "           -2.7330e-01, -4.9852e-01],\n",
       "          [ 8.1111e-01,  2.3626e-01,  8.5629e-01,  ...,  5.6384e-01,\n",
       "           -7.0402e-01,  3.7033e-01]]]], grad_fn=<CopyBackwards>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 0.2464,  0.1358, -0.0982,  ...,  0.0832, -0.1072,  0.2378],\n",
       "         [ 0.3381, -0.1182,  0.1537,  ..., -0.3589,  0.3943, -0.2407],\n",
       "         [ 0.4136, -0.4441, -0.2722,  ...,  0.2113, -0.5373, -0.2768],\n",
       "         ...,\n",
       "         [ 0.8109,  0.1011, -0.2805,  ...,  0.2509, -0.1029, -0.2049],\n",
       "         [ 0.8542, -0.1589, -0.3096,  ..., -0.4395, -0.2594, -0.3731],\n",
       "         [ 0.0760,  0.0113,  0.0126,  ..., -0.0189,  0.0222, -0.0010]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
    "output = model2(torch.tensor([input_ids]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5910e+00,  2.5640e+00,  1.3747e+00,  3.3591e+00,  5.7585e-01,\n",
       "        -1.8205e+00,  2.2158e+00,  1.2557e+00,  6.9837e-01,  1.4597e+00,\n",
       "         2.4318e-01, -2.0223e+00,  2.2234e+00,  1.2420e+00, -7.4025e-03,\n",
       "         3.2402e+00, -1.4127e+00,  1.8509e+00,  3.4712e-01, -3.0437e+00,\n",
       "         4.1268e+00,  1.2321e+00,  4.9061e-01,  1.1696e-01,  2.0364e+00,\n",
       "         3.7533e-01, -1.8060e+00, -1.4544e+00,  9.6806e-01,  1.4304e-01,\n",
       "         6.4117e-02,  1.5383e+00, -1.8814e+00, -8.7380e-01, -7.6932e-01,\n",
       "         1.3767e+00,  1.8780e+00,  4.0782e-01,  9.0700e-01,  1.9348e+00,\n",
       "         1.4394e+00, -3.3133e-01, -1.4788e+00, -1.8033e+00,  4.9778e-01,\n",
       "        -1.6058e+00,  1.5434e+00, -8.8079e-01, -2.2636e+00,  2.5295e+00,\n",
       "        -6.2439e-01,  2.2474e-01, -1.5547e+00, -3.4560e+00, -1.2337e+00,\n",
       "        -1.2477e+00,  8.5897e-01,  4.0533e-01,  2.9369e+00, -4.2344e-01,\n",
       "        -3.6229e-01, -2.0335e-01, -5.7681e-01, -7.8728e-01,  1.1724e+00,\n",
       "        -2.1079e+00,  1.6286e+00, -5.0691e-01,  2.6770e-01,  8.0814e-02,\n",
       "         1.9739e+00, -8.3651e-01, -1.5776e+00, -1.1057e+00,  4.6792e-01,\n",
       "        -3.0074e-01, -1.1532e+00, -1.3837e+00, -2.7442e-01,  8.2235e-01,\n",
       "        -1.4269e+00,  1.8323e+00,  4.1630e+00, -8.2169e-01,  3.8911e-01,\n",
       "        -1.2932e+00, -4.7906e-01,  5.6542e-02,  2.8715e+00,  4.2756e-01,\n",
       "        -2.7655e-01,  2.6993e-01,  3.3314e-01, -2.3145e+00,  8.1402e-01,\n",
       "        -1.0091e+00,  2.2807e+00, -3.0498e-01,  6.2257e-01, -9.7910e-01,\n",
       "        -1.8757e-01,  7.7540e-01,  5.8325e-01, -8.0042e-02,  9.7602e-01,\n",
       "        -2.2899e+00, -1.7371e+00, -1.3022e+00, -1.3342e+00,  1.7107e+00,\n",
       "        -1.4293e+00,  5.5086e-01, -2.1587e+00, -1.7359e-01,  1.5921e+00,\n",
       "        -8.8555e-01, -1.3700e+00,  2.6341e+00, -8.8090e-01, -2.9599e+00,\n",
       "        -5.0507e+00, -1.3226e+00,  9.1571e-01,  7.6351e-01, -1.5551e+00,\n",
       "         1.4612e-02, -2.5704e+00,  1.9180e+00, -2.0033e+00, -1.1213e+00,\n",
       "        -1.4928e+00,  2.0970e+00,  3.7658e-01,  6.8649e-01,  2.5140e-01,\n",
       "        -5.3548e+00, -3.4548e-02,  2.2370e-02, -2.3526e+00, -1.4052e+00,\n",
       "         6.5831e-01,  3.4778e-02, -1.1153e+00,  9.5044e-01, -1.1332e+00,\n",
       "        -1.6515e+00,  1.3588e+00,  1.1258e+00,  1.8945e+00,  2.9942e-01,\n",
       "        -4.4218e-02,  8.3414e-01, -1.3647e-03,  1.9039e+00,  3.5785e+00,\n",
       "        -3.2931e+00, -1.0699e+00, -1.2405e+00, -4.0615e-01,  1.3815e-01,\n",
       "        -1.5967e+00,  6.5159e-01, -1.7799e+00,  1.0772e+00,  7.0991e-01,\n",
       "         1.8567e+00, -2.2242e+00,  1.1110e+00,  1.3822e+00,  3.8234e-01,\n",
       "         2.0313e+00,  2.0080e-01,  4.9557e-01,  9.1714e-01, -3.7248e-01,\n",
       "        -1.9756e+00,  7.8344e-01, -1.4601e+00,  2.6196e+00,  3.8257e+00,\n",
       "        -4.9923e-01,  1.2911e+00, -1.7828e+00,  1.5580e+00,  1.6097e+00,\n",
       "         1.3219e+00, -6.8433e-01, -3.5992e-01,  2.0329e+00, -3.2628e+00,\n",
       "        -1.0973e+00, -9.3576e-01, -1.1929e+00, -2.1209e+00, -1.1550e+00,\n",
       "        -3.8389e+00,  7.3776e-01,  2.1178e+00, -2.3207e+00, -7.6960e-01,\n",
       "        -1.5688e+00, -1.8427e+00,  5.7302e-01,  1.3764e+00, -2.9317e+00,\n",
       "        -1.4725e+00, -4.7928e-01, -2.3332e+00,  8.5078e-01,  2.3598e+00,\n",
       "        -8.4000e-01,  2.0005e+00,  6.8505e-01, -1.3237e-01,  1.5776e+00,\n",
       "        -2.9291e+00, -8.5058e-01, -2.4475e+00,  1.0033e-01, -5.6712e-01,\n",
       "         1.1794e+00,  3.7303e-01, -1.6274e+00,  2.4232e+00, -3.7367e+00,\n",
       "         2.5023e+00,  2.0833e-01,  2.6673e-01, -4.4427e-01, -9.3673e-01,\n",
       "         1.1712e+00, -1.2408e+00, -1.1107e+00, -1.0662e+00, -4.0315e-01,\n",
       "         9.2840e-01, -3.9865e+00,  1.5874e+00,  1.7520e+00, -2.5514e+00,\n",
       "         4.2564e-01,  3.2453e-01,  9.3629e-01, -5.7393e-01, -1.2122e+00,\n",
       "        -1.6182e+00, -1.4831e+00,  2.2748e+00, -1.1365e+00,  3.9919e+00,\n",
       "        -1.3325e+00, -3.0565e+00,  2.3120e-02, -9.1118e-01, -3.1571e-01,\n",
       "         1.8132e+00,  2.1051e-01, -2.2772e-01,  6.6603e-02,  3.2286e+00,\n",
       "         1.1201e+00,  1.3629e+00, -3.9943e+00, -4.6799e+00,  1.0752e+00,\n",
       "         2.5523e-01,  6.0422e-01, -2.8062e+00,  1.0751e+00, -2.9267e+00,\n",
       "         4.0088e-01, -2.3363e-01, -1.2873e+00,  2.8498e+00, -2.5793e-01,\n",
       "        -2.9623e+00, -5.7692e-01, -1.0478e+00,  1.4997e+00,  4.1972e-01,\n",
       "        -6.1774e-01,  4.9241e-01, -1.2567e+00,  1.9347e+00,  1.2044e+00,\n",
       "         6.1424e-01, -2.6627e+00,  1.5727e+00,  2.8037e+00,  2.1775e+00,\n",
       "        -9.8083e-01, -1.1867e+00,  4.0747e-01, -1.4105e-01, -1.2566e+00,\n",
       "         2.7653e+00, -1.3517e+00,  1.2688e-01, -5.1005e+00, -4.7935e-01,\n",
       "        -1.2206e+00, -1.3205e-01, -5.9982e-01, -1.0605e+00,  1.1055e+00,\n",
       "         9.8792e-01,  9.2965e-01,  6.6733e-01,  1.3301e-01, -1.3026e-03,\n",
       "        -5.2497e-01, -2.5902e-01, -3.8466e-01,  2.9123e+00, -7.4613e-01,\n",
       "        -2.1709e-02, -3.5938e+00,  9.8322e-01,  1.3243e+00, -3.1516e+00,\n",
       "        -2.1819e+00,  2.4202e+00,  2.9402e+00, -3.7792e-02,  1.0735e+00,\n",
       "         1.0054e+00,  1.2535e+00, -5.0823e-01,  3.5730e+00,  6.6579e-01,\n",
       "         1.1825e+00,  1.0926e+00,  5.1821e-01,  3.7248e-01, -2.1656e+00,\n",
       "        -7.2018e-01,  9.2860e-01,  7.6341e-01,  6.8095e-01,  1.8596e+00,\n",
       "        -1.8389e-01,  4.4707e+00,  2.6276e+00, -2.5168e+00, -2.1506e+00,\n",
       "         5.0312e-01,  2.7414e+00,  2.5260e+00, -1.5981e+00, -5.9332e-01,\n",
       "         2.9995e-01,  2.4554e+00,  1.4473e+00,  2.1069e-01,  4.0208e+00,\n",
       "        -1.6960e+00,  1.0811e+00, -4.9678e+00,  9.8154e-01,  2.6231e+00,\n",
       "        -1.1488e+00, -2.0256e-01, -2.3868e-01, -6.9640e-01,  3.8476e-01,\n",
       "         2.1092e+00,  2.0972e-01,  8.1720e-01,  1.4495e+00, -1.1652e+00,\n",
       "         1.1697e+00,  3.8369e+00,  2.7832e+00, -8.2028e-01,  1.5830e-01,\n",
       "         5.3125e-01,  1.6714e+00, -1.4179e+00, -1.2713e-01,  6.8678e-01,\n",
       "        -3.3236e+00,  5.1667e-01,  9.3238e-01, -6.3274e-01,  2.8054e+00,\n",
       "        -5.7497e-01,  7.6267e-03,  2.0645e+00, -1.3326e+00, -2.0106e+00,\n",
       "        -2.7810e-01,  8.5357e-02,  5.4416e-01,  3.2315e-01,  1.0579e+00,\n",
       "        -1.3531e+00, -1.7516e+00, -1.9536e-01,  5.0784e-01, -2.9621e+00,\n",
       "         2.1409e+00, -6.3125e-01,  3.2515e-01,  7.4985e-01,  1.3570e+00,\n",
       "        -5.4328e-01, -7.4030e-01, -1.7702e+00, -1.4692e+00, -1.1974e+00,\n",
       "        -2.1538e-01,  3.7835e+00, -1.1416e+00, -6.0803e-01,  1.7138e+00,\n",
       "         5.3527e-01,  2.0431e-01, -1.1070e+00,  4.3370e-01,  9.2009e-01,\n",
       "         3.6856e+00,  2.8612e+00, -1.6455e+00, -2.3224e+00,  5.9431e-01,\n",
       "         8.4359e-01, -2.6640e+00, -2.9578e+00, -2.5104e+00, -1.7421e+00,\n",
       "        -4.9531e-02, -3.9144e-03,  9.1855e-01,  1.8339e+00,  1.4223e-01,\n",
       "         7.2612e-01,  1.5463e+00, -7.4061e-01, -3.9223e-01, -9.1813e-01,\n",
       "        -7.1570e-01, -3.8196e+00, -3.7918e-01,  1.8554e+00,  3.2215e+00,\n",
       "         9.1257e-01, -7.8358e-01,  1.0716e+00, -1.8921e+00,  2.5154e+00,\n",
       "         5.3428e-01, -2.2719e+00, -7.3913e-01, -3.2893e-03, -1.0515e+00,\n",
       "         4.1817e-01,  1.3651e+00,  7.2936e-01, -1.6871e+00,  1.2591e+00,\n",
       "        -2.5364e-01, -1.5400e+00,  3.9820e+00,  7.5956e-01, -1.4321e+00,\n",
       "        -4.5364e+00, -1.6669e-01,  1.1966e+00,  1.8102e+00, -1.5013e-01,\n",
       "         4.7373e-02, -1.1055e+00, -2.3912e+00, -2.3066e+00, -2.7333e+00,\n",
       "        -7.9349e-01,  2.7257e+00,  1.2207e+00, -2.9442e-01, -2.7160e+00,\n",
       "        -1.5266e+00, -2.8947e+00, -1.2188e-01,  1.1395e+00,  3.3737e-01,\n",
       "        -8.8937e-02, -3.3998e+00,  4.5548e-01, -1.6074e-01, -3.4834e-01,\n",
       "        -1.8433e+00,  2.5660e+00, -6.5074e-01, -1.7737e+00,  1.1034e+00,\n",
       "        -1.6492e+00, -5.2428e+00,  1.3136e+00,  1.2956e+00, -9.4198e-01,\n",
       "        -1.0976e+00,  1.2703e+00, -2.9037e+00, -1.5988e+00,  1.0237e+00,\n",
       "        -7.5611e-01, -2.1342e+00,  2.2411e-02,  1.0181e+00, -2.1619e+00,\n",
       "        -1.8459e+00, -2.2489e+00, -7.1231e-01,  4.4680e-01, -9.2432e-01,\n",
       "         4.3058e-01,  2.3404e+00, -3.1869e+00,  4.1586e-01, -2.4026e+00,\n",
       "        -1.4496e+00, -3.1237e-01,  1.9181e-01, -3.2115e+00, -2.4924e+00,\n",
       "         4.2933e-02, -7.8957e-01, -1.9365e-01, -2.6595e-01, -3.8632e+00,\n",
       "        -2.1383e+00,  2.2671e+00, -1.4694e+00,  5.7331e-01, -8.8013e-01,\n",
       "         5.7945e-01,  1.9558e+00,  2.0367e+00, -9.1407e-01, -3.1479e+00,\n",
       "         1.5221e+00,  1.2492e-01, -4.3321e-01,  1.4833e+00,  8.3672e-01,\n",
       "         3.2657e-02,  3.3396e+00,  1.1759e+00,  1.0999e+00,  1.3992e+00,\n",
       "         3.1855e+00, -1.0441e+00, -3.4823e+00, -1.6234e+00, -6.6229e-02,\n",
       "        -3.6637e+00, -2.4755e-01, -1.5559e+00,  9.6401e-01,  1.1011e+00,\n",
       "         2.2277e-01,  1.9366e+00, -5.2577e-01,  1.7996e+00,  8.4084e-01,\n",
       "        -5.4386e-01,  9.3896e-01, -2.9228e-02, -8.4814e-01,  8.4402e-01,\n",
       "        -1.7767e+00, -3.5593e+00,  3.8616e-01,  1.4848e+00, -1.4373e+00,\n",
       "         2.4035e+00,  4.0997e-01,  4.4417e+00,  1.7856e+00,  1.6650e-01,\n",
       "         2.0257e+00, -6.9231e-01,  1.8976e+00, -6.1042e-01, -3.4495e+00,\n",
       "         4.2913e+00, -1.6849e+00,  1.4322e+00, -6.9242e+00, -1.8454e+00,\n",
       "        -3.9234e-01,  1.5790e+00, -4.2585e-01, -8.2389e-01,  3.0328e+01,\n",
       "         4.3991e-02, -5.7745e-01,  8.5236e-01, -1.3283e+00,  3.5454e-01,\n",
       "         1.2518e+00,  9.3304e-01,  7.4122e-01,  5.9802e-01, -7.0995e-01,\n",
       "        -1.4463e+00, -4.8820e-01,  1.6767e+00,  9.1712e-01, -1.0909e+00,\n",
       "        -1.4405e+00, -5.6881e-01, -5.3062e-01,  6.3055e-01,  1.5209e+00,\n",
       "         2.9302e+00,  1.3573e+00, -4.5676e+00,  6.0087e-01, -3.1885e+00,\n",
       "        -1.5407e+00, -1.3154e+00, -5.4464e-01, -1.6574e+00, -7.9772e-01,\n",
       "        -6.4280e-01,  2.2497e-01,  1.1595e+00,  1.6939e+00, -5.7789e-01,\n",
       "         6.9691e-01, -8.5310e-01,  2.3616e+00, -4.0731e-01, -6.2535e-01,\n",
       "         3.4466e+00, -5.0833e-01,  5.9137e-01, -9.0315e-01, -3.3263e-01,\n",
       "         3.0566e+00, -4.5183e-01, -6.3547e-01,  2.3277e-01, -1.7135e-01,\n",
       "        -1.5067e+00,  2.0301e+00,  5.4448e-01, -1.4998e+00,  2.0530e+00,\n",
       "        -1.8200e+00,  8.8345e-01, -1.8157e+00, -1.1333e+00, -1.6835e+00,\n",
       "        -2.9152e+00, -1.6972e+00, -1.5522e+00, -1.1343e+00,  1.2752e+00,\n",
       "        -7.1641e-01,  2.2718e+00, -2.2522e+00,  3.8584e-01,  1.6330e-01,\n",
       "        -3.6574e+00,  1.6438e+00, -5.4648e-01, -5.4219e-01,  2.5144e+00,\n",
       "        -3.2202e-01, -3.1841e+00,  9.1812e-01, -3.9847e+00,  9.6924e-01,\n",
       "        -5.2771e-01,  2.3541e+00, -2.0568e+00,  5.6135e-01, -7.5729e-01,\n",
       "        -2.2187e+00,  2.7196e+00, -1.1235e+00, -3.2537e-01, -1.3140e+00,\n",
       "         2.4622e+00,  1.1815e+00,  2.2340e+00,  9.4394e-01,  2.1687e-01,\n",
       "         4.4646e-01, -1.7757e+00,  2.3695e+00,  6.0093e-01, -4.8294e-01,\n",
       "         1.4360e+00,  3.6999e+00,  9.9708e-01,  1.9928e+00, -5.3774e-01,\n",
       "        -2.4961e-01,  5.7288e-01, -3.5102e+00,  3.0449e+00,  1.3154e+00,\n",
       "         1.7785e-01,  1.0157e+00, -8.3735e-01,  1.3787e+00,  3.8094e-01,\n",
       "        -6.7987e-01,  8.8280e-01, -1.5200e+00, -4.2820e-01,  2.1684e+00,\n",
       "        -4.1169e-01, -1.9688e+00,  5.3322e+00, -1.2684e+00, -2.1040e-01,\n",
       "        -1.5723e+00, -7.2551e-01, -5.7812e-01,  6.4161e-01, -2.7294e+00,\n",
       "         1.3358e+00, -2.6092e+00,  1.3526e+00, -6.1968e-01, -1.2703e+00,\n",
       "        -1.3223e-01,  6.3345e-02, -2.2130e+00,  1.1399e+00, -5.1348e-01,\n",
       "        -3.0280e+00,  2.2744e+00, -1.0594e+00, -1.7407e-01, -1.9106e+00,\n",
       "        -3.2869e+00,  3.0111e+00, -2.3058e-01, -1.9162e+00, -4.3314e-01,\n",
       "        -8.3443e-01, -1.4458e+00, -2.1284e+00,  8.9224e-01, -1.5598e+00,\n",
       "        -5.6143e-01, -9.2827e-02,  1.4093e+00, -2.9183e-01, -2.6345e-01,\n",
       "         2.9407e+00,  7.6896e-01, -1.3844e+00, -1.4062e+00, -1.6394e+00,\n",
       "         1.0172e+00,  1.2157e+00, -6.8636e-01,  9.4041e-01,  1.1614e+00,\n",
       "         1.5569e+00, -2.0884e+00,  1.0474e+00], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 27616,     1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = model.generate(torch.tensor([input_ids]), num_beams=4,  max_length=512,  eos_token_id=1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s> 당사자는 유리해지니까, 그걸 악용하는 일도 아주 쉬워진다고 생각해요.</s>'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobart_tokenizer.decode(*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...   \n",
       "2      2                    이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('./data/train_data.csv')\n",
    "df_test = pd.read_csv('./data/test_data.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    df['premise'] = df['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', \"\")\n",
    "    df['hypothesis'] = df['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', \"\")\n",
    "    df['premise'] = '<s>' + df['premise'] + '<unused0>'\n",
    "    df['hypothesis'] = df['hypothesis'] + '</s>'\n",
    "    return df\n",
    "\n",
    "df_train = preprocessing(df_train)\n",
    "df_test = preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt;씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정...</td>\n",
       "      <td>씨름의 여자들의 놀이이다&lt;/s&gt;</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다&lt;/s&gt;</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;s&gt;이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다00000&lt;unused0&gt;</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다&lt;/s&gt;</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;s&gt;광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다&lt;/s&gt;</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;s&gt;진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다&lt;/s&gt;</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  <s>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정...   \n",
       "1      1  <s>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였...   \n",
       "2      2    <s>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다00000<unused0>   \n",
       "3      3  <s>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보...   \n",
       "4      4  <s>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에...   \n",
       "\n",
       "                                   hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다</s>  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다</s>  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</s>     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다</s>        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</s>        neutral  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] 지정된 프로시저를 찾을 수 없습니다. Error loading \"c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31808\\124605286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] 지정된 프로시저를 찾을 수 없습니다. Error loading \"c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at gogamza/kobart-base-v2 and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartForSequenceClassification(\n",
      "  (model): BartModel(\n",
      "    (shared): Embedding(30000, 768, padding_idx=3)\n",
      "    (encoder): BartEncoder(\n",
      "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
      "      (layers): ModuleList(\n",
      "        (0): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): BartDecoder(\n",
      "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
      "      (layers): ModuleList(\n",
      "        (0): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classification_head): BartClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "BartConfig {\n",
      "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"kobart_version\": 2.0,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
    "\n",
    "MODEL_NAME = 'gogamza/kobart-base-v2'\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "config.num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "print(model)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2919 [10:15<?, ?it/s]\n",
      "  0%|          | 0/4375 [11:59<?, ?it/s]\n",
      "  0%|          | 0/4375 [05:10<?, ?it/s]\n",
      "  0%|          | 0/4375 [14:15<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0, 17700, 17757, 14588, 15106, 25922, 17507, 23397, 14038, 12669,\n",
      "        12037, 14576, 15106, 14300, 11285, 10326, 18953, 11863, 23039, 12273,\n",
      "        14217, 14350, 20211, 14079, 14474,     7, 17507, 11908,  9120, 14300,\n",
      "        11285, 28743, 15263, 13590, 16282, 17992,     1,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3])\n",
      "<s> 이정재가 삼성그룹 부회장 이재용의 전처인 대상그룹 임세령 상무와 열애중이라고 합니다00000<unused0> 이재용과 임세령은 결혼한 적이 없다</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, eval_dataset = train_test_split(df_train, test_size=0.2, shuffle=True, stratify=df_train['label'])\n",
    "\n",
    "tokenized_train = tokenizer(\n",
    "    list(train_dataset['premise']),\n",
    "    list(train_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=256, # Max_Length = 190\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "tokenized_eval = tokenizer(\n",
    "    list(eval_dataset['premise']),\n",
    "    list(eval_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=256,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(tokenized_train['input_ids'][0])\n",
    "print(tokenizer.decode(tokenized_train['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kobartDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pair_dataset, label):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "def label_to_num(label):\n",
    "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
    "    num_label = []\n",
    "\n",
    "    for v in label:\n",
    "        num_label.append(label_dict[v])\n",
    "    \n",
    "    return num_label\n",
    "\n",
    "\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "eval_label = label_to_num(eval_dataset['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19998\n",
      "{'input_ids': tensor([    0, 14105,  9989, 16344, 14025, 28975, 15050, 12024, 22745, 19663,\n",
      "        19095, 14796, 18137, 14399, 16449, 13390, 14108, 20935, 16982, 14079,\n",
      "        14474,     7, 14105,  9989, 16344, 14025, 28975, 15050,  9698, 22745,\n",
      "        16505, 20701, 16982,     1,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n",
      "<s> 안드레스 이니에스타의 갑작스런 스페인 귀국에 일본 축구팬들이 당황했다00000<unused0> 안드레스 이니에스타는 갑작스럽게 귀국했다</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "processed_train = copy.copy(tokenized_train)\n",
    "processed_train.pop('token_type_ids')\n",
    "processed_eval = copy.copy(tokenized_eval)\n",
    "processed_eval.pop('token_type_ids')\n",
    "\n",
    "train_dataset = kobartDataset(processed_train, train_label)\n",
    "eval_dataset = kobartDataset(processed_eval, eval_label)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(train_dataset.__len__())\n",
    "print(train_dataset.__getitem__(19997))\n",
    "print(tokenizer.decode(train_dataset.__getitem__(19997)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  \"\"\" validation을 위한 metrics function \"\"\"\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  probs = pred.predictions\n",
    "\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n",
    "\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./result',\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_total_limit=5,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 500,\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4375 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-186-1fea62ac79fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./result/best_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('./result/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "c:\\Users\\leejoon-byeong\\anaconda3\\envs\\stdata\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    df['premise'] = df['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', \"\")\n",
    "    df['hypothesis'] = df['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', \"\")\n",
    "    df['premise'] = '</s>' + df['premise'] + '<unused0>'\n",
    "    df['hypothesis'] = df['hypothesis'] + '</s>'\n",
    "    return df\n",
    "\n",
    "df_train = preprocessing(df_train)\n",
    "df_test = preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import BartForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...   \n",
       "2      2                    이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train_data.csv')\n",
    "df_test = pd.read_csv('./data/test_data.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class Classification(pl.LightningModule):\n",
    "    def __init__(self, hparams, **kwargs) -> None:\n",
    "        super(Classification, self).__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        # add model specific args\n",
    "        parser = argparse.ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "\n",
    "        parser.add_argument(\n",
    "            \"--batch-size\",\n",
    "            type=int,\n",
    "            default=32,\n",
    "            help=\"batch size for training (default: 96)\",\n",
    "        )\n",
    "\n",
    "        parser.add_argument(\n",
    "            \"--lr\", type=float, default=5e-5, help=\"The initial learning rate\"\n",
    "        )\n",
    "\n",
    "        parser.add_argument(\n",
    "            \"--warmup_ratio\", type=float, default=0.1, help=\"warmup ratio\"\n",
    "        )\n",
    "\n",
    "        return parser\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Prepare optimizer\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.01,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters, lr=self.hparams.lr, correct_bias=False\n",
    "        )\n",
    "        # warm up lr\n",
    "        num_workers = (self.hparams.gpus if self.hparams.gpus is not None else 1) * (\n",
    "            self.hparams.num_nodes if self.hparams.num_nodes is not None else 1\n",
    "        )\n",
    "        data_len = len(self.train_dataloader().dataset)\n",
    "        logging.info(f\"number of workers {num_workers}, data length {data_len}\")\n",
    "        num_train_steps = int(\n",
    "            data_len\n",
    "            / (\n",
    "                self.hparams.batch_size\n",
    "                * num_workers\n",
    "                * self.hparams.accumulate_grad_batches\n",
    "            )\n",
    "            * self.hparams.max_epochs\n",
    "        )\n",
    "        logging.info(f\"num_train_steps : {num_train_steps}\")\n",
    "        num_warmup_steps = int(num_train_steps * self.hparams.warmup_ratio)\n",
    "        logging.info(f\"num_warmup_steps : {num_warmup_steps}\")\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_train_steps,\n",
    "        )\n",
    "        lr_scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"loss\",\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "\n",
    "class KoBARTClassification(pl.LightningModule):\n",
    "    def __init__(self, hparams, **kwargs):\n",
    "        super(KoBARTClassification, self).__init__(hparams, **kwargs)\n",
    "        self.model = BartForSequenceClassification.from_pretrained(\n",
    "            'gogamza/kobart-base-v2'\n",
    "        )\n",
    "        \n",
    "        self.model.train()\n",
    "        self.metric_acc = pl.metrics.classification.Accuracy()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        return self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outs = self(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"])\n",
    "        loss = outs.loss\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pred = self(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        labels = batch[\"labels\"]\n",
    "        accuracy = self.metric_acc(\n",
    "            torch.nn.functional.softmax(pred.logits, dim=1), labels\n",
    "        )\n",
    "        self.log(\"accuracy\", accuracy)\n",
    "        result = {\"accuracy\": accuracy}\n",
    "        # Checkpoint model based on validation loss\n",
    "        return result\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_acc = torch.stack([i[\"accuracy\"] for i in outputs]).mean()\n",
    "        self.log(\"val_acc\", val_acc, prog_bar=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e17ea03fbb32132e5671c308166b4379813c9bd4e6a684633c3a9083728c29e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('stdata')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
